{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test = np.load(\"./data/X_test.npy\")\n",
    "y_test = np.load(\"./data/y_test.npy\")\n",
    "person_train_valid = np.load(\"./data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"./data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"./data/y_train_valid.npy\")\n",
    "person_test = np.load(\"./data/person_test.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid target shape: (2115,)\n",
      "Test target shape: (443,)\n",
      "Person train/valid shape: (2115, 1)\n",
      "Person test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"data_augmentation.py\n",
    "Automatically generated by Colaboratory.\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1mspvRcDFXus4jLFjUgUPtgrzm95cMxb7\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "We will put functions to augment data in here.\n",
    "Functions in this file:\n",
    "  window_data\n",
    "\"\"\"\n",
    "\n",
    "def window_data(X, y, window_size, stride):\n",
    "  '''\n",
    "  This function takes in X (a 3-d tensor) of size (#trials x #electrodes x #time \n",
    "  series) and y data of size (#trials) and outputs two options for using it. \n",
    "  X_new1: The first output stacks the windowed data in a new dimension, resulting \n",
    "    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\n",
    "  X_new2: The second option makes the windows into new trails, resulting in a new\n",
    "    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \n",
    "    for the larger number of trials, we also need to augment the y data.\n",
    "  y_new:  The augmented y vector of size (#trials*#windows) to match X_new2.\n",
    "  Some code to visualize what's happening:\n",
    "  #X_new_wind1, X_new_wind2, Y_new  = window_data(X_train_valid, y_train_valid, 200, 20)\n",
    "  #print(X_new_wind1.shape)\n",
    "  #print(X_new_wind2.shape)\n",
    "  #print(Y_new.shape)\n",
    "  '''\n",
    "  num_sub_trials = int((X.shape[2]-window_size)/stride)\n",
    "  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\n",
    "  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\n",
    "  y_new = np.empty([X.shape[0]*num_sub_trials])\n",
    "  for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "      for k in range(num_sub_trials):\n",
    "        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\n",
    "        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\n",
    "        y_new[i*num_sub_trials+k] = y[i]\n",
    "  return X_new1, X_new2, y_new\n",
    "\n",
    "_, X_train, y_train = window_data(X_train_valid, y_train_valid, window_size=200, stride=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Dataloader for EEG data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nclass EEG_Dataset(Dataset):\\n    def __init__ (self, X, y, p, mode='train'):\\n        trial_num = X.shape[0]\\n        trial_idx = np.arange(trial_num)\\n        np.random.shuffle(trial_idx)\\n        train_idx = trial_idx[: int(np.floor(0.8*trial_num))]\\n        val_idx = trial_idx[int(np.ceil(0.8*trial_num)):]\\n        self.X = X\\n        self.y = y - 769\\n        self.p = p\\n        if mode == 'train':\\n            self.sample_list = train_idx\\n        else:\\n            self.sample_list = val_idx\\n\\n    def __len__(self):\\n        return (len(self.sample_list))\\n    \\n    def __getitem__(self, idx):\\n        sample_idx = self.sample_list[idx]\\n        eeg_seq = torch.from_numpy(self.X[sample_idx,:,:]).float()\\n        label = torch.tensor(self.y[sample_idx]).long()\\n        #person_id = torch.from_numpy(self.p[sample_idx,:]).long()\\n        sample = {'eeg_seq': eeg_seq, 'label': label}\\n\\n        return sample\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset for train/val by splitting the train_valid\n",
    "'''\n",
    "class EEG_Dataset(Dataset):\n",
    "    def __init__ (self, X, y, p, mode='train'):\n",
    "        trial_num = X.shape[0]\n",
    "        trial_idx = np.arange(trial_num)\n",
    "        np.random.shuffle(trial_idx)\n",
    "        train_idx = trial_idx[: int(np.floor(0.8*trial_num))]\n",
    "        val_idx = trial_idx[int(np.ceil(0.8*trial_num)):]\n",
    "        self.X = X\n",
    "        self.y = y - 769\n",
    "        self.p = p\n",
    "        if mode == 'train':\n",
    "            self.sample_list = train_idx\n",
    "        else:\n",
    "            self.sample_list = val_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.sample_list))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx = self.sample_list[idx]\n",
    "        eeg_seq = torch.from_numpy(self.X[sample_idx,:,:]).float()\n",
    "        label = torch.tensor(self.y[sample_idx]).long()\n",
    "        #person_id = torch.from_numpy(self.p[sample_idx,:]).long()\n",
    "        sample = {'eeg_seq': eeg_seq, 'label': label}\n",
    "\n",
    "        return sample\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for train/test \n",
    "\n",
    "class EEG_Dataset(Dataset):\n",
    "    def __init__ (self, X_train, y_train, X_test, y_test, mode='train'):\n",
    "        if mode == 'train':\n",
    "            self.X = X_train\n",
    "            self.y = y_train - 769\n",
    "        else:\n",
    "            self.X = X_test\n",
    "            self.y = y_test - 769\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.X.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        eeg_seq = torch.from_numpy(self.X[idx,:,:]).float()\n",
    "        label = torch.tensor(self.y[idx]).long()\n",
    "        sample = {'eeg_seq': eeg_seq, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LSTM + FC to perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "acc:0.28326241134751773\n",
      "loss:911.6234918832779\n",
      "epoch:2\n",
      "acc:0.31173758865248224\n",
      "loss:902.1433691978455\n",
      "epoch:3\n",
      "acc:0.31880023640661936\n",
      "loss:899.1044268608093\n",
      "epoch:4\n",
      "acc:0.334580378250591\n",
      "loss:891.2641495466232\n",
      "epoch:5\n",
      "acc:0.35709219858156027\n",
      "loss:879.686817407608\n",
      "epoch:6\n",
      "acc:0.37388297872340426\n",
      "loss:864.8881139755249\n",
      "epoch:7\n",
      "acc:0.38479314420803784\n",
      "loss:857.483899474144\n",
      "epoch:8\n",
      "acc:0.4008451536643026\n",
      "loss:843.9414757490158\n",
      "epoch:9\n",
      "acc:0.4170626477541371\n",
      "loss:826.4971395730972\n",
      "epoch:10\n",
      "acc:0.4371985815602837\n",
      "loss:807.6768835783005\n",
      "epoch:11\n",
      "acc:0.4633451536643026\n",
      "loss:780.1588814258575\n",
      "epoch:12\n",
      "acc:0.476725768321513\n",
      "loss:761.663426399231\n",
      "epoch:13\n",
      "acc:0.5035460992907801\n",
      "loss:731.0705375671387\n",
      "epoch:14\n",
      "acc:0.522127659574468\n",
      "loss:709.492603123188\n",
      "epoch:15\n",
      "acc:0.5496808510638298\n",
      "loss:677.0949718952179\n",
      "epoch:16\n",
      "acc:0.5568498817966903\n",
      "loss:668.4036608934402\n",
      "epoch:17\n",
      "acc:0.5729255319148936\n",
      "loss:648.2337754964828\n",
      "epoch:18\n",
      "acc:0.5849231678486998\n",
      "loss:632.1437944173813\n",
      "epoch:19\n",
      "acc:0.601548463356974\n",
      "loss:612.096088051796\n",
      "epoch:20\n",
      "acc:0.6302186761229315\n",
      "loss:575.7524453401566\n"
     ]
    }
   ],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, class_num):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, cn) = self.rnn(x)\n",
    "        out = self.fc(torch.squeeze(hn))\n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "model = model(input_size=22, hidden_size=100, class_num=4).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "EEG_trainset = EEG_Dataset(X_train, y_train, X_test, y_test, mode='train')\n",
    "EEG_trainloader = DataLoader(EEG_trainset, batch_size=256, shuffle=True)\n",
    "\n",
    "\n",
    "epoch = 20\n",
    "for i in range (epoch):\n",
    "    print ('epoch:{}'.format(i+1))\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for idx, batch in enumerate(EEG_trainloader):\n",
    "        eeg_seq = batch['eeg_seq'].permute(2,0,1).to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output= model(eeg_seq)\n",
    "        loss = criterion(output, label)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()                \n",
    "        optimizer.step()\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        correct += torch.sum(pred == label).item()\n",
    "        total += label.shape[0]\n",
    "    print ('acc:{}'.format(correct/total))\n",
    "    print ('loss:{}'.format(running_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.3837471783295711\n"
     ]
    }
   ],
   "source": [
    "EEG_testset = EEG_Dataset(X_train, y_train, X_test, y_test, mode='test')\n",
    "EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n",
    "running_loss = 0.0\n",
    "total = 0\n",
    "correct = 0\n",
    "for idx, batch in enumerate(EEG_testloader):\n",
    "    eeg_seq = batch['eeg_seq'].permute(2,0,1).to(device)\n",
    "    label = batch['label'].to(device)\n",
    "    random_idx = np.random.choice(800, 10)        \n",
    "    for i in range(len(random_idx)):\n",
    "        eeg_subseq = eeg_seq[random_idx[i]:random_idx[i]+200,:,:]\n",
    "        if i == 0:\n",
    "            output = model(eeg_subseq)\n",
    "        else:\n",
    "            output += model(eeg_subseq)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    correct += torch.sum(pred == label).item()\n",
    "    total += label.shape[0]\n",
    "print ('acc:{}'.format(correct/total))\n",
    "#print ('loss:{}'.format(running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
