{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "colab_version_clean_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuaghannan/ECEC247_Project/blob/jonathan-tests/colab_version_clean_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA1x8mSiTyYL",
        "colab_type": "text"
      },
      "source": [
        "### loading modules and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQwpQEszAQ9u",
        "colab_type": "code",
        "outputId": "5d305538-5b9d-4035-9595-3e0c90fbc453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6iA6D4yYwiq",
        "colab_type": "code",
        "outputId": "cc67887e-c022-435b-f7d0-8e6c9921ae1e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# # If using colab\n",
        " from google.colab import files\n",
        " files.upload()\n",
        "# # select the 3 .py files (models, utils, data_utils)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-82b586b3-a958-4800-bfaa-d550b7b87244\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-82b586b3-a958-4800-bfaa-d550b7b87244\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-S67grVAoSt",
        "colab_type": "code",
        "outputId": "f7198c15-2f42-4398-81f7-e228e58bdaac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "# Create a folder \"C247\" and then store the project datasets within that folder\n",
        "# Check that your datasets are setup correctly\n",
        "\n",
        "!ls \"/content/gdrive/My Drive/C247\" # File path"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_utils.py\t   person_test.npy\t   X_test.npy\t      y_train_valid.npy\n",
            "EEG_loading.ipynb  person_train_valid.npy  X_train_valid.npy\n",
            "models.py\t   utils.py\t\t   y_test.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jkt1ZNZWIhi",
        "colab_type": "code",
        "outputId": "a3feab89-9020-4bb4-82db-f43e316e8126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from models import *\n",
        "from utils import *\n",
        "from data_utils import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJfyBLNLA686",
        "colab_type": "code",
        "outputId": "b33888c1-27e4-4b0f-a85c-f55aa5cd0217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# X_test = np.load(\"X_test.npy\")\n",
        "# y_test = np.load(\"y_test.npy\")\n",
        "# person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "# X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "# y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "# person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "# Change if your directory is different\n",
        "\n",
        "# dataset_path = './data/' # Yiming Path\n",
        "dataset_path = \"/content/gdrive/My Drive/C247/\" \n",
        "\n",
        "X_test = np.load(dataset_path + \"X_test.npy\")\n",
        "y_test = np.load(dataset_path + \"y_test.npy\")\n",
        "person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n",
        "X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n",
        "y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n",
        "person_test = np.load(dataset_path + \"person_test.npy\")\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))\n",
        "\n",
        "#train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90IvaY2LTyY1",
        "colab_type": "text"
      },
      "source": [
        "### K-Fold Training and Validation (use k=1 to get results faster)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3_bl5-h3DxE",
        "colab_type": "text"
      },
      "source": [
        "Data $\\rightarrow$ Window $\\rightarrow$ STFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrIa4w_EqqOi",
        "colab_type": "code",
        "outputId": "0e994708-3eff-4725-8215-e26864af06d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 100\n",
        "window_stride = 40\n",
        "vote_num = 30 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 2.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 5\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt applied...\n",
            "fold 1\n",
            "Initial fold shape: (1692, 176, 1000)\n",
            "window applied...\n",
            "Data shape: (37224, 176, 100)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 6.98    loss: 403.978    train acc: 0.270    val acc: 0.284\n",
            "saving best model...\n",
            "epoch: 2      time: 7.11    loss: 401.754    train acc: 0.284    val acc: 0.265\n",
            "epoch: 3      time: 7.31    loss: 400.657    train acc: 0.294    val acc: 0.307\n",
            "saving best model...\n",
            "epoch: 4      time: 7.06    loss: 399.948    train acc: 0.296    val acc: 0.310\n",
            "saving best model...\n",
            "epoch: 5      time: 6.92    loss: 399.064    train acc: 0.304    val acc: 0.340\n",
            "saving best model...\n",
            "epoch: 6      time: 7.12    loss: 398.406    train acc: 0.305    val acc: 0.317\n",
            "epoch: 7      time: 7.02    loss: 397.001    train acc: 0.317    val acc: 0.298\n",
            "epoch: 8      time: 7.17    loss: 395.392    train acc: 0.327    val acc: 0.298\n",
            "epoch: 9      time: 7.20    loss: 394.427    train acc: 0.330    val acc: 0.314\n",
            "epoch: 10     time: 7.27    loss: 392.772    train acc: 0.337    val acc: 0.333\n",
            "epoch: 11     time: 7.37    loss: 391.432    train acc: 0.344    val acc: 0.319\n",
            "epoch: 12     time: 7.19    loss: 389.523    train acc: 0.351    val acc: 0.331\n",
            "epoch: 13     time: 7.07    loss: 388.649    train acc: 0.354    val acc: 0.326\n",
            "epoch: 14     time: 7.30    loss: 386.630    train acc: 0.361    val acc: 0.324\n",
            "epoch: 15     time: 7.07    loss: 384.809    train acc: 0.368    val acc: 0.336\n",
            "epoch: 16     time: 6.95    loss: 383.668    train acc: 0.372    val acc: 0.338\n",
            "epoch: 17     time: 6.96    loss: 382.196    train acc: 0.377    val acc: 0.369\n",
            "saving best model...\n",
            "epoch: 18     time: 6.97    loss: 380.086    train acc: 0.387    val acc: 0.307\n",
            "epoch: 19     time: 7.09    loss: 378.086    train acc: 0.389    val acc: 0.338\n",
            "epoch: 20     time: 7.02    loss: 377.540    train acc: 0.395    val acc: 0.402\n",
            "saving best model...\n",
            "fold 2\n",
            "Initial fold shape: (1692, 176, 1000)\n",
            "window applied...\n",
            "Data shape: (37224, 176, 100)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 7.31    loss: 403.825    train acc: 0.270    val acc: 0.265\n",
            "saving best model...\n",
            "epoch: 2      time: 7.39    loss: 401.868    train acc: 0.283    val acc: 0.272\n",
            "saving best model...\n",
            "epoch: 3      time: 7.18    loss: 400.907    train acc: 0.291    val acc: 0.303\n",
            "saving best model...\n",
            "epoch: 4      time: 7.11    loss: 400.523    train acc: 0.291    val acc: 0.305\n",
            "saving best model...\n",
            "epoch: 5      time: 7.37    loss: 399.944    train acc: 0.297    val acc: 0.305\n",
            "saving best model...\n",
            "epoch: 6      time: 7.15    loss: 399.192    train acc: 0.302    val acc: 0.293\n",
            "epoch: 7      time: 6.97    loss: 398.850    train acc: 0.305    val acc: 0.284\n",
            "epoch: 8      time: 7.20    loss: 398.507    train acc: 0.308    val acc: 0.348\n",
            "saving best model...\n",
            "epoch: 9      time: 7.00    loss: 397.809    train acc: 0.311    val acc: 0.296\n",
            "epoch: 10     time: 7.22    loss: 396.928    train acc: 0.315    val acc: 0.305\n",
            "epoch: 11     time: 7.20    loss: 396.573    train acc: 0.319    val acc: 0.319\n",
            "epoch: 12     time: 7.31    loss: 395.963    train acc: 0.321    val acc: 0.298\n",
            "epoch: 13     time: 7.40    loss: 395.029    train acc: 0.328    val acc: 0.355\n",
            "saving best model...\n",
            "epoch: 14     time: 7.20    loss: 393.892    train acc: 0.336    val acc: 0.352\n",
            "epoch: 15     time: 7.22    loss: 392.391    train acc: 0.340    val acc: 0.345\n",
            "epoch: 16     time: 7.43    loss: 392.126    train acc: 0.342    val acc: 0.378\n",
            "saving best model...\n",
            "epoch: 17     time: 7.31    loss: 390.083    train acc: 0.352    val acc: 0.350\n",
            "epoch: 18     time: 7.25    loss: 388.743    train acc: 0.355    val acc: 0.364\n",
            "epoch: 19     time: 7.35    loss: 387.277    train acc: 0.364    val acc: 0.392\n",
            "saving best model...\n",
            "epoch: 20     time: 7.27    loss: 385.421    train acc: 0.367    val acc: 0.409\n",
            "saving best model...\n",
            "fold 3\n",
            "Initial fold shape: (1692, 176, 1000)\n",
            "window applied...\n",
            "Data shape: (37224, 176, 100)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 7.53    loss: 403.807    train acc: 0.267    val acc: 0.284\n",
            "saving best model...\n",
            "epoch: 2      time: 7.43    loss: 401.838    train acc: 0.281    val acc: 0.305\n",
            "saving best model...\n",
            "epoch: 3      time: 7.34    loss: 400.928    train acc: 0.291    val acc: 0.281\n",
            "epoch: 4      time: 7.41    loss: 400.352    train acc: 0.293    val acc: 0.326\n",
            "saving best model...\n",
            "epoch: 5      time: 7.34    loss: 399.388    train acc: 0.299    val acc: 0.312\n",
            "epoch: 6      time: 7.24    loss: 398.291    train acc: 0.309    val acc: 0.340\n",
            "saving best model...\n",
            "epoch: 7      time: 7.29    loss: 398.231    train acc: 0.306    val acc: 0.366\n",
            "saving best model...\n",
            "epoch: 8      time: 7.25    loss: 397.551    train acc: 0.308    val acc: 0.359\n",
            "epoch: 9      time: 7.25    loss: 396.978    train acc: 0.317    val acc: 0.366\n",
            "saving best model...\n",
            "epoch: 10     time: 7.27    loss: 397.107    train acc: 0.315    val acc: 0.343\n",
            "epoch: 11     time: 7.26    loss: 396.203    train acc: 0.322    val acc: 0.348\n",
            "epoch: 12     time: 7.37    loss: 394.993    train acc: 0.327    val acc: 0.355\n",
            "epoch: 13     time: 7.30    loss: 393.766    train acc: 0.333    val acc: 0.312\n",
            "epoch: 14     time: 7.38    loss: 392.756    train acc: 0.334    val acc: 0.350\n",
            "epoch: 15     time: 7.44    loss: 392.751    train acc: 0.338    val acc: 0.340\n",
            "epoch: 16     time: 7.58    loss: 390.858    train acc: 0.344    val acc: 0.397\n",
            "saving best model...\n",
            "epoch: 17     time: 7.27    loss: 389.371    train acc: 0.351    val acc: 0.388\n",
            "epoch: 18     time: 7.42    loss: 388.527    train acc: 0.355    val acc: 0.381\n",
            "epoch: 19     time: 7.48    loss: 387.290    train acc: 0.359    val acc: 0.385\n",
            "epoch: 20     time: 7.23    loss: 385.664    train acc: 0.366    val acc: 0.411\n",
            "saving best model...\n",
            "fold 4\n",
            "Initial fold shape: (1692, 176, 1000)\n",
            "window applied...\n",
            "Data shape: (37224, 176, 100)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 7.37    loss: 404.034    train acc: 0.266    val acc: 0.251\n",
            "saving best model...\n",
            "epoch: 2      time: 7.46    loss: 402.422    train acc: 0.278    val acc: 0.324\n",
            "saving best model...\n",
            "epoch: 3      time: 7.50    loss: 402.048    train acc: 0.284    val acc: 0.324\n",
            "saving best model...\n",
            "epoch: 4      time: 7.50    loss: 401.188    train acc: 0.290    val acc: 0.338\n",
            "saving best model...\n",
            "epoch: 5      time: 7.29    loss: 400.864    train acc: 0.292    val acc: 0.329\n",
            "epoch: 6      time: 7.38    loss: 400.445    train acc: 0.295    val acc: 0.345\n",
            "saving best model...\n",
            "epoch: 7      time: 7.50    loss: 400.104    train acc: 0.297    val acc: 0.331\n",
            "epoch: 8      time: 7.33    loss: 399.764    train acc: 0.294    val acc: 0.357\n",
            "saving best model...\n",
            "epoch: 9      time: 7.32    loss: 398.720    train acc: 0.304    val acc: 0.364\n",
            "saving best model...\n",
            "epoch: 10     time: 7.32    loss: 398.370    train acc: 0.310    val acc: 0.329\n",
            "epoch: 11     time: 7.40    loss: 397.631    train acc: 0.309    val acc: 0.357\n",
            "epoch: 12     time: 7.33    loss: 396.730    train acc: 0.317    val acc: 0.374\n",
            "saving best model...\n",
            "epoch: 13     time: 7.44    loss: 396.597    train acc: 0.316    val acc: 0.352\n",
            "epoch: 14     time: 7.48    loss: 395.518    train acc: 0.323    val acc: 0.364\n",
            "epoch: 15     time: 7.53    loss: 394.749    train acc: 0.329    val acc: 0.350\n",
            "epoch: 16     time: 7.32    loss: 394.027    train acc: 0.329    val acc: 0.359\n",
            "epoch: 17     time: 7.48    loss: 392.635    train acc: 0.336    val acc: 0.397\n",
            "saving best model...\n",
            "epoch: 18     time: 7.42    loss: 392.222    train acc: 0.338    val acc: 0.395\n",
            "epoch: 19     time: 7.30    loss: 391.164    train acc: 0.345    val acc: 0.392\n",
            "epoch: 20     time: 7.30    loss: 390.445    train acc: 0.345    val acc: 0.400\n",
            "saving best model...\n",
            "fold 5\n",
            "Initial fold shape: (1692, 176, 1000)\n",
            "window applied...\n",
            "Data shape: (37224, 176, 100)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 7.35    loss: 404.340    train acc: 0.263    val acc: 0.279\n",
            "saving best model...\n",
            "epoch: 2      time: 7.29    loss: 402.633    train acc: 0.276    val acc: 0.270\n",
            "epoch: 3      time: 7.36    loss: 401.627    train acc: 0.285    val acc: 0.281\n",
            "saving best model...\n",
            "epoch: 4      time: 7.41    loss: 401.225    train acc: 0.288    val acc: 0.307\n",
            "saving best model...\n",
            "epoch: 5      time: 7.47    loss: 400.830    train acc: 0.293    val acc: 0.300\n",
            "epoch: 6      time: 7.50    loss: 400.304    train acc: 0.294    val acc: 0.317\n",
            "saving best model...\n",
            "epoch: 7      time: 7.40    loss: 399.371    train acc: 0.302    val acc: 0.322\n",
            "saving best model...\n",
            "epoch: 8      time: 7.34    loss: 399.475    train acc: 0.302    val acc: 0.300\n",
            "epoch: 9      time: 7.46    loss: 398.552    train acc: 0.305    val acc: 0.305\n",
            "epoch: 10     time: 7.30    loss: 398.158    train acc: 0.311    val acc: 0.329\n",
            "saving best model...\n",
            "epoch: 11     time: 7.27    loss: 397.080    train acc: 0.315    val acc: 0.300\n",
            "epoch: 12     time: 7.35    loss: 396.605    train acc: 0.318    val acc: 0.281\n",
            "epoch: 13     time: 7.27    loss: 396.099    train acc: 0.318    val acc: 0.340\n",
            "saving best model...\n",
            "epoch: 14     time: 7.32    loss: 395.043    train acc: 0.324    val acc: 0.340\n",
            "saving best model...\n",
            "epoch: 15     time: 7.40    loss: 393.729    train acc: 0.331    val acc: 0.338\n",
            "epoch: 16     time: 7.47    loss: 392.566    train acc: 0.337    val acc: 0.340\n",
            "saving best model...\n",
            "epoch: 17     time: 7.49    loss: 393.078    train acc: 0.336    val acc: 0.348\n",
            "saving best model...\n",
            "epoch: 18     time: 7.38    loss: 390.951    train acc: 0.345    val acc: 0.322\n",
            "epoch: 19     time: 7.37    loss: 389.683    train acc: 0.350    val acc: 0.343\n",
            "epoch: 20     time: 7.47    loss: 388.306    train acc: 0.355    val acc: 0.385\n",
            "saving best model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yGSJZ62TyY7",
        "colab_type": "text"
      },
      "source": [
        "### Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kw9gvQr0S44",
        "colab_type": "text"
      },
      "source": [
        "#### Test 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT9IdrogTyY9",
        "colab_type": "code",
        "outputId": "45fe9d49-a525-44df-afcd-6deded6936cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.3160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFarYt6AtV9Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "c81b90ee-7270-4b42-d8a7-4db129e7e0c5"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 150\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 2.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt applied...\n",
            "fold 1\n",
            "Initial fold shape: (1692, 176, 1000)\n",
            "window applied...\n",
            "Data shape: (28764, 176, 150)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 8.24    loss: 312.516    train acc: 0.269    val acc: 0.279\n",
            "saving best model...\n",
            "epoch: 2      time: 8.50    loss: 310.560    train acc: 0.285    val acc: 0.270\n",
            "epoch: 3      time: 8.49    loss: 309.938    train acc: 0.292    val acc: 0.274\n",
            "epoch: 4      time: 8.29    loss: 309.587    train acc: 0.296    val acc: 0.274\n",
            "epoch: 5      time: 8.45    loss: 309.056    train acc: 0.304    val acc: 0.293\n",
            "saving best model...\n",
            "epoch: 6      time: 8.40    loss: 308.114    train acc: 0.308    val acc: 0.331\n",
            "saving best model...\n",
            "epoch: 7      time: 8.29    loss: 307.502    train acc: 0.312    val acc: 0.312\n",
            "epoch: 8      time: 8.34    loss: 306.295    train acc: 0.322    val acc: 0.279\n",
            "epoch: 9      time: 8.23    loss: 305.497    train acc: 0.328    val acc: 0.300\n",
            "epoch: 10     time: 8.25    loss: 304.659    train acc: 0.331    val acc: 0.307\n",
            "epoch: 11     time: 8.29    loss: 302.620    train acc: 0.341    val acc: 0.322\n",
            "epoch: 12     time: 8.26    loss: 301.249    train acc: 0.350    val acc: 0.303\n",
            "epoch: 13     time: 8.39    loss: 300.012    train acc: 0.357    val acc: 0.310\n",
            "epoch: 14     time: 8.40    loss: 298.468    train acc: 0.361    val acc: 0.305\n",
            "epoch: 15     time: 8.47    loss: 296.469    train acc: 0.370    val acc: 0.333\n",
            "saving best model...\n",
            "epoch: 16     time: 8.49    loss: 294.033    train acc: 0.383    val acc: 0.324\n",
            "epoch: 17     time: 8.27    loss: 291.261    train acc: 0.397    val acc: 0.350\n",
            "saving best model...\n",
            "epoch: 18     time: 8.46    loss: 290.689    train acc: 0.397    val acc: 0.336\n",
            "epoch: 19     time: 8.31    loss: 288.261    train acc: 0.406    val acc: 0.348\n",
            "epoch: 20     time: 8.25    loss: 286.450    train acc: 0.416    val acc: 0.343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOhVBENUvGWM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "874d0738-3e86-4ec0-d7b3-abb31e5aab32"
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting test data...\n",
            "Testing...\n",
            "Testing Accuracy: 0.3296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oYBFsTI0X6O",
        "colab_type": "text"
      },
      "source": [
        "### Test 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEbqPF23weaY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "60a50b2c-fdd5-4cd2-9dfe-772deebe958b"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 150\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 1.0\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 25\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 2e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt applied...\n",
            "fold 1\n",
            "Initial fold shape: (1692, 176, 1000)\n",
            "window applied...\n",
            "Data shape: (28764, 176, 150)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.002\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 8.37    loss: 312.700    train acc: 0.263    val acc: 0.279\n",
            "saving best model...\n",
            "epoch: 2      time: 8.31    loss: 311.472    train acc: 0.272    val acc: 0.300\n",
            "saving best model...\n",
            "epoch: 3      time: 8.34    loss: 310.940    train acc: 0.278    val acc: 0.322\n",
            "saving best model...\n",
            "epoch: 4      time: 8.50    loss: 310.631    train acc: 0.281    val acc: 0.303\n",
            "epoch: 5      time: 8.58    loss: 310.451    train acc: 0.284    val acc: 0.352\n",
            "saving best model...\n",
            "epoch: 6      time: 8.56    loss: 310.387    train acc: 0.281    val acc: 0.324\n",
            "epoch: 7      time: 8.41    loss: 310.344    train acc: 0.284    val acc: 0.331\n",
            "epoch: 8      time: 8.54    loss: 309.993    train acc: 0.286    val acc: 0.329\n",
            "epoch: 9      time: 8.48    loss: 309.878    train acc: 0.289    val acc: 0.333\n",
            "epoch: 10     time: 8.38    loss: 309.820    train acc: 0.289    val acc: 0.348\n",
            "epoch: 11     time: 8.41    loss: 309.735    train acc: 0.292    val acc: 0.340\n",
            "epoch: 12     time: 8.48    loss: 309.504    train acc: 0.291    val acc: 0.312\n",
            "epoch: 13     time: 8.43    loss: 309.606    train acc: 0.287    val acc: 0.338\n",
            "epoch: 14     time: 8.39    loss: 308.903    train acc: 0.295    val acc: 0.350\n",
            "epoch: 15     time: 8.47    loss: 308.816    train acc: 0.299    val acc: 0.350\n",
            "epoch: 16     time: 8.50    loss: 307.737    train acc: 0.306    val acc: 0.371\n",
            "saving best model...\n",
            "epoch: 17     time: 8.53    loss: 305.642    train acc: 0.321    val acc: 0.340\n",
            "epoch: 18     time: 8.56    loss: 304.516    train acc: 0.324    val acc: 0.374\n",
            "saving best model...\n",
            "epoch: 19     time: 8.41    loss: 303.011    train acc: 0.338    val acc: 0.326\n",
            "epoch: 20     time: 8.54    loss: 301.209    train acc: 0.346    val acc: 0.423\n",
            "saving best model...\n",
            "epoch: 21     time: 8.42    loss: 298.293    train acc: 0.365    val acc: 0.392\n",
            "epoch: 22     time: 8.44    loss: 296.336    train acc: 0.372    val acc: 0.409\n",
            "epoch: 23     time: 8.44    loss: 295.435    train acc: 0.377    val acc: 0.435\n",
            "saving best model...\n",
            "epoch: 24     time: 8.48    loss: 293.809    train acc: 0.382    val acc: 0.385\n",
            "epoch: 25     time: 8.52    loss: 292.432    train acc: 0.386    val acc: 0.407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYf_Zl6NxE-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3814471a-6ff2-4a8d-e956-636d4feb44b1"
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting test data...\n",
            "Testing...\n",
            "Testing Accuracy: 0.4424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SeGVR_v0dpG",
        "colab_type": "text"
      },
      "source": [
        "### Test 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798JftVyyh-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "a0b3ae99-56e4-409e-9fa6-82e8245dcb2a"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 1.0\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt applied...\n",
            "fold 1\n",
            "Initial fold shape: (1692, 198, 1000)\n",
            "window applied...\n",
            "Data shape: (16920, 198, 200)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.002\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 7.30    loss: 185.216    train acc: 0.254    val acc: 0.274\n",
            "saving best model...\n",
            "epoch: 2      time: 7.06    loss: 184.458    train acc: 0.268    val acc: 0.227\n",
            "epoch: 3      time: 7.10    loss: 184.099    train acc: 0.272    val acc: 0.281\n",
            "saving best model...\n",
            "epoch: 4      time: 7.15    loss: 183.935    train acc: 0.276    val acc: 0.279\n",
            "epoch: 5      time: 7.14    loss: 183.745    train acc: 0.276    val acc: 0.291\n",
            "saving best model...\n",
            "epoch: 6      time: 7.17    loss: 183.832    train acc: 0.281    val acc: 0.253\n",
            "epoch: 7      time: 7.24    loss: 183.434    train acc: 0.287    val acc: 0.298\n",
            "saving best model...\n",
            "epoch: 8      time: 7.27    loss: 183.627    train acc: 0.284    val acc: 0.324\n",
            "saving best model...\n",
            "epoch: 9      time: 7.24    loss: 183.503    train acc: 0.281    val acc: 0.348\n",
            "saving best model...\n",
            "epoch: 10     time: 7.11    loss: 183.517    train acc: 0.279    val acc: 0.305\n",
            "epoch: 11     time: 7.23    loss: 183.262    train acc: 0.287    val acc: 0.338\n",
            "epoch: 12     time: 7.20    loss: 183.298    train acc: 0.284    val acc: 0.284\n",
            "epoch: 13     time: 7.11    loss: 183.080    train acc: 0.289    val acc: 0.359\n",
            "saving best model...\n",
            "epoch: 14     time: 7.15    loss: 182.853    train acc: 0.295    val acc: 0.333\n",
            "epoch: 15     time: 7.14    loss: 182.179    train acc: 0.303    val acc: 0.322\n",
            "epoch: 16     time: 7.16    loss: 181.625    train acc: 0.307    val acc: 0.293\n",
            "epoch: 17     time: 7.09    loss: 180.775    train acc: 0.320    val acc: 0.343\n",
            "epoch: 18     time: 7.15    loss: 180.847    train acc: 0.317    val acc: 0.357\n",
            "epoch: 19     time: 7.20    loss: 180.117    train acc: 0.328    val acc: 0.369\n",
            "saving best model...\n",
            "epoch: 20     time: 7.11    loss: 179.782    train acc: 0.327    val acc: 0.345\n",
            "epoch: 21     time: 7.18    loss: 179.356    train acc: 0.330    val acc: 0.345\n",
            "epoch: 22     time: 7.25    loss: 179.313    train acc: 0.333    val acc: 0.322\n",
            "epoch: 23     time: 7.25    loss: 178.545    train acc: 0.334    val acc: 0.366\n",
            "epoch: 24     time: 7.13    loss: 178.114    train acc: 0.339    val acc: 0.340\n",
            "epoch: 25     time: 7.22    loss: 177.228    train acc: 0.351    val acc: 0.362\n",
            "epoch: 26     time: 7.23    loss: 175.976    train acc: 0.363    val acc: 0.388\n",
            "saving best model...\n",
            "epoch: 27     time: 7.10    loss: 175.896    train acc: 0.365    val acc: 0.376\n",
            "epoch: 28     time: 7.14    loss: 174.942    train acc: 0.370    val acc: 0.376\n",
            "epoch: 29     time: 7.13    loss: 174.081    train acc: 0.375    val acc: 0.355\n",
            "epoch: 30     time: 7.19    loss: 174.086    train acc: 0.375    val acc: 0.409\n",
            "saving best model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFkQDOSZzR1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7a817547-f518-4525-a789-ddd9aeb23a7b"
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting test data...\n",
            "Testing...\n",
            "Testing Accuracy: 0.3950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMH4qopo1t8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGEBGZiS2EK-",
        "colab_type": "text"
      },
      "source": [
        "### Test 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J8syp_l2GAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "bffbb517-9b5e-4186-afdb-9395ecab9792"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 1.0\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"window\"\n",
        "aug_2 = \"cwt\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "window applied...\n",
            "fold 1\n",
            "Initial fold shape: (16920, 22, 200)\n",
            "cwt applied...\n",
            "Data shape: (16920, 198, 200)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 5.93    loss: 185.141    train acc: 0.258    val acc: 0.261\n",
            "saving best model...\n",
            "epoch: 2      time: 5.77    loss: 184.140    train acc: 0.273    val acc: 0.258\n",
            "epoch: 3      time: 5.83    loss: 183.799    train acc: 0.280    val acc: 0.270\n",
            "saving best model...\n",
            "epoch: 4      time: 5.80    loss: 183.754    train acc: 0.280    val acc: 0.278\n",
            "saving best model...\n",
            "epoch: 5      time: 5.81    loss: 183.471    train acc: 0.288    val acc: 0.273\n",
            "epoch: 6      time: 5.80    loss: 183.266    train acc: 0.286    val acc: 0.270\n",
            "epoch: 7      time: 5.78    loss: 183.031    train acc: 0.294    val acc: 0.264\n",
            "epoch: 8      time: 5.78    loss: 183.284    train acc: 0.286    val acc: 0.273\n",
            "epoch: 9      time: 5.75    loss: 183.043    train acc: 0.290    val acc: 0.273\n",
            "epoch: 10     time: 5.80    loss: 182.832    train acc: 0.292    val acc: 0.281\n",
            "saving best model...\n",
            "epoch: 11     time: 5.76    loss: 182.739    train acc: 0.298    val acc: 0.277\n",
            "epoch: 12     time: 5.79    loss: 182.502    train acc: 0.299    val acc: 0.270\n",
            "epoch: 13     time: 5.81    loss: 182.261    train acc: 0.303    val acc: 0.286\n",
            "saving best model...\n",
            "epoch: 14     time: 5.80    loss: 182.364    train acc: 0.298    val acc: 0.282\n",
            "epoch: 15     time: 5.79    loss: 182.016    train acc: 0.305    val acc: 0.293\n",
            "saving best model...\n",
            "epoch: 16     time: 5.80    loss: 181.696    train acc: 0.303    val acc: 0.288\n",
            "epoch: 17     time: 5.80    loss: 181.146    train acc: 0.318    val acc: 0.308\n",
            "saving best model...\n",
            "epoch: 18     time: 5.76    loss: 180.353    train acc: 0.323    val acc: 0.315\n",
            "saving best model...\n",
            "epoch: 19     time: 5.75    loss: 179.924    train acc: 0.329    val acc: 0.311\n",
            "epoch: 20     time: 5.76    loss: 178.915    train acc: 0.337    val acc: 0.320\n",
            "saving best model...\n",
            "epoch: 21     time: 5.75    loss: 178.963    train acc: 0.335    val acc: 0.324\n",
            "saving best model...\n",
            "epoch: 22     time: 5.76    loss: 177.654    train acc: 0.346    val acc: 0.321\n",
            "epoch: 23     time: 5.75    loss: 177.772    train acc: 0.343    val acc: 0.316\n",
            "epoch: 24     time: 5.77    loss: 177.150    train acc: 0.349    val acc: 0.304\n",
            "epoch: 25     time: 5.78    loss: 176.457    train acc: 0.355    val acc: 0.327\n",
            "saving best model...\n",
            "epoch: 26     time: 5.77    loss: 176.128    train acc: 0.361    val acc: 0.311\n",
            "epoch: 27     time: 5.74    loss: 175.327    train acc: 0.363    val acc: 0.322\n",
            "epoch: 28     time: 5.76    loss: 174.308    train acc: 0.375    val acc: 0.315\n",
            "epoch: 29     time: 5.74    loss: 174.161    train acc: 0.375    val acc: 0.328\n",
            "saving best model...\n",
            "epoch: 30     time: 5.74    loss: 172.170    train acc: 0.391    val acc: 0.340\n",
            "saving best model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYzzeNN_2Kh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "684397c7-0b5b-4aa3-b9eb-3955869f2419"
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting test data...\n",
            "Testing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8a136dfb6e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_test_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_test_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAug_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperson_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maug_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwindow_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_stride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstft_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstft_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstft_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstft_stride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcwt_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwt_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcwt_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwt_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mTestRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_test_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvote_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvote_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstft_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstft_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstft_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstft_stride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcwt_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwt_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcwt_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwt_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: TestRNN() got an unexpected keyword argument 'stft_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THs058di9syd",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmwRgYkb8a5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "3b2714bd-2cf4-410c-b761-704d898c2cdc"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 0.7\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt applied...\n",
            "fold 1\n",
            "Initial fold shape: (1692, 198, 1000)\n",
            "window applied...\n",
            "Data shape: (16920, 198, 250)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.002\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 8.69    loss: 185.440    train acc: 0.253    val acc: 0.284\n",
            "saving best model...\n",
            "epoch: 2      time: 8.81    loss: 184.310    train acc: 0.266    val acc: 0.258\n",
            "epoch: 3      time: 8.79    loss: 184.026    train acc: 0.273    val acc: 0.322\n",
            "saving best model...\n",
            "epoch: 4      time: 8.83    loss: 183.658    train acc: 0.279    val acc: 0.348\n",
            "saving best model...\n",
            "epoch: 5      time: 8.70    loss: 183.818    train acc: 0.274    val acc: 0.248\n",
            "epoch: 6      time: 8.73    loss: 183.609    train acc: 0.277    val acc: 0.270\n",
            "epoch: 7      time: 8.65    loss: 183.554    train acc: 0.278    val acc: 0.333\n",
            "epoch: 8      time: 8.76    loss: 183.210    train acc: 0.286    val acc: 0.331\n",
            "epoch: 9      time: 8.73    loss: 182.370    train acc: 0.294    val acc: 0.366\n",
            "saving best model...\n",
            "epoch: 10     time: 8.71    loss: 181.941    train acc: 0.306    val acc: 0.402\n",
            "saving best model...\n",
            "epoch: 11     time: 8.76    loss: 181.359    train acc: 0.310    val acc: 0.336\n",
            "epoch: 12     time: 8.67    loss: 180.219    train acc: 0.325    val acc: 0.348\n",
            "epoch: 13     time: 8.70    loss: 178.611    train acc: 0.347    val acc: 0.378\n",
            "epoch: 14     time: 8.69    loss: 176.331    train acc: 0.366    val acc: 0.357\n",
            "epoch: 15     time: 8.78    loss: 175.451    train acc: 0.369    val acc: 0.366\n",
            "epoch: 16     time: 8.75    loss: 173.875    train acc: 0.379    val acc: 0.390\n",
            "epoch: 17     time: 8.79    loss: 172.349    train acc: 0.386    val acc: 0.400\n",
            "epoch: 18     time: 8.81    loss: 171.326    train acc: 0.392    val acc: 0.374\n",
            "epoch: 19     time: 8.75    loss: 170.716    train acc: 0.397    val acc: 0.390\n",
            "epoch: 20     time: 8.75    loss: 168.559    train acc: 0.414    val acc: 0.374\n",
            "epoch: 21     time: 8.72    loss: 168.011    train acc: 0.413    val acc: 0.366\n",
            "epoch: 22     time: 8.68    loss: 166.714    train acc: 0.420    val acc: 0.421\n",
            "saving best model...\n",
            "epoch: 23     time: 8.69    loss: 166.199    train acc: 0.421    val acc: 0.428\n",
            "saving best model...\n",
            "epoch: 24     time: 8.71    loss: 164.859    train acc: 0.429    val acc: 0.411\n",
            "epoch: 25     time: 8.75    loss: 164.901    train acc: 0.424    val acc: 0.426\n",
            "epoch: 26     time: 8.71    loss: 163.837    train acc: 0.440    val acc: 0.374\n",
            "epoch: 27     time: 8.74    loss: 163.519    train acc: 0.437    val acc: 0.430\n",
            "saving best model...\n",
            "epoch: 28     time: 8.73    loss: 161.649    train acc: 0.446    val acc: 0.411\n",
            "epoch: 29     time: 8.72    loss: 161.186    train acc: 0.450    val acc: 0.437\n",
            "saving best model...\n",
            "epoch: 30     time: 8.72    loss: 160.307    train acc: 0.452    val acc: 0.395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCyum8Am977T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f18f0706-ff69-4178-ac4a-bd91231adb19"
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Augmenting test data...\n",
            "Testing...\n",
            "Testing Accuracy: 0.4266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPzC1YWnAwsk",
        "colab_type": "text"
      },
      "source": [
        "### Testtttt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Pq_8g2Ae4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "outputId": "2bfbbb4e-a3ca-4707-ab5d-920cb37791a0"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 0.4\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt applied...\n",
            "fold 1\n",
            "Initial fold shape: (1692, 198, 1000)\n",
            "window applied...\n",
            "Data shape: (16920, 198, 250)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.002\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 8.75    loss: 185.518    train acc: 0.255    val acc: 0.258\n",
            "saving best model...\n",
            "epoch: 2      time: 8.84    loss: 184.361    train acc: 0.263    val acc: 0.265\n",
            "saving best model...\n",
            "epoch: 3      time: 8.81    loss: 184.303    train acc: 0.263    val acc: 0.267\n",
            "saving best model...\n",
            "epoch: 4      time: 8.92    loss: 184.200    train acc: 0.271    val acc: 0.284\n",
            "saving best model...\n",
            "epoch: 5      time: 8.85    loss: 183.880    train acc: 0.274    val acc: 0.251\n",
            "epoch: 6      time: 8.85    loss: 183.926    train acc: 0.275    val acc: 0.260\n",
            "epoch: 7      time: 8.86    loss: 183.834    train acc: 0.273    val acc: 0.267\n",
            "epoch: 8      time: 8.75    loss: 183.800    train acc: 0.275    val acc: 0.284\n",
            "saving best model...\n",
            "epoch: 9      time: 8.84    loss: 183.586    train acc: 0.281    val acc: 0.246\n",
            "epoch: 10     time: 8.75    loss: 182.985    train acc: 0.285    val acc: 0.298\n",
            "saving best model...\n",
            "epoch: 11     time: 8.87    loss: 182.130    train acc: 0.304    val acc: 0.241\n",
            "epoch: 12     time: 8.82    loss: 180.901    train acc: 0.319    val acc: 0.364\n",
            "saving best model...\n",
            "epoch: 13     time: 8.76    loss: 179.558    train acc: 0.332    val acc: 0.300\n",
            "epoch: 14     time: 8.76    loss: 178.529    train acc: 0.336    val acc: 0.362\n",
            "epoch: 15     time: 8.81    loss: 177.039    train acc: 0.352    val acc: 0.369\n",
            "saving best model...\n",
            "epoch: 16     time: 8.80    loss: 176.209    train acc: 0.356    val acc: 0.371\n",
            "saving best model...\n",
            "epoch: 17     time: 8.81    loss: 174.983    train acc: 0.360    val acc: 0.369\n",
            "epoch: 18     time: 8.83    loss: 174.475    train acc: 0.365    val acc: 0.395\n",
            "saving best model...\n",
            "epoch: 19     time: 8.77    loss: 172.118    train acc: 0.384    val acc: 0.418\n",
            "saving best model...\n",
            "epoch: 20     time: 8.82    loss: 172.368    train acc: 0.383    val acc: 0.409\n",
            "epoch: 21     time: 8.82    loss: 170.298    train acc: 0.394    val acc: 0.433\n",
            "saving best model...\n",
            "epoch: 22     time: 8.77    loss: 169.335    train acc: 0.405    val acc: 0.385\n",
            "epoch: 23     time: 8.83    loss: 168.815    train acc: 0.407    val acc: 0.407\n",
            "epoch: 24     time: 8.72    loss: 166.720    train acc: 0.419    val acc: 0.355\n",
            "epoch: 25     time: 8.86    loss: 165.485    train acc: 0.426    val acc: 0.452\n",
            "saving best model...\n",
            "epoch: 26     time: 8.74    loss: 164.628    train acc: 0.429    val acc: 0.400\n",
            "epoch: 27     time: 8.77    loss: 163.222    train acc: 0.435    val acc: 0.433\n",
            "epoch: 28     time: 8.76    loss: 161.918    train acc: 0.445    val acc: 0.388\n",
            "epoch: 29     time: 8.74    loss: 161.979    train acc: 0.445    val acc: 0.407\n",
            "epoch: 30     time: 8.80    loss: 160.174    train acc: 0.452    val acc: 0.390\n",
            "Augmenting test data...\n",
            "Testing...\n",
            "Testing Accuracy: 0.4289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFnUcUAGCYn0",
        "colab_type": "text"
      },
      "source": [
        "## Bandpass Filter Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73g4VX76HqK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bandpass_filter(X,low,high):\n",
        "  N, C, T = X.shape\n",
        "  out = np.zeros_like(X)\n",
        "  nyq = 125 #nyquist frequency, highest able to be sensed for this data\n",
        "  if high > nyq :\n",
        "    high = nyq\n",
        "  order = 9\n",
        "\n",
        "  b, a = sig.butter(order, [low/nyq,high/nyq], btype='band')\n",
        "  out = sig.lfilter(b, a, X, axis=-1)\n",
        "\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi3kzLexJrNe",
        "colab_type": "text"
      },
      "source": [
        "## Tests with bandpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQp9Waa8O-eN",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwdFsE2LCTC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "outputId": "12c34ba5-2cfe-44fe-b0ef-578f47403978"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 1.0\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data bandpass filtered...\n",
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt applied...\n",
            "fold 1\n",
            "Initial fold shape: (1692, 198, 1000)\n",
            "window applied...\n",
            "Data shape: (27072, 198, 200)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.002\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 10.77    loss: 294.517    train acc: 0.267    val acc: 0.298\n",
            "saving best model...\n",
            "epoch: 2      time: 10.29    loss: 293.576    train acc: 0.268    val acc: 0.274\n",
            "epoch: 3      time: 10.23    loss: 293.399    train acc: 0.272    val acc: 0.312\n",
            "saving best model...\n",
            "epoch: 4      time: 10.30    loss: 292.906    train acc: 0.278    val acc: 0.253\n",
            "epoch: 5      time: 10.26    loss: 292.644    train acc: 0.279    val acc: 0.345\n",
            "saving best model...\n",
            "epoch: 6      time: 10.30    loss: 291.994    train acc: 0.288    val acc: 0.326\n",
            "epoch: 7      time: 10.26    loss: 290.250    train acc: 0.305    val acc: 0.359\n",
            "saving best model...\n",
            "epoch: 8      time: 10.21    loss: 288.586    train acc: 0.319    val acc: 0.326\n",
            "epoch: 9      time: 10.24    loss: 286.751    train acc: 0.326    val acc: 0.392\n",
            "saving best model...\n",
            "epoch: 10     time: 10.34    loss: 285.808    train acc: 0.329    val acc: 0.310\n",
            "epoch: 11     time: 10.41    loss: 284.910    train acc: 0.332    val acc: 0.366\n",
            "epoch: 12     time: 10.35    loss: 283.700    train acc: 0.339    val acc: 0.352\n",
            "epoch: 13     time: 10.44    loss: 282.989    train acc: 0.342    val acc: 0.333\n",
            "epoch: 14     time: 10.41    loss: 280.709    train acc: 0.358    val acc: 0.392\n",
            "saving best model...\n",
            "epoch: 15     time: 10.39    loss: 279.239    train acc: 0.365    val acc: 0.385\n",
            "epoch: 16     time: 10.43    loss: 277.261    train acc: 0.378    val acc: 0.366\n",
            "epoch: 17     time: 10.39    loss: 275.724    train acc: 0.384    val acc: 0.366\n",
            "epoch: 18     time: 10.48    loss: 274.760    train acc: 0.385    val acc: 0.376\n",
            "epoch: 19     time: 10.42    loss: 273.625    train acc: 0.393    val acc: 0.409\n",
            "saving best model...\n",
            "epoch: 20     time: 10.40    loss: 272.456    train acc: 0.395    val acc: 0.392\n",
            "epoch: 21     time: 10.40    loss: 271.046    train acc: 0.400    val acc: 0.416\n",
            "saving best model...\n",
            "epoch: 22     time: 10.39    loss: 270.690    train acc: 0.405    val acc: 0.402\n",
            "epoch: 23     time: 10.38    loss: 268.993    train acc: 0.411    val acc: 0.402\n",
            "epoch: 24     time: 10.40    loss: 268.767    train acc: 0.414    val acc: 0.402\n",
            "epoch: 25     time: 10.44    loss: 267.217    train acc: 0.415    val acc: 0.421\n",
            "saving best model...\n",
            "epoch: 26     time: 10.38    loss: 267.149    train acc: 0.416    val acc: 0.407\n",
            "epoch: 27     time: 10.41    loss: 265.704    train acc: 0.421    val acc: 0.374\n",
            "epoch: 28     time: 10.46    loss: 264.885    train acc: 0.422    val acc: 0.409\n",
            "epoch: 29     time: 10.38    loss: 265.038    train acc: 0.420    val acc: 0.402\n",
            "epoch: 30     time: 10.39    loss: 264.267    train acc: 0.425    val acc: 0.440\n",
            "saving best model...\n",
            "Augmenting test data...\n",
            "Testing...\n",
            "Testing Accuracy: 0.4266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ7xtszgONPW",
        "colab_type": "text"
      },
      "source": [
        "### Test Again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHbuo9WYC8n4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61d09102-9279-42f1-b3af-695d19490cbb"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 10\n",
        "cwt_scale = 2\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 40\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 5\n",
        "band_high = 35\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data bandpass filtered...\n",
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt applied...\n",
            "fold 1\n",
            "Initial fold shape: (1692, 220, 1000)\n",
            "window applied...\n",
            "Data shape: (16920, 220, 250)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.002\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 8.97    loss: 184.912    train acc: 0.261    val acc: 0.267\n",
            "saving best model...\n",
            "epoch: 2      time: 9.11    loss: 184.248    train acc: 0.271    val acc: 0.255\n",
            "epoch: 3      time: 9.13    loss: 183.996    train acc: 0.274    val acc: 0.270\n",
            "saving best model...\n",
            "epoch: 4      time: 9.23    loss: 183.691    train acc: 0.279    val acc: 0.326\n",
            "saving best model...\n",
            "epoch: 5      time: 9.07    loss: 183.678    train acc: 0.279    val acc: 0.310\n",
            "epoch: 6      time: 9.05    loss: 183.656    train acc: 0.279    val acc: 0.274\n",
            "epoch: 7      time: 9.12    loss: 183.515    train acc: 0.286    val acc: 0.284\n",
            "epoch: 8      time: 9.11    loss: 183.245    train acc: 0.287    val acc: 0.300\n",
            "epoch: 9      time: 9.09    loss: 183.267    train acc: 0.284    val acc: 0.267\n",
            "epoch: 10     time: 9.07    loss: 183.146    train acc: 0.291    val acc: 0.350\n",
            "saving best model...\n",
            "epoch: 11     time: 9.28    loss: 183.143    train acc: 0.289    val acc: 0.300\n",
            "epoch: 12     time: 9.12    loss: 182.970    train acc: 0.291    val acc: 0.329\n",
            "epoch: 13     time: 9.08    loss: 182.726    train acc: 0.296    val acc: 0.291\n",
            "epoch: 14     time: 9.13    loss: 182.752    train acc: 0.296    val acc: 0.345\n",
            "epoch: 15     time: 9.11    loss: 181.471    train acc: 0.308    val acc: 0.352\n",
            "saving best model...\n",
            "epoch: 16     time: 9.11    loss: 179.851    train acc: 0.329    val acc: 0.352\n",
            "saving best model...\n",
            "epoch: 17     time: 9.12    loss: 178.325    train acc: 0.342    val acc: 0.345\n",
            "epoch: 18     time: 9.24    loss: 177.497    train acc: 0.345    val acc: 0.350\n",
            "epoch: 19     time: 9.08    loss: 176.861    train acc: 0.350    val acc: 0.357\n",
            "saving best model...\n",
            "epoch: 20     time: 9.16    loss: 175.617    train acc: 0.360    val acc: 0.400\n",
            "saving best model...\n",
            "epoch: 21     time: 9.20    loss: 174.016    train acc: 0.368    val acc: 0.383\n",
            "epoch: 22     time: 9.10    loss: 173.178    train acc: 0.381    val acc: 0.362\n",
            "epoch: 23     time: 9.18    loss: 170.983    train acc: 0.398    val acc: 0.402\n",
            "saving best model...\n",
            "epoch: 24     time: 9.10    loss: 170.092    train acc: 0.403    val acc: 0.383\n",
            "epoch: 25     time: 9.24    loss: 168.077    train acc: 0.411    val acc: 0.390\n",
            "epoch: 26     time: 9.13    loss: 167.536    train acc: 0.415    val acc: 0.409\n",
            "saving best model...\n",
            "epoch: 27     time: 9.11    loss: 165.595    train acc: 0.425    val acc: 0.388\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e2cdb0416dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mEEG_valloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEEG_valset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data prepared, model initialized, beginning training...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainValRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEEG_trainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEEG_valloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvote_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvote_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Augmenting test data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mTrainValRNN\u001b[0;34m(model, criterion, optimizer, trainloader, valloader, num_epochs, verbose, aug_type, window_size, vote_num)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98CEEa5vTHbW",
        "colab_type": "text"
      },
      "source": [
        "### Using weird windowing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZuppYXaOhA3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "a0899b78-f898-43e8-b1cf-3c9918785d5f"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 10\n",
        "cwt_scale = 0.4\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'CNNGRUnet'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt2\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data bandpass filtered...\n",
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt2 applied...\n",
            "fold 1\n",
            "Initial fold shape: (16920, 22, 1000)\n",
            "window applied...\n",
            "Data shape: (169200, 22, 200)\n",
            "RNN TYPE: CNNGRUnet\n",
            "WEIGHT DECAY: 0.001\n",
            "LEARNING RATE: 0.002\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 35.58    loss: 1810.645    train acc: 0.295    val acc: 0.360\n",
            "saving best model...\n",
            "epoch: 2      time: 35.24    loss: 1763.187    train acc: 0.344    val acc: 0.371\n",
            "saving best model...\n",
            "epoch: 3      time: 35.33    loss: 1740.999    train acc: 0.359    val acc: 0.366\n",
            "epoch: 4      time: 35.42    loss: 1686.162    train acc: 0.400    val acc: 0.434\n",
            "saving best model...\n",
            "epoch: 5      time: 35.91    loss: 1654.259    train acc: 0.422    val acc: 0.434\n",
            "saving best model...\n",
            "epoch: 6      time: 35.33    loss: 1634.675    train acc: 0.432    val acc: 0.463\n",
            "saving best model...\n",
            "epoch: 7      time: 35.43    loss: 1622.712    train acc: 0.438    val acc: 0.406\n",
            "epoch: 8      time: 35.22    loss: 1611.245    train acc: 0.443    val acc: 0.479\n",
            "saving best model...\n",
            "epoch: 9      time: 35.00    loss: 1604.458    train acc: 0.446    val acc: 0.422\n",
            "epoch: 10     time: 35.03    loss: 1596.189    train acc: 0.451    val acc: 0.437\n",
            "epoch: 11     time: 35.10    loss: 1591.147    train acc: 0.452    val acc: 0.426\n",
            "epoch: 12     time: 36.44    loss: 1586.155    train acc: 0.454    val acc: 0.446\n",
            "epoch: 13     time: 35.92    loss: 1576.666    train acc: 0.459    val acc: 0.404\n",
            "epoch: 14     time: 36.11    loss: 1577.152    train acc: 0.459    val acc: 0.431\n",
            "epoch: 15     time: 36.22    loss: 1573.529    train acc: 0.458    val acc: 0.457\n",
            "epoch: 16     time: 36.14    loss: 1564.704    train acc: 0.464    val acc: 0.476\n",
            "epoch: 17     time: 36.12    loss: 1558.377    train acc: 0.465    val acc: 0.470\n",
            "epoch: 18     time: 36.28    loss: 1553.711    train acc: 0.469    val acc: 0.445\n",
            "epoch: 19     time: 36.68    loss: 1546.503    train acc: 0.473    val acc: 0.456\n",
            "epoch: 20     time: 35.80    loss: 1538.793    train acc: 0.475    val acc: 0.433\n",
            "Augmenting test data...\n",
            "Testing...\n",
            "Testing Accuracy: 0.3998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deSamYEt9Ltc",
        "colab_type": "text"
      },
      "source": [
        "### Repeating Josh's test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtJS_EoX6oGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "f5470b15-eae0-426a-9bd1-4d434fb1f8de"
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.6\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 0\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt2\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data bandpass filtered...\n",
            "Data normalized...\n",
            "Data shape: (2115, 22, 1000)\n",
            "cwt2 applied...\n",
            "fold 1\n",
            "Initial fold shape: (13536, 22, 1000)\n",
            "window applied...\n",
            "Data shape: (216576, 22, 200)\n",
            "RNN TYPE: GRU\n",
            "WEIGHT DECAY: 0\n",
            "LEARNING RATE: 0.001\n",
            "Data prepared, model initialized, beginning training...\n",
            "epoch: 1      time: 155.23    loss: 2272.804    train acc: 0.330    val acc: 0.423\n",
            "saving best model...\n",
            "epoch: 2      time: 138.31    loss: 2054.214    train acc: 0.451    val acc: 0.467\n",
            "saving best model...\n",
            "epoch: 3      time: 134.66    loss: 1895.706    train acc: 0.512    val acc: 0.428\n",
            "epoch: 4      time: 127.80    loss: 1770.024    train acc: 0.554    val acc: 0.457\n",
            "epoch: 5      time: 138.26    loss: 1668.944    train acc: 0.587    val acc: 0.456\n",
            "epoch: 6      time: 137.77    loss: 1587.056    train acc: 0.611    val acc: 0.474\n",
            "saving best model...\n",
            "epoch: 7      time: 135.07    loss: 1510.500    train acc: 0.635    val acc: 0.457\n",
            "epoch: 8      time: 124.64    loss: 1452.823    train acc: 0.652    val acc: 0.465\n",
            "epoch: 9      time: 137.94    loss: 1404.168    train acc: 0.665    val acc: 0.461\n",
            "epoch: 10     time: 132.91    loss: 1357.798    train acc: 0.678    val acc: 0.440\n",
            "epoch: 11     time: 123.77    loss: 1325.891    train acc: 0.687    val acc: 0.450\n",
            "epoch: 12     time: 138.04    loss: 1290.876    train acc: 0.696    val acc: 0.432\n",
            "epoch: 13     time: 136.87    loss: 1263.912    train acc: 0.703    val acc: 0.450\n",
            "epoch: 14     time: 132.23    loss: 1239.338    train acc: 0.711    val acc: 0.466\n",
            "epoch: 15     time: 124.91    loss: 1216.782    train acc: 0.716    val acc: 0.436\n",
            "epoch: 16     time: 138.29    loss: 1193.690    train acc: 0.721    val acc: 0.444\n",
            "epoch: 17     time: 131.97    loss: 1177.815    train acc: 0.726    val acc: 0.429\n",
            "epoch: 18     time: 125.93    loss: 1158.547    train acc: 0.732    val acc: 0.436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JKb8vCtz6lb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiEhKxsQT3m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}