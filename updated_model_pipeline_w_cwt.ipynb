{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"updated_model_pipeline_w_cwt.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JA1x8mSiTyYL","colab_type":"text"},"source":["### loading modules and data"]},{"cell_type":"code","metadata":{"id":"KQwpQEszAQ9u","colab_type":"code","outputId":"9fadc848-c9f7-43cc-8061-5890b6a532ce","executionInfo":{"status":"ok","timestamp":1584408654791,"user_tz":420,"elapsed":36721,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["########################################################\n","\n","# If running with Google Colab\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g6iA6D4yYwiq","colab_type":"code","outputId":"f15af9ad-cff7-46b0-d37c-359e9f6ab12f","executionInfo":{"status":"ok","timestamp":1584408665427,"user_tz":420,"elapsed":47335,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":216}},"source":["# # If using colab\n","from google.colab import files\n","files.upload()\n","# # select the 3 .py files (models, utils, data_utils)"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-192d7ce7-ce24-4c1d-a0e1-b5ae0daf3be5\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-192d7ce7-ce24-4c1d-a0e1-b5ae0daf3be5\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving data_utils.py to data_utils.py\n","Saving models.py to models.py\n","Saving utils.py to utils.py\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'data_utils.py': b'import numpy as np\\r\\nimport scipy.signal as sig\\r\\nimport pywt\\r\\nfrom torch.utils.data import Dataset, DataLoader\\r\\nimport torch\\r\\n\\r\\n\\'\\'\\'\\r\\nThe customized dataset and data augmentations are defined here.\\r\\n\\r\\n\\'\\'\\'\\r\\nclass EEG_Dataset(Dataset):\\r\\n    \\'\\'\\'\\r\\n    use use fold_idx to instantiate different train val datasets for k-fold cross validation\\r\\n\\r\\n    \\'\\'\\'\\r\\n    def __init__ (self, X_train=None, y_train=None, p_train=None, X_val=None, y_val=None, p_val=None, X_test=None, y_test=None, p_test=None, mode=\\'train\\'):\\r\\n        if mode == \\'train\\':\\r\\n            self.X = X_train\\r\\n            self.y = y_train- 769\\r\\n            self.p = p_train\\r\\n            \\r\\n        elif mode == \\'val\\':\\r\\n            self.X = X_val\\r\\n            self.y = y_val- 769\\r\\n            self.p = p_val\\r\\n\\r\\n        elif mode == \\'test\\':\\r\\n            self.X = X_test\\r\\n            self.y = y_test - 769        \\r\\n            self.p = p_test\\r\\n\\r\\n    def __len__(self):\\r\\n        return (self.X.shape[0])\\r\\n    \\r\\n    def __getitem__(self, idx):\\r\\n        \\'\\'\\'\\r\\n        X: (augmented) time sequence \\r\\n        y: class label\\r\\n        p: person id\\r\\n\\r\\n        \\'\\'\\'\\r\\n        X = torch.from_numpy(self.X[idx,:,:]).float()\\r\\n        y = torch.tensor(self.y[idx]).long()\\r\\n        p = torch.tensor(self.p[idx]).long()\\r\\n        #p = torch.from_numpy(self.p[idx,:]).long()     \\r\\n        sample = {\\'X\\': X, \\'y\\': y, \\'p\\':p}\\r\\n\\r\\n        return sample\\r\\n\\r\\n\\r\\n\\'\\'\\'\\r\\nData Augmentions\\r\\n\\r\\n\\'\\'\\'\\r\\n\\r\\ndef window_data(X, y, p, window_size, stride):\\r\\n  \\'\\'\\'\\r\\n  X (a 3-d tensor) of size (#trials, #electrodes, #time series)\\r\\n  y (#trials,): label \\r\\n  p (#trials, 1): person id\\r\\n\\r\\n  X_new1: The first output stacks the windowed data in a new dimension, resulting \\r\\n    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\\r\\n  X_new2: The second option makes the windows into new trails, resulting in a new\\r\\n    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \\r\\n    for the larger number of trials, we also need to augment the y data.\\r\\n  y_new: The augmented y vector of size (#trials*#windows) to match X_new2.\\r\\n  p_new: The augmented p vector of size (#trials*#windows) to match X_new2\\r\\n \\r\\n  \\'\\'\\'\\r\\n  num_sub_trials = int((X.shape[2]-window_size)/stride)\\r\\n  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\\r\\n  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\\r\\n  y_new = np.empty([X.shape[0]*num_sub_trials])\\r\\n  p_new = np.empty([X.shape[0]*num_sub_trials])\\r\\n  for i in range(X.shape[0]):\\r\\n    for j in range(X.shape[1]):\\r\\n      for k in range(num_sub_trials):\\r\\n        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\\r\\n        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\\r\\n        y_new[i*num_sub_trials+k] = y[i]\\r\\n        p_new[i*num_sub_trials+k] = p[i]\\r\\n  return X_new1, X_new2, y_new, p_new\\r\\n\\r\\n\\r\\ndef stft_data(X, window, stride):\\r\\n    \\'\\'\\'\\r\\n    Inputs:\\r\\n    X - input data, last dimension is one which transform will be taken across.\\r\\n    window - size of sliding window to take transform across\\r\\n    stride - stride of sliding window across time-series\\r\\n\\r\\n    Returns:\\r\\n    X_STFT - Output data, same shape as input with last dimension replaced with two new dimensions, F x T.\\r\\n            where F = window//2 + 1 is the frequency axis\\r\\n            and T = (input_length - window)//stride + 1, similar to the formula for aconvolutional filter.\\r\\n    t - the corresponding times for the time axis, T\\r\\n    f - the corresponding frequencies on the frequency axis, F.\\r\\n\\r\\n    reshape X_STFT (N, C, F, T) to (N, C*F, T) to fit the input of rnn\\r\\n\\r\\n    Note that a smaller window means only higher frequencies may be found, but give finer time resolution.\\r\\n    Conversely, a large window gives better frequency resolution, but poor time resolution.\\r\\n\\r\\n    \\'\\'\\'\\r\\n    noverlap = window-stride\\r\\n    if noverlap < 0 :\\r\\n        print(\\'Stride results in skipped data!\\')\\r\\n        return\\r\\n    f, t, X_STFT = sig.spectrogram(X,nperseg=window,noverlap=noverlap,fs=250, return_onesided=True)\\r\\n    N, C, F, T = X_STFT.shape\\r\\n    X_STFT = X_STFT.reshape(N, C*F, T)\\r\\n    return X_STFT\\r\\n\\r\\n\\r\\ndef cwt_data(X, num_levels, top_scale=3):\\r\\n    \\'\\'\\'\\r\\n    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\\r\\n    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\\r\\n    Appends to the data a new dimension, of size \\'num_levels\\'\\r\\n    New dimension corresponds to wavelet content at num_levels different scalings (linear)\\r\\n    also returns the central frequencies that the scalings correspond to\\r\\n    input data is N x C X T\\r\\n    output data is N x C x T x F\\r\\n    note: CWT is fairly slow to compute\\r\\n\\r\\n    # EXAMPLE USAGE\\r\\n    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\\r\\n    \\'\\'\\'\\r\\n    scales = np.logspace(start=0,stop=top_scale,num=num_levels)\\r\\n    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\\r\\n    for i in range(X.shape[0]):\\r\\n        for j in range(X.shape[1]):\\r\\n            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\\r\\n            out[i,j,:] = coef.T\\r\\n    freqs = pywt.scale2frequency(\\'mexh\\',scales)*250\\r\\n    N, C, T, F = out.shape\\r\\n    X_CWT = np.transpose(out, (0,1,3,2)).reshape(N, C*F, T)\\r\\n    return X_CWT\\r\\n\\r\\n\\r\\ndef cwt_data2(X, y, p, num_levels, bottom_scale = 0.1, top_scale=0.4):\\r\\n    \\'\\'\\'\\r\\n    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\\r\\n    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\\r\\n    Appends to the data a new dimension, of size \\'num_levels\\'\\r\\n    New dimension corresponds to wavelet content at num_levels different scalings (linear)\\r\\n    also returns the central frequencies that the scalings correspond to\\r\\n    input data is N x C X T\\r\\n    output data is N x C x T x F\\r\\n    note: CWT is fairly slow to compute\\r\\n\\r\\n    # EXAMPLE USAGE\\r\\n    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\\r\\n    \\'\\'\\'\\r\\n    scales = np.logspace(start=bottom_scale,stop=top_scale,num=num_levels)\\r\\n    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\\r\\n    for i in range(X.shape[0]):\\r\\n        for j in range(X.shape[1]):\\r\\n            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\\r\\n            out[i,j,:] = coef.T\\r\\n    freqs = pywt.scale2frequency(\\'mexh\\',scales)*250\\r\\n    N, C, T, F = out.shape\\r\\n    X_cwt = np.transpose(out, (0,3,1,2)).reshape(N*F, C, T)\\r\\n    y_cwt = np.empty([X.shape[0]*F])\\r\\n    p_cwt = np.empty([X.shape[0]*F])\\r\\n    for i in range(X.shape[0]):\\r\\n      for k in range(F):\\r\\n        y_cwt[i*F+k] = y[i]\\r\\n        p_cwt[i*F+k] = p[i]\\r\\n    return X_cwt, y_cwt, p_cwt\\r\\n\\r\\n\\r\\ndef Aug_Data(X, y, p, aug_type=None, window_size=200, window_stride=20, stft_size=None, stft_stride=None, cwt_level=None, cwt_scale=None):\\r\\n    if aug_type == None:\\r\\n        X_aug, y_aug, p_aug = X, y, p\\r\\n    elif aug_type == \"window\":\\r\\n        _, X_aug, y_aug, p_aug = window_data(X, y, p, window_size, window_stride)\\r\\n    elif aug_type == \"stft\":\\r\\n        X_aug = stft_data(X, stft_size, stft_stride)\\r\\n        y_aug, p_aug = y, p\\r\\n    elif aug_type == \\'cwt\\':\\r\\n        X_aug = cwt_data(X, cwt_level, cwt_scale)\\r\\n        y_aug, p_aug = y, p\\r\\n    return X_aug, y_aug, p_aug\\r\\n\\r\\n\\'\\'\\'\\r\\nSplit training and validation\\r\\n\\r\\n\\'\\'\\'\\r\\n\\r\\ndef Train_Val_Data(X_train_valid, y_train_val):\\r\\n    \\'\\'\\'\\r\\n    split the train_valid into k folds (we fix k = 5 here)\\r\\n    return: list of index of train data and val data of k folds\\r\\n    train_fold[i], val_fold[i] is the index for training and validation in the i-th fold \\r\\n\\r\\n    \\'\\'\\'\\r\\n    fold_idx = []\\r\\n    train_fold = []\\r\\n    val_fold = []\\r\\n    train_val_num = X_train_valid.shape[0]\\r\\n    fold_num = int(train_val_num / 5)\\r\\n    perm = np.random.permutation(train_val_num)\\r\\n    for k in range(5):\\r\\n        fold_idx.append(np.arange(k*fold_num, (k+1)*fold_num, 1))\\r\\n    for k in range(5):\\r\\n        val_fold.append(fold_idx[k])\\r\\n        count = 0\\r\\n        for i in range(5):\\r\\n            if i != k:\\r\\n                if count == 0:\\r\\n                    train_idx = fold_idx[i]\\r\\n                else:\\r\\n                    train_idx = np.concatenate((train_idx, fold_idx[i]))\\r\\n                count += 1\\r\\n        train_fold.append(train_idx)\\r\\n\\r\\n    return train_fold, val_fold',\n"," 'models.py': b\"import numpy as np\\r\\nimport torch\\r\\nimport torch.nn as nn\\r\\n\\r\\n'''\\r\\nAdd your new models here as a new class\\r\\n\\r\\n'''\\r\\n\\r\\nclass LSTMnet(nn.Module):\\r\\n    '''\\r\\n    Create Basic LSTM:\\r\\n    2 layers\\r\\n\\r\\n    '''\\r\\n    def __init__(self, input_size, hidden_size, output_dim, dropout):\\r\\n        super(LSTMnet, self).__init__()\\r\\n        self.input_size = input_size\\r\\n        self.hidden_size = hidden_size\\r\\n        self.output_dim = output_dim\\r\\n        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\\r\\n        self.fc = nn.Linear(hidden_size, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        x = x.permute(2, 0, 1)\\r\\n        if type(h) == type(None):\\r\\n            out, hn = self.rnn(x)\\r\\n        else:\\r\\n            out, hn = self.rnn(x, h.detach())\\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n\\r\\n\\r\\nclass ThreeLayerLSTMnet(nn.Module):\\r\\n    '''\\r\\n    Create Basic LSTM:\\r\\n    3 layers\\r\\n\\r\\n    '''\\r\\n    def __init__(self, input_size, hidden_size, output_dim, dropout):\\r\\n        super(ThreeLayerLSTMnet, self).__init__()\\r\\n        self.input_size = input_size\\r\\n        self.hidden_size = hidden_size\\r\\n        self.output_dim = output_dim\\r\\n        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=5, dropout=dropout)\\r\\n        self.fc = nn.Linear(hidden_size, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        x = x.permute(2, 0, 1)\\r\\n        if type(h) == type(None):\\r\\n            out, hn = self.rnn(x)\\r\\n        else:\\r\\n            out, hn = self.rnn(x, h.detach())\\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n\\r\\n\\r\\nclass FiveLayerLSTMnet(nn.Module):\\r\\n    '''\\r\\n    Create Basic LSTM:\\r\\n    5 layers\\r\\n\\r\\n    '''\\r\\n    def __init__(self, input_size, hidden_size, output_dim, dropout):\\r\\n        super(FiveLayerLSTMnet, self).__init__()\\r\\n        self.input_size = input_size\\r\\n        self.hidden_size = hidden_size\\r\\n        self.output_dim = output_dim\\r\\n        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=5, dropout=dropout)\\r\\n        self.fc = nn.Linear(hidden_size, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        x = x.permute(2, 0, 1)\\r\\n        if type(h) == type(None):\\r\\n            out, hn = self.rnn(x)\\r\\n        else:\\r\\n            out, hn = self.rnn(x, h.detach())\\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n\\r\\n\\r\\nclass CNNLSTMnet(nn.Module):\\r\\n    '''\\r\\n    CNN + LSTM\\r\\n    \\r\\n    '''\\r\\n    def __init__(self, cnn_input_size, rnn_input_size, hidden_size, output_dim, dropout):\\r\\n        super(CNNLSTMnet, self).__init__()\\r\\n        self.cnn_input_size = cnn_input_size\\r\\n        self.rnn_input_size = rnn_input_size\\r\\n        self.hidden_size = hidden_size\\r\\n        self.output_dim = output_dim\\r\\n        self.cnn = nn.Sequential(\\r\\n            nn.Conv1d(cnn_input_size, rnn_input_size, kernel_size=10, stride=2),\\r\\n            nn.BatchNorm1d(rnn_input_size),\\r\\n            nn.ReLU(),\\r\\n        )\\r\\n        self.rnn = nn.LSTM(input_size=rnn_input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\\r\\n        self.fc = nn.Linear(hidden_size, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        out = self.cnn(x)\\r\\n        out = out.permute(2,0,1)\\r\\n        if type(h) == type(None):\\r\\n            out, hn = self.rnn(out)\\r\\n        else:\\r\\n            out, hn = self.rnn(out, h.detach())\\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n\\r\\n\\r\\nclass GRUnet(nn.Module):\\r\\n    '''\\r\\n    Create Basic GRU:\\r\\n    2 layers\\r\\n    \\r\\n    '''\\r\\n    def __init__(self, input_size, hidden_size, output_dim, dropout):\\r\\n        super(GRUnet, self).__init__()\\r\\n        self.input_size = input_size\\r\\n        self.hidden_size = hidden_size\\r\\n        self.output_dim = output_dim\\r\\n        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\\r\\n        self.fc = nn.Linear(hidden_size, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        x = x.permute(2, 0, 1)\\r\\n        if type(h) == type(None):\\r\\n            out, hn = self.rnn(x)\\r\\n        else:\\r\\n            out, hn = self.rnn(x, h.detach())\\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n        \\r\\n\\r\\nclass GRU2HiddenDimsnet(nn.Module):\\r\\n    '''\\r\\n    Create Basic GRU:\\r\\n    2 layers (hidden dims=hidden_dims, 2)\\r\\n    \\r\\n    '''\\r\\n    def __init__(self, input_size, hidden_size, output_dim, dropout):\\r\\n        super(GRU2HiddenDimsnet, self).__init__()\\r\\n        self.input_size = input_size\\r\\n        self.hidden_size = hidden_size\\r\\n        self.output_dim = output_dim\\r\\n        self.rnn1 = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=1, dropout=dropout)\\r\\n        self.rnn2 = nn.GRU(input_size=hidden_size, hidden_size=25, num_layers=1, dropout=dropout)\\r\\n        self.fc = nn.Linear(25, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        x = x.permute(2, 0, 1)\\r\\n        out, hn = self.rnn1(x)\\r\\n        out, hn = self.rnn2(out)\\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n\\r\\n\\r\\nclass ThreeLayerGRUnet(nn.Module):\\r\\n    '''\\r\\n    Create Basic GRU:\\r\\n    3 layers\\r\\n    \\r\\n    '''\\r\\n    def __init__(self, input_size, hidden_size, output_dim, dropout):\\r\\n        super(ThreeLayerGRUnet, self).__init__()\\r\\n        self.input_size = input_size\\r\\n        self.hidden_size = hidden_size\\r\\n        self.output_dim = output_dim\\r\\n        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=3, dropout=dropout)\\r\\n        self.fc = nn.Linear(hidden_size, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        x = x.permute(2, 0, 1)\\r\\n        if type(h) == type(None):\\r\\n            out, hn = self.rnn(x)\\r\\n        else:\\r\\n            out, hn = self.rnn(x, h.detach())\\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n\\r\\n\\r\\nclass CNNGRUnet(nn.Module):\\r\\n    '''\\r\\n    CNN + GRU\\r\\n    \\r\\n    '''\\r\\n    def __init__(self, cnn_input_size, rnn_input_size, hidden_size, output_dim, dropout):\\r\\n        super(CNNGRUnet, self).__init__()\\r\\n        self.cnn_input_size = cnn_input_size\\r\\n        self.rnn_input_size = rnn_input_size\\r\\n        self.hidden_size = hidden_size\\r\\n        self.output_dim = output_dim\\r\\n        self.cnn = nn.Sequential(\\r\\n            nn.Conv1d(cnn_input_size, rnn_input_size, kernel_size=10, stride=2),\\r\\n            nn.BatchNorm1d(rnn_input_size),\\r\\n            nn.ReLU(),\\r\\n        )\\r\\n        self.rnn = nn.GRU(input_size=rnn_input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\\r\\n        self.fc = nn.Linear(hidden_size, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        out = self.cnn(x)\\r\\n        out = out.permute(2,0,1)\\r\\n        if type(h) == type(None):\\r\\n            out, hn = self.rnn(out)\\r\\n        else:\\r\\n            out, hn = self.rnn(out, h.detach())\\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n\\r\\n\\r\\nclass CNN2LSTM(nn.Module):\\r\\n    '''\\r\\n    CNN1 + LSTM1 + CNN2 + LSTM2\\r\\n    \\r\\n    '''\\r\\n    def __init__(self, cnn1_input_size, rnn1_input_size, hidden_size1, rnn2_input_size, hidden_size2, output_dim, dropout):\\r\\n        super(CNN2LSTM, self).__init__()\\r\\n        self.cnn1_input_size = cnn1_input_size\\r\\n        self.rnn1_input_size = rnn1_input_size\\r\\n        self.rnn2_input_size = rnn2_input_size\\r\\n        self.hidden_size1 = hidden_size1\\r\\n        self.hidden_size2 = hidden_size2\\r\\n        self.output_dim = output_dim\\r\\n        self.cnn1 = nn.Sequential(\\r\\n            nn.Conv1d(cnn1_input_size, rnn1_input_size, kernel_size=10, stride=2),\\r\\n            nn.BatchNorm1d(rnn1_input_size),\\r\\n            nn.ReLU(),\\r\\n        )\\r\\n        self.rnn1 = nn.LSTM(input_size=rnn1_input_size, hidden_size=hidden_size1, num_layers=1, dropout=dropout)\\r\\n        self.cnn2 = nn.Sequential(\\r\\n            nn.Conv1d(hidden_size1, rnn2_input_size, kernel_size=10, stride=2),\\r\\n            nn.BatchNorm1d(rnn2_input_size),\\r\\n            nn.ReLU(),\\r\\n        )\\r\\n        self.rnn2 = nn.LSTM(input_size=rnn2_input_size, hidden_size=hidden_size2, num_layers=1, dropout=dropout)\\r\\n        self.fc = nn.Linear(hidden_size2, output_dim)\\r\\n    \\r\\n    def forward(self, x, h=None):\\r\\n        out = self.cnn1(x)\\r\\n        out = out.permute(2,0,1)\\r\\n        out, hn = self.rnn1(out)      \\r\\n        out = out.permute(1, 2, 0)        \\r\\n        out = self.cnn2(out)\\r\\n        out = out.permute(2,0,1)\\r\\n        out, hn = self.rnn2(out) \\r\\n        out = self.fc(out[-1, :, :])\\r\\n        return out\\r\\n\\r\\n\\r\\n# TODO: Fix these \\r\\n# class CNN2GRUnet(nn.Module):\\r\\n#     '''\\r\\n#     2 x CNN + GRU\\r\\n    \\r\\n#     '''\\r\\n#     def __init__(self, cnn_input_size, rnn_input_size, hidden_size, output_dim, dropout):\\r\\n#         super(CNNGRUnet, self).__init__()\\r\\n#         self.cnn_input_size = cnn_input_size\\r\\n#         self.rnn_input_size = rnn_input_size\\r\\n#         self.hidden_size = hidden_size\\r\\n#         self.output_dim = output_dim\\r\\n#         self.cnn = nn.Sequential(\\r\\n#             nn.Conv1d(cnn_input_size, rnn_input_size, kernel_size=10, stride=2),\\r\\n#             nn.BatchNorm1d(rnn_input_size),\\r\\n#             nn.ReLU(),\\r\\n#         )\\r\\n#         self.rnn = nn.GRU(input_size=rnn_input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\\r\\n#         self.fc = nn.Linear(hidden_size, output_dim)\\r\\n    \\r\\n#     def forward(self, x, h=None):\\r\\n#         out = self.cnn(x)\\r\\n#         out = out.permute(2,0,1)\\r\\n#         if type(h) == type(None):\\r\\n#             out, hn = self.rnn(out)\\r\\n#         else:\\r\\n#             out, hn = self.rnn(out, h.detach())\\r\\n#         out = self.fc(out[-1, :, :])\\r\\n#         return out\",\n"," 'utils.py': b'import numpy as np\\r\\nimport torch\\r\\nimport time\\r\\nfrom models import *\\r\\nfrom data_utils import *\\r\\n\\r\\nis_cuda = torch.cuda.is_available()\\r\\nif is_cuda:\\r\\n    device = torch.device(\"cuda\")\\r\\n    # device = torch.device(\"cuda:1\") # For Yiming \\r\\n    print(\"GPU is available\")\\r\\nelse:\\r\\n    device = torch.device(\"cpu\")\\r\\n    print(\"GPU not available, CPU used\")\\r\\n\\r\\n\\r\\ndef InitRNN(rnn_type=\"LSTM\", input_size=22, rnn_input_size=40, hidden_size=50, rnn2_input_size=25, hidden_size2=20, output_dim=4, dropout=0.5, lr=1e-3, weight_decay=1e-4):\\r\\n    \\'\\'\\'\\r\\n    Function to initialize RNN\\r\\n    \\r\\n    input: RNN type(LSTM, GRU, CNNLSTM), and other params if neccessary (regularization, acitvation, dropout, num layers, etc.)\\r\\n\\r\\n    output: model, criterion, optimizer\\r\\n\\r\\n    TODO: Eventually should also take in params such as dropout, number of layers, and activation function(s), etc.\\r\\n    \\'\\'\\'\\r\\n\\r\\n    print(\"RNN TYPE: {}\".format(rnn_type))\\r\\n    print(\"WEIGHT DECAY: {}\".format(weight_decay))\\r\\n    print(\"LEARNING RATE: {}\".format(lr))\\r\\n\\r\\n    if rnn_type==\"LSTM\":\\r\\n        model = LSTMnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\\r\\n\\r\\n    elif rnn_type==\"ThreeLayerLSTMnet\":\\r\\n        model = ThreeLayerLSTMnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\\r\\n\\r\\n    elif rnn_type==\"FiveLayerLSTMnet\":\\r\\n        model = FiveLayerLSTMnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\\r\\n\\r\\n    elif rnn_type==\"GRU\":\\r\\n        model = GRUnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\\r\\n  \\r\\n    elif rnn_type==\"GRU2HiddenDimsnet\":\\r\\n        model = GRU2HiddenDimsnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\\r\\n  \\r\\n    elif rnn_type==\"ThreeLayerGRUnet\":\\r\\n        model = ThreeLayerGRUnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\\r\\n    \\r\\n    elif rnn_type==\"CNNLSTM\":\\r\\n        model = CNNLSTMnet(cnn_input_size=input_size, rnn_input_size=rnn_input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\\r\\n\\r\\n    elif rnn_type==\"CNNGRUnet\":\\r\\n        model = CNNGRUnet(cnn_input_size=input_size, rnn_input_size=rnn_input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\\r\\n\\r\\n    elif rnn_type==\"CNN2LSTM\":\\r\\n        model = CNN2LSTM(cnn1_input_size=input_size, rnn1_input_size=rnn_input_size, hidden_size1=hidden_size, rnn2_input_size=rnn2_input_size, hidden_size2=hidden_size2, output_dim=output_dim, dropout=dropout).to(device)\\r\\n\\r\\n    criterion = nn.CrossEntropyLoss()\\r\\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\\r\\n\\r\\n    return model, criterion, optimizer\\r\\n\\r\\n\\r\\ndef TrainValRNN(model, criterion, optimizer, trainloader, valloader=None, num_epochs=15, verbose=True, aug_type=None, window_size=None, vote_num=None):\\r\\n    val_acc_list = []\\r\\n    best_val_acc = 0.0\\r\\n    for ep in range(num_epochs):\\r\\n        tstart = time.time()\\r\\n        running_loss = 0.0\\r\\n        correct, total = 0, 0\\r\\n        for idx, batch in enumerate(trainloader):\\r\\n            optimizer.zero_grad()\\r\\n            X = batch[\\'X\\'].to(device)\\r\\n            y = batch[\\'y\\'].to(device)\\r\\n            output = model(X)\\r\\n            loss = criterion(output, y)\\r\\n            running_loss += loss.item()\\r\\n            loss.backward()\\r\\n            optimizer.step()\\r\\n            pred = torch.argmax(output, dim=1)\\r\\n            correct += torch.sum(pred == y).item()\\r\\n            total += y.shape[0]\\r\\n        train_acc = correct / total\\r\\n        train_loss = running_loss\\r\\n        \\'\\'\\'\\r\\n        The validation need to be customized according to the data augmenation type\\r\\n        for stft and cwt: they didn\\'t increase the number of trials, we can directly pass the augmented data to the model\\r\\n        for window: it increase the number of trials, we need to do a voting for different subsequences in one trial\\r\\n        \\r\\n        \\'\\'\\'\\r\\n        if aug_type == \\'window\\':\\r\\n            correct, total = 0, 0\\r\\n            for idx, batch in enumerate(valloader):\\r\\n                #X = batch[\\'X\\'].permute(2, 0, 1).to(device)\\r\\n                X = batch[\\'X\\'].to(device)\\r\\n                y = batch[\\'y\\'].to(device)\\r\\n                vote_idx = np.random.choice(1000-window_size, vote_num)\\r\\n                vote_pred = np.zeros(y.shape[0])\\r\\n                for i in range(len(vote_idx)):\\r\\n                    X_sub = X[:,:,vote_idx[i]:vote_idx[i]+window_size]\\r\\n                    output = model(X_sub)\\r\\n                    pred = torch.argmax(output, dim=1)\\r\\n                    if i == 0:\\r\\n                        vote_matrix = np.asarray(pred.cpu().view(-1, 1))\\r\\n                    else:\\r\\n                        vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\\r\\n                for row in range(y.shape[0]):\\r\\n                    vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\\r\\n                vote_pred = torch.from_numpy(vote_pred).long()\\r\\n                correct += torch.sum(vote_pred == y.cpu()).item()\\r\\n                total += y.shape[0]\\r\\n            val_acc = correct / total        \\r\\n        else:\\r\\n            correct, total = 0, 0\\r\\n            for idx, batch in enumerate(valloader):\\r\\n                X = batch[\\'X\\'].to(device)\\r\\n                y = batch[\\'y\\'].to(device)\\r\\n                output = model(X)                    \\r\\n                pred = torch.argmax(output, dim=1)\\r\\n                correct += torch.sum(pred == y.cpu()).item()\\r\\n                total += y.shape[0]\\r\\n            val_acc = correct / total\\r\\n        tend = time.time()\\r\\n        if verbose:\\r\\n            print(\\'epoch: {:<3d}    time: {:<3.2f}    loss: {:<3.3f}    train acc: {:<1.3f}    val acc: {:<1.3f}\\'.format(ep+1, tend - tstart, train_loss, train_acc, val_acc))\\r\\n        if val_acc >= best_val_acc:\\r\\n            best_val_acc = val_acc\\r\\n            best_model = model\\r\\n            print (\\'saving best model...\\')\\r\\n    return best_model\\r\\n\\r\\ndef TestRNN(model, X_test, y_test, p_test, aug_type=None, window_size=None, vote_num=None):\\r\\n    if aug_type == \\'window\\':\\r\\n        EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode=\\'test\\')\\r\\n        EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\\r\\n        correct, total = 0, 0\\r\\n        for idx, batch in enumerate(EEG_testloader):\\r\\n            X = batch[\\'X\\'].to(device)\\r\\n            y = batch[\\'y\\'].to(device)\\r\\n            vote_idx = np.random.choice(1000-window_size, vote_num)\\r\\n            vote_pred = np.zeros(y.shape[0])\\r\\n            for i in range(len(vote_idx)):\\r\\n                X_sub = X[:,:,vote_idx[i]:vote_idx[i]+window_size]\\r\\n                output = model(X_sub)\\r\\n                pred = torch.argmax(output, dim=1)\\r\\n                if i == 0:\\r\\n                    vote_matrix = np.asarray(pred.cpu().view(-1, 1))\\r\\n                else:\\r\\n                    vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\\r\\n                for row in range(y.shape[0]):\\r\\n                    vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\\r\\n            vote_pred = torch.from_numpy(vote_pred).long()\\r\\n            correct += torch.sum(vote_pred == y.cpu()).item()\\r\\n            total += y.shape[0]\\r\\n        test_acc = correct / total \\r\\n    else:\\r\\n        X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test, aug_type=aug_type)\\r\\n        EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode=\\'test\\')\\r\\n        EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\\r\\n        for idx, batch in enumerate(EEG_testloader):\\r\\n            X = batch[\\'X\\'].to(device)\\r\\n            y = batch[\\'y\\'].to(device)\\r\\n            output = model(X)                    \\r\\n            pred = torch.argmax(output, dim=1)\\r\\n            correct += torch.sum(pred == y.cpu()).item()\\r\\n            total += y.shape[0]\\r\\n        test_acc = correct / total\\r\\n    print (\\'Testing Accuracy: {:.4f}\\'.format(test_acc))'}"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"E-S67grVAoSt","colab_type":"code","outputId":"98a6133d-074d-49f6-da62-1ec9abcc345b","executionInfo":{"status":"ok","timestamp":1584408667003,"user_tz":420,"elapsed":48891,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":138}},"source":["########################################################\n","\n","# If running with Google Colab\n","# Create a folder \"C247\" and then store the project datasets within that folder\n","# Check that your datasets are setup correctly\n","\n","!ls \"/content/gdrive/My Drive/C247\" # File path"],"execution_count":3,"outputs":[{"output_type":"stream","text":["cwt_into_window_tests\t__pycache__\t     X_train_ICA10.npy\n","Eden_tests1.ipynb\tX_test_filtered.npy  X_train_ICA15.npy\n","Eden_tests2.ipynb\tX_test_ICA10.npy     X_train_ICA5.npy\n","EEG_loading.ipynb\tX_test_ICA15.npy     X_train_ICA.npy\n","FinalProject\t\tX_test_ICA5.npy      X_train_valid.npy\n","person_test.npy\t\tX_test_ICA.npy\t     y_test.npy\n","person_train_valid.npy\tX_test.npy\t     y_train_valid.npy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-jkt1ZNZWIhi","colab_type":"code","outputId":"a4fae16b-3133-45de-b4f7-063741dd3962","executionInfo":{"status":"ok","timestamp":1584408670438,"user_tz":420,"elapsed":52308,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from models import *\n","from utils import *\n","from data_utils import *"],"execution_count":4,"outputs":[{"output_type":"stream","text":["GPU is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TJfyBLNLA686","colab_type":"code","outputId":"003cb280-dc38-4946-b5af-bb1c079ab0ce","executionInfo":{"status":"ok","timestamp":1584408675929,"user_tz":420,"elapsed":57777,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["# X_test = np.load(\"X_test.npy\")\n","# y_test = np.load(\"y_test.npy\")\n","# person_train_valid = np.load(\"person_train_valid.npy\")\n","# X_train_valid = np.load(\"X_train_valid.npy\")\n","# y_train_valid = np.load(\"y_train_valid.npy\")\n","# person_test = np.load(\"person_test.npy\")\n","\n","# Change if your directory is different\n","\n","# dataset_path = './data/' # Yiming Path\n","dataset_path = \"/content/gdrive/My Drive/C247/\" \n","\n","X_test = np.load(dataset_path + \"X_test.npy\")\n","y_test = np.load(dataset_path + \"y_test.npy\")\n","person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n","X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n","y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n","person_test = np.load(dataset_path + \"person_test.npy\")\n","print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n","print ('Test data shape: {}'.format(X_test.shape))\n","print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n","print ('Test target shape: {}'.format(y_test.shape))\n","print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n","print ('Person test shape: {}'.format(person_test.shape))\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Training/Valid data shape: (2115, 22, 1000)\n","Test data shape: (443, 22, 1000)\n","Training/Valid target shape: (2115,)\n","Test target shape: (443,)\n","Person train/valid shape: (2115, 1)\n","Person test shape: (443, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"90IvaY2LTyY1","colab_type":"text"},"source":["### CWT 0.1 & 0.4"]},{"cell_type":"code","metadata":{"id":"I-zWZCDHkcKF","colab_type":"code","outputId":"d9205839-bf53-47f6-9528-25211600a850","executionInfo":{"status":"ok","timestamp":1584308698609,"user_tz":420,"elapsed":58832,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.4\n","bottom_scale = 0.1\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"nmJd_5kbTyY2","colab_type":"code","outputId":"0831933f-5f86-4ee9-ce5d-a53fcaf82d3c","executionInfo":{"status":"ok","timestamp":1584310350976,"user_tz":420,"elapsed":1674919,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 31.88    loss: 1473.324    train acc: 0.253    val acc: 0.258\n","saving best model...\n","epoch: 2      time: 31.29    loss: 1466.368    train acc: 0.262    val acc: 0.283\n","saving best model...\n","epoch: 3      time: 31.58    loss: 1464.054    train acc: 0.269    val acc: 0.292\n","saving best model...\n","epoch: 4      time: 31.36    loss: 1461.840    train acc: 0.275    val acc: 0.310\n","saving best model...\n","epoch: 5      time: 31.48    loss: 1458.624    train acc: 0.283    val acc: 0.284\n","epoch: 6      time: 31.57    loss: 1455.232    train acc: 0.289    val acc: 0.316\n","saving best model...\n","epoch: 7      time: 31.70    loss: 1448.788    train acc: 0.300    val acc: 0.355\n","saving best model...\n","epoch: 8      time: 31.85    loss: 1439.505    train acc: 0.316    val acc: 0.346\n","epoch: 9      time: 31.98    loss: 1431.071    train acc: 0.326    val acc: 0.359\n","saving best model...\n","epoch: 10     time: 32.34    loss: 1421.392    train acc: 0.336    val acc: 0.385\n","saving best model...\n","epoch: 11     time: 32.43    loss: 1411.514    train acc: 0.344    val acc: 0.346\n","epoch: 12     time: 32.67    loss: 1401.915    train acc: 0.351    val acc: 0.372\n","epoch: 13     time: 32.71    loss: 1390.255    train acc: 0.360    val acc: 0.370\n","epoch: 14     time: 32.54    loss: 1377.800    train acc: 0.369    val acc: 0.375\n","epoch: 15     time: 32.70    loss: 1366.291    train acc: 0.377    val acc: 0.384\n","epoch: 16     time: 32.88    loss: 1355.086    train acc: 0.386    val acc: 0.397\n","saving best model...\n","epoch: 17     time: 33.06    loss: 1341.803    train acc: 0.399    val acc: 0.413\n","saving best model...\n","epoch: 18     time: 32.88    loss: 1328.040    train acc: 0.410    val acc: 0.421\n","saving best model...\n","epoch: 19     time: 33.20    loss: 1313.865    train acc: 0.421    val acc: 0.447\n","saving best model...\n","epoch: 20     time: 33.12    loss: 1300.719    train acc: 0.430    val acc: 0.439\n","epoch: 21     time: 33.10    loss: 1288.840    train acc: 0.437    val acc: 0.438\n","epoch: 22     time: 33.27    loss: 1277.882    train acc: 0.443    val acc: 0.443\n","epoch: 23     time: 33.36    loss: 1267.108    train acc: 0.449    val acc: 0.470\n","saving best model...\n","epoch: 24     time: 32.97    loss: 1258.181    train acc: 0.458    val acc: 0.435\n","epoch: 25     time: 32.93    loss: 1249.257    train acc: 0.461    val acc: 0.445\n","epoch: 26     time: 33.05    loss: 1239.559    train acc: 0.468    val acc: 0.435\n","epoch: 27     time: 33.04    loss: 1230.964    train acc: 0.473    val acc: 0.473\n","saving best model...\n","epoch: 28     time: 32.93    loss: 1223.593    train acc: 0.478    val acc: 0.474\n","saving best model...\n","epoch: 29     time: 33.00    loss: 1217.109    train acc: 0.482    val acc: 0.465\n","epoch: 30     time: 32.82    loss: 1209.255    train acc: 0.486    val acc: 0.458\n","epoch: 31     time: 32.75    loss: 1202.472    train acc: 0.491    val acc: 0.465\n","epoch: 32     time: 32.78    loss: 1195.669    train acc: 0.495    val acc: 0.480\n","saving best model...\n","epoch: 33     time: 32.85    loss: 1187.427    train acc: 0.498    val acc: 0.463\n","epoch: 34     time: 32.79    loss: 1180.828    train acc: 0.502    val acc: 0.464\n","epoch: 35     time: 32.68    loss: 1174.716    train acc: 0.506    val acc: 0.470\n","epoch: 36     time: 32.90    loss: 1167.423    train acc: 0.510    val acc: 0.452\n","epoch: 37     time: 32.93    loss: 1162.835    train acc: 0.512    val acc: 0.465\n","epoch: 38     time: 32.82    loss: 1155.057    train acc: 0.516    val acc: 0.457\n","epoch: 39     time: 32.89    loss: 1151.221    train acc: 0.520    val acc: 0.467\n","epoch: 40     time: 32.83    loss: 1143.603    train acc: 0.523    val acc: 0.463\n","epoch: 41     time: 33.15    loss: 1136.730    train acc: 0.525    val acc: 0.465\n","epoch: 42     time: 33.26    loss: 1131.678    train acc: 0.527    val acc: 0.473\n","epoch: 43     time: 33.21    loss: 1126.382    train acc: 0.530    val acc: 0.466\n","epoch: 44     time: 32.84    loss: 1121.707    train acc: 0.532    val acc: 0.476\n","epoch: 45     time: 32.57    loss: 1114.772    train acc: 0.536    val acc: 0.458\n","epoch: 46     time: 32.97    loss: 1108.567    train acc: 0.540    val acc: 0.459\n","epoch: 47     time: 33.02    loss: 1104.098    train acc: 0.542    val acc: 0.460\n","epoch: 48     time: 33.10    loss: 1098.782    train acc: 0.546    val acc: 0.473\n","epoch: 49     time: 32.80    loss: 1094.044    train acc: 0.547    val acc: 0.457\n","epoch: 50     time: 32.81    loss: 1087.721    train acc: 0.550    val acc: 0.457\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5yGSJZ62TyY7","colab_type":"text"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"id":"PT9IdrogTyY9","colab_type":"code","outputId":"b6d9a4e8-a23b-45f6-c2e3-d2102f51a16a","executionInfo":{"status":"ok","timestamp":1584310361869,"user_tz":420,"elapsed":1649016,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.5228\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"R03V4zge17cO"},"source":["### CWT 0 & 0.4"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"2d2583ff-0eba-4711-905c-080b3cc1aeca","executionInfo":{"status":"ok","timestamp":1584310381401,"user_tz":420,"elapsed":1663506,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"Ma67zszM17cU","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.4\n","bottom_scale = 0\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"b7a52875-f17a-4c3c-e355-92416b3d87ab","id":"V_3F_ND517cX","executionInfo":{"status":"ok","timestamp":1584312025691,"user_tz":420,"elapsed":3305910,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 32.41    loss: 1472.372    train acc: 0.253    val acc: 0.237\n","saving best model...\n","epoch: 2      time: 32.57    loss: 1466.791    train acc: 0.263    val acc: 0.278\n","saving best model...\n","epoch: 3      time: 32.59    loss: 1465.286    train acc: 0.266    val acc: 0.278\n","epoch: 4      time: 32.52    loss: 1463.403    train acc: 0.272    val acc: 0.284\n","saving best model...\n","epoch: 5      time: 32.59    loss: 1461.749    train acc: 0.277    val acc: 0.283\n","epoch: 6      time: 32.46    loss: 1460.383    train acc: 0.280    val acc: 0.271\n","epoch: 7      time: 32.52    loss: 1457.075    train acc: 0.287    val acc: 0.305\n","saving best model...\n","epoch: 8      time: 32.60    loss: 1452.549    train acc: 0.295    val acc: 0.344\n","saving best model...\n","epoch: 9      time: 32.91    loss: 1444.215    train acc: 0.309    val acc: 0.351\n","saving best model...\n","epoch: 10     time: 32.88    loss: 1436.817    train acc: 0.319    val acc: 0.351\n","epoch: 11     time: 32.94    loss: 1430.180    train acc: 0.328    val acc: 0.335\n","epoch: 12     time: 32.94    loss: 1424.292    train acc: 0.332    val acc: 0.355\n","saving best model...\n","epoch: 13     time: 32.99    loss: 1412.061    train acc: 0.345    val acc: 0.349\n","epoch: 14     time: 32.77    loss: 1400.127    train acc: 0.356    val acc: 0.350\n","epoch: 15     time: 32.82    loss: 1382.682    train acc: 0.372    val acc: 0.375\n","saving best model...\n","epoch: 16     time: 32.84    loss: 1362.853    train acc: 0.392    val acc: 0.400\n","saving best model...\n","epoch: 17     time: 32.73    loss: 1350.091    train acc: 0.403    val acc: 0.429\n","saving best model...\n","epoch: 18     time: 32.66    loss: 1337.915    train acc: 0.412    val acc: 0.413\n","epoch: 19     time: 32.67    loss: 1324.701    train acc: 0.420    val acc: 0.409\n","epoch: 20     time: 32.47    loss: 1315.166    train acc: 0.428    val acc: 0.421\n","epoch: 21     time: 32.41    loss: 1304.330    train acc: 0.435    val acc: 0.408\n","epoch: 22     time: 32.67    loss: 1294.616    train acc: 0.440    val acc: 0.412\n","epoch: 23     time: 32.44    loss: 1286.315    train acc: 0.445    val acc: 0.433\n","saving best model...\n","epoch: 24     time: 32.52    loss: 1279.177    train acc: 0.450    val acc: 0.445\n","saving best model...\n","epoch: 25     time: 32.52    loss: 1270.658    train acc: 0.455    val acc: 0.429\n","epoch: 26     time: 32.52    loss: 1263.220    train acc: 0.459    val acc: 0.420\n","epoch: 27     time: 32.63    loss: 1255.829    train acc: 0.463    val acc: 0.411\n","epoch: 28     time: 32.53    loss: 1248.890    train acc: 0.468    val acc: 0.427\n","epoch: 29     time: 32.55    loss: 1243.332    train acc: 0.470    val acc: 0.438\n","epoch: 30     time: 32.60    loss: 1235.080    train acc: 0.476    val acc: 0.425\n","epoch: 31     time: 32.49    loss: 1228.683    train acc: 0.479    val acc: 0.438\n","epoch: 32     time: 32.66    loss: 1223.056    train acc: 0.483    val acc: 0.426\n","epoch: 33     time: 32.63    loss: 1217.462    train acc: 0.487    val acc: 0.429\n","epoch: 34     time: 32.61    loss: 1210.266    train acc: 0.490    val acc: 0.421\n","epoch: 35     time: 32.60    loss: 1204.589    train acc: 0.493    val acc: 0.450\n","saving best model...\n","epoch: 36     time: 32.54    loss: 1200.317    train acc: 0.495    val acc: 0.425\n","epoch: 37     time: 32.66    loss: 1193.370    train acc: 0.498    val acc: 0.432\n","epoch: 38     time: 32.55    loss: 1188.195    train acc: 0.501    val acc: 0.444\n","epoch: 39     time: 32.63    loss: 1182.214    train acc: 0.504    val acc: 0.453\n","saving best model...\n","epoch: 40     time: 32.57    loss: 1176.527    train acc: 0.507    val acc: 0.457\n","saving best model...\n","epoch: 41     time: 32.70    loss: 1172.436    train acc: 0.511    val acc: 0.448\n","epoch: 42     time: 32.58    loss: 1166.259    train acc: 0.514    val acc: 0.420\n","epoch: 43     time: 32.59    loss: 1161.967    train acc: 0.516    val acc: 0.451\n","epoch: 44     time: 32.66    loss: 1156.347    train acc: 0.518    val acc: 0.435\n","epoch: 45     time: 32.58    loss: 1150.789    train acc: 0.522    val acc: 0.441\n","epoch: 46     time: 32.60    loss: 1147.114    train acc: 0.524    val acc: 0.439\n","epoch: 47     time: 32.59    loss: 1141.290    train acc: 0.527    val acc: 0.455\n","epoch: 48     time: 32.60    loss: 1136.579    train acc: 0.530    val acc: 0.450\n","epoch: 49     time: 32.54    loss: 1131.491    train acc: 0.533    val acc: 0.446\n","epoch: 50     time: 32.56    loss: 1127.015    train acc: 0.534    val acc: 0.448\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mgwba45e17cb"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gcQMeXTo17cb","outputId":"76a9e721-0336-4421-c2e4-5b30aaf9b334","executionInfo":{"status":"ok","timestamp":1584312036931,"user_tz":420,"elapsed":3313995,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.5174\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"D9O-q6542DUn"},"source":["### CWT 0.1 & 0.5"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"9ce91a88-e5b1-4621-ac3e-20d774ced133","executionInfo":{"status":"ok","timestamp":1584312058416,"user_tz":420,"elapsed":3333232,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"QVCA1f8O2DUr","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.5\n","bottom_scale = 0.1\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"99255d91-e28f-461f-c977-1d94bce62c08","id":"ErBBbUWT2DUw","executionInfo":{"status":"ok","timestamp":1584313714152,"user_tz":420,"elapsed":4987343,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 32.65    loss: 1473.585    train acc: 0.257    val acc: 0.266\n","saving best model...\n","epoch: 2      time: 32.76    loss: 1465.842    train acc: 0.265    val acc: 0.254\n","epoch: 3      time: 32.67    loss: 1463.246    train acc: 0.272    val acc: 0.295\n","saving best model...\n","epoch: 4      time: 32.80    loss: 1461.614    train acc: 0.275    val acc: 0.281\n","epoch: 5      time: 32.79    loss: 1458.480    train acc: 0.284    val acc: 0.306\n","saving best model...\n","epoch: 6      time: 32.81    loss: 1456.493    train acc: 0.288    val acc: 0.305\n","epoch: 7      time: 32.67    loss: 1452.382    train acc: 0.297    val acc: 0.327\n","saving best model...\n","epoch: 8      time: 32.79    loss: 1446.039    train acc: 0.308    val acc: 0.368\n","saving best model...\n","epoch: 9      time: 32.88    loss: 1425.098    train acc: 0.337    val acc: 0.371\n","saving best model...\n","epoch: 10     time: 32.81    loss: 1401.239    train acc: 0.364    val acc: 0.394\n","saving best model...\n","epoch: 11     time: 32.77    loss: 1369.436    train acc: 0.395    val acc: 0.428\n","saving best model...\n","epoch: 12     time: 32.78    loss: 1347.416    train acc: 0.411    val acc: 0.422\n","epoch: 13     time: 32.84    loss: 1330.985    train acc: 0.420    val acc: 0.411\n","epoch: 14     time: 32.67    loss: 1320.120    train acc: 0.429    val acc: 0.402\n","epoch: 15     time: 32.99    loss: 1309.650    train acc: 0.435    val acc: 0.443\n","saving best model...\n","epoch: 16     time: 33.12    loss: 1300.543    train acc: 0.439    val acc: 0.440\n","epoch: 17     time: 33.09    loss: 1292.297    train acc: 0.443    val acc: 0.452\n","saving best model...\n","epoch: 18     time: 33.20    loss: 1284.895    train acc: 0.449    val acc: 0.435\n","epoch: 19     time: 33.40    loss: 1277.624    train acc: 0.452    val acc: 0.456\n","saving best model...\n","epoch: 20     time: 33.33    loss: 1270.613    train acc: 0.455    val acc: 0.466\n","saving best model...\n","epoch: 21     time: 33.22    loss: 1264.300    train acc: 0.460    val acc: 0.446\n","epoch: 22     time: 33.34    loss: 1259.081    train acc: 0.462    val acc: 0.462\n","epoch: 23     time: 33.42    loss: 1250.998    train acc: 0.467    val acc: 0.457\n","epoch: 24     time: 33.31    loss: 1246.220    train acc: 0.470    val acc: 0.448\n","epoch: 25     time: 33.21    loss: 1239.292    train acc: 0.474    val acc: 0.483\n","saving best model...\n","epoch: 26     time: 33.39    loss: 1233.054    train acc: 0.478    val acc: 0.472\n","epoch: 27     time: 33.57    loss: 1227.152    train acc: 0.482    val acc: 0.457\n","epoch: 28     time: 33.56    loss: 1222.013    train acc: 0.484    val acc: 0.472\n","epoch: 29     time: 33.31    loss: 1215.062    train acc: 0.489    val acc: 0.474\n","epoch: 30     time: 33.18    loss: 1210.375    train acc: 0.490    val acc: 0.465\n","epoch: 31     time: 32.89    loss: 1203.941    train acc: 0.494    val acc: 0.456\n","epoch: 32     time: 33.09    loss: 1199.829    train acc: 0.496    val acc: 0.456\n","epoch: 33     time: 32.83    loss: 1192.497    train acc: 0.500    val acc: 0.470\n","epoch: 34     time: 32.76    loss: 1187.551    train acc: 0.503    val acc: 0.494\n","saving best model...\n","epoch: 35     time: 32.71    loss: 1183.249    train acc: 0.506    val acc: 0.489\n","epoch: 36     time: 32.76    loss: 1177.232    train acc: 0.509    val acc: 0.474\n","epoch: 37     time: 32.90    loss: 1172.180    train acc: 0.511    val acc: 0.480\n","epoch: 38     time: 32.79    loss: 1167.149    train acc: 0.513    val acc: 0.467\n","epoch: 39     time: 32.82    loss: 1161.624    train acc: 0.518    val acc: 0.492\n","epoch: 40     time: 32.84    loss: 1157.389    train acc: 0.519    val acc: 0.475\n","epoch: 41     time: 32.81    loss: 1151.734    train acc: 0.523    val acc: 0.498\n","saving best model...\n","epoch: 42     time: 32.85    loss: 1148.286    train acc: 0.523    val acc: 0.469\n","epoch: 43     time: 32.75    loss: 1143.156    train acc: 0.526    val acc: 0.485\n","epoch: 44     time: 32.86    loss: 1137.171    train acc: 0.531    val acc: 0.469\n","epoch: 45     time: 32.60    loss: 1133.260    train acc: 0.531    val acc: 0.466\n","epoch: 46     time: 32.52    loss: 1127.547    train acc: 0.535    val acc: 0.471\n","epoch: 47     time: 32.64    loss: 1125.175    train acc: 0.536    val acc: 0.484\n","epoch: 48     time: 32.39    loss: 1120.182    train acc: 0.538    val acc: 0.479\n","epoch: 49     time: 32.53    loss: 1115.521    train acc: 0.542    val acc: 0.497\n","epoch: 50     time: 32.60    loss: 1111.907    train acc: 0.542    val acc: 0.480\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"F1w86MJP2DUy"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pQ2lpb4W2DUz","outputId":"f34b2e05-b574-468b-c66e-2e312eac37c8","executionInfo":{"status":"ok","timestamp":1584313725035,"user_tz":420,"elapsed":4995435,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.5219\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"djGwAkd-2V7q"},"source":["### CWT 0.2 & 0.5"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"bc0727b8-ec91-461d-cb40-844d95c78779","executionInfo":{"status":"ok","timestamp":1584313744433,"user_tz":420,"elapsed":5012323,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"oK-2O-tA2V7u","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.5\n","bottom_scale = 0.2\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"ff7fac8a-826d-4264-c55b-b2adca43bd2c","id":"-T9RipZy2V7y","executionInfo":{"status":"ok","timestamp":1584315356596,"user_tz":420,"elapsed":246549,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 32.23    loss: 1475.100    train acc: 0.252    val acc: 0.246\n","saving best model...\n","epoch: 2      time: 32.21    loss: 1467.159    train acc: 0.261    val acc: 0.261\n","saving best model...\n","epoch: 3      time: 32.30    loss: 1464.151    train acc: 0.270    val acc: 0.290\n","saving best model...\n","epoch: 4      time: 32.32    loss: 1460.917    train acc: 0.278    val acc: 0.316\n","saving best model...\n","epoch: 5      time: 32.60    loss: 1457.575    train acc: 0.286    val acc: 0.326\n","saving best model...\n","epoch: 6      time: 32.46    loss: 1452.075    train acc: 0.296    val acc: 0.339\n","saving best model...\n","epoch: 7      time: 32.31    loss: 1443.873    train acc: 0.310    val acc: 0.346\n","saving best model...\n","epoch: 8      time: 32.49    loss: 1433.359    train acc: 0.325    val acc: 0.346\n","epoch: 9      time: 32.40    loss: 1425.400    train acc: 0.335    val acc: 0.371\n","saving best model...\n","epoch: 10     time: 32.33    loss: 1414.866    train acc: 0.347    val acc: 0.375\n","saving best model...\n","epoch: 11     time: 32.13    loss: 1393.244    train acc: 0.369    val acc: 0.402\n","saving best model...\n","epoch: 12     time: 32.38    loss: 1360.639    train acc: 0.398    val acc: 0.416\n","saving best model...\n","epoch: 13     time: 32.20    loss: 1338.733    train acc: 0.412    val acc: 0.347\n","epoch: 14     time: 32.10    loss: 1321.939    train acc: 0.424    val acc: 0.384\n","epoch: 15     time: 32.12    loss: 1307.839    train acc: 0.430    val acc: 0.414\n","epoch: 16     time: 31.82    loss: 1293.379    train acc: 0.440    val acc: 0.417\n","saving best model...\n","epoch: 17     time: 31.73    loss: 1282.009    train acc: 0.446    val acc: 0.424\n","saving best model...\n","epoch: 18     time: 31.84    loss: 1270.833    train acc: 0.453    val acc: 0.419\n","epoch: 19     time: 31.90    loss: 1261.577    train acc: 0.459    val acc: 0.406\n","epoch: 20     time: 31.79    loss: 1250.894    train acc: 0.463    val acc: 0.438\n","saving best model...\n","epoch: 21     time: 31.77    loss: 1242.618    train acc: 0.468    val acc: 0.459\n","saving best model...\n","epoch: 22     time: 31.78    loss: 1234.383    train acc: 0.473    val acc: 0.453\n","epoch: 23     time: 31.75    loss: 1226.501    train acc: 0.476    val acc: 0.469\n","saving best model...\n","epoch: 24     time: 31.85    loss: 1216.995    train acc: 0.482    val acc: 0.440\n","epoch: 25     time: 31.77    loss: 1210.816    train acc: 0.486    val acc: 0.458\n","epoch: 26     time: 31.90    loss: 1203.103    train acc: 0.490    val acc: 0.471\n","saving best model...\n","epoch: 27     time: 31.91    loss: 1197.483    train acc: 0.493    val acc: 0.451\n","epoch: 28     time: 31.92    loss: 1190.228    train acc: 0.498    val acc: 0.455\n","epoch: 29     time: 31.82    loss: 1184.022    train acc: 0.502    val acc: 0.463\n","epoch: 30     time: 31.82    loss: 1177.073    train acc: 0.503    val acc: 0.477\n","saving best model...\n","epoch: 31     time: 31.98    loss: 1171.266    train acc: 0.507    val acc: 0.471\n","epoch: 32     time: 32.20    loss: 1163.922    train acc: 0.512    val acc: 0.460\n","epoch: 33     time: 32.33    loss: 1157.745    train acc: 0.515    val acc: 0.487\n","saving best model...\n","epoch: 34     time: 32.35    loss: 1153.231    train acc: 0.518    val acc: 0.478\n","epoch: 35     time: 32.17    loss: 1146.756    train acc: 0.521    val acc: 0.473\n","epoch: 36     time: 32.19    loss: 1141.512    train acc: 0.526    val acc: 0.451\n","epoch: 37     time: 32.12    loss: 1134.562    train acc: 0.529    val acc: 0.476\n","epoch: 38     time: 32.16    loss: 1128.413    train acc: 0.532    val acc: 0.479\n","epoch: 39     time: 32.05    loss: 1123.573    train acc: 0.534    val acc: 0.473\n","epoch: 40     time: 32.10    loss: 1119.308    train acc: 0.536    val acc: 0.472\n","epoch: 41     time: 32.16    loss: 1111.654    train acc: 0.540    val acc: 0.484\n","epoch: 42     time: 31.93    loss: 1107.549    train acc: 0.543    val acc: 0.485\n","epoch: 43     time: 32.00    loss: 1102.108    train acc: 0.545    val acc: 0.486\n","epoch: 44     time: 31.82    loss: 1096.611    train acc: 0.548    val acc: 0.466\n","epoch: 45     time: 31.94    loss: 1092.433    train acc: 0.549    val acc: 0.487\n","saving best model...\n","epoch: 46     time: 31.78    loss: 1086.944    train acc: 0.553    val acc: 0.482\n","epoch: 47     time: 31.91    loss: 1082.177    train acc: 0.555    val acc: 0.490\n","saving best model...\n","epoch: 48     time: 32.01    loss: 1078.210    train acc: 0.559    val acc: 0.471\n","epoch: 49     time: 31.75    loss: 1072.514    train acc: 0.561    val acc: 0.478\n","epoch: 50     time: 31.65    loss: 1066.721    train acc: 0.564    val acc: 0.491\n","saving best model...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4SIWCtiL2V71"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Uz_AvqtG2V72","outputId":"fb0b8dd1-9461-4c3b-a69e-b07a1296290f","executionInfo":{"status":"ok","timestamp":1584315367300,"user_tz":420,"elapsed":10708,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.4876\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hMy3sU8i1ygh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kBtPbTGHrSR8"},"source":["### CWT 0 & 0.3"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"64bfac40-ac5c-4239-e5b2-7ae459825347","executionInfo":{"status":"ok","timestamp":1584317461870,"user_tz":420,"elapsed":19619,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"8V68wBJVrSR-","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.3\n","bottom_scale = 0\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"f1d10ea3-d424-493b-a3a4-789dbe9bf2cd","executionInfo":{"status":"ok","timestamp":1584319111038,"user_tz":420,"elapsed":1666887,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"0FaKBHhGrSSB","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 32.58    loss: 1471.761    train acc: 0.255    val acc: 0.262\n","saving best model...\n","epoch: 2      time: 32.74    loss: 1466.900    train acc: 0.261    val acc: 0.263\n","saving best model...\n","epoch: 3      time: 32.58    loss: 1465.307    train acc: 0.264    val acc: 0.286\n","saving best model...\n","epoch: 4      time: 32.65    loss: 1463.205    train acc: 0.271    val acc: 0.270\n","epoch: 5      time: 32.62    loss: 1461.465    train acc: 0.277    val acc: 0.261\n","epoch: 6      time: 32.61    loss: 1459.599    train acc: 0.282    val acc: 0.255\n","epoch: 7      time: 32.62    loss: 1456.054    train acc: 0.289    val acc: 0.302\n","saving best model...\n","epoch: 8      time: 32.56    loss: 1451.728    train acc: 0.297    val acc: 0.296\n","epoch: 9      time: 32.64    loss: 1440.580    train acc: 0.313    val acc: 0.322\n","saving best model...\n","epoch: 10     time: 32.58    loss: 1433.230    train acc: 0.324    val acc: 0.315\n","epoch: 11     time: 32.52    loss: 1417.283    train acc: 0.340    val acc: 0.357\n","saving best model...\n","epoch: 12     time: 32.51    loss: 1402.485    train acc: 0.352    val acc: 0.367\n","saving best model...\n","epoch: 13     time: 32.66    loss: 1390.203    train acc: 0.361    val acc: 0.361\n","epoch: 14     time: 32.38    loss: 1379.409    train acc: 0.370    val acc: 0.395\n","saving best model...\n","epoch: 15     time: 32.76    loss: 1366.458    train acc: 0.382    val acc: 0.410\n","saving best model...\n","epoch: 16     time: 32.59    loss: 1348.497    train acc: 0.399    val acc: 0.408\n","epoch: 17     time: 32.55    loss: 1332.978    train acc: 0.410    val acc: 0.397\n","epoch: 18     time: 32.40    loss: 1321.207    train acc: 0.418    val acc: 0.404\n","epoch: 19     time: 32.54    loss: 1309.137    train acc: 0.427    val acc: 0.402\n","epoch: 20     time: 32.59    loss: 1299.450    train acc: 0.435    val acc: 0.413\n","saving best model...\n","epoch: 21     time: 32.44    loss: 1289.765    train acc: 0.442    val acc: 0.432\n","saving best model...\n","epoch: 22     time: 32.62    loss: 1281.630    train acc: 0.446    val acc: 0.425\n","epoch: 23     time: 32.30    loss: 1271.980    train acc: 0.452    val acc: 0.434\n","saving best model...\n","epoch: 24     time: 32.57    loss: 1264.782    train acc: 0.457    val acc: 0.423\n","epoch: 25     time: 32.47    loss: 1255.582    train acc: 0.463    val acc: 0.417\n","epoch: 26     time: 32.45    loss: 1247.255    train acc: 0.469    val acc: 0.394\n","epoch: 27     time: 32.59    loss: 1239.683    train acc: 0.474    val acc: 0.423\n","epoch: 28     time: 32.65    loss: 1233.445    train acc: 0.478    val acc: 0.417\n","epoch: 29     time: 32.73    loss: 1224.963    train acc: 0.483    val acc: 0.434\n","saving best model...\n","epoch: 30     time: 32.69    loss: 1217.463    train acc: 0.487    val acc: 0.442\n","saving best model...\n","epoch: 31     time: 32.57    loss: 1210.404    train acc: 0.491    val acc: 0.437\n","epoch: 32     time: 32.68    loss: 1203.443    train acc: 0.496    val acc: 0.422\n","epoch: 33     time: 32.66    loss: 1198.348    train acc: 0.498    val acc: 0.431\n","epoch: 34     time: 32.70    loss: 1190.996    train acc: 0.504    val acc: 0.427\n","epoch: 35     time: 32.55    loss: 1183.316    train acc: 0.508    val acc: 0.438\n","epoch: 36     time: 32.52    loss: 1177.745    train acc: 0.510    val acc: 0.431\n","epoch: 37     time: 32.83    loss: 1171.880    train acc: 0.513    val acc: 0.427\n","epoch: 38     time: 32.85    loss: 1165.963    train acc: 0.516    val acc: 0.428\n","epoch: 39     time: 32.88    loss: 1158.950    train acc: 0.521    val acc: 0.442\n","saving best model...\n","epoch: 40     time: 32.88    loss: 1152.894    train acc: 0.523    val acc: 0.418\n","epoch: 41     time: 32.94    loss: 1148.374    train acc: 0.526    val acc: 0.435\n","epoch: 42     time: 32.97    loss: 1142.065    train acc: 0.530    val acc: 0.413\n","epoch: 43     time: 33.02    loss: 1135.667    train acc: 0.532    val acc: 0.431\n","epoch: 44     time: 33.29    loss: 1132.576    train acc: 0.535    val acc: 0.444\n","saving best model...\n","epoch: 45     time: 33.32    loss: 1125.903    train acc: 0.537    val acc: 0.435\n","epoch: 46     time: 33.37    loss: 1119.041    train acc: 0.541    val acc: 0.440\n","epoch: 47     time: 33.43    loss: 1114.962    train acc: 0.542    val acc: 0.454\n","saving best model...\n","epoch: 48     time: 33.36    loss: 1110.062    train acc: 0.545    val acc: 0.449\n","epoch: 49     time: 33.23    loss: 1105.864    train acc: 0.547    val acc: 0.426\n","epoch: 50     time: 33.25    loss: 1100.020    train acc: 0.552    val acc: 0.461\n","saving best model...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"yLvRC9SQrSSD"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"822ac6bb-fe42-4c96-ff70-f07c73e84459","executionInfo":{"status":"ok","timestamp":1584319122094,"user_tz":420,"elapsed":1673086,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"nAdJpy5vrSSD","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.5210\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CTfpZoyKrSSF","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CErnDSAMrcpT"},"source":["### CWT 0.1 & 0.3"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"e954689a-e043-4f42-9137-c0b06242a5ea","executionInfo":{"status":"ok","timestamp":1584343646388,"user_tz":420,"elapsed":30240,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"DHVZf0HQrcpU","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.3\n","bottom_scale = 0.1\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"c13c1f45-a3dd-404d-8dd7-5744b47ca59e","executionInfo":{"status":"ok","timestamp":1584315356596,"user_tz":420,"elapsed":246549,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"W-gOZWAzrcpW","colab":{"base_uri":"https://localhost:8080/","height":727}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 190\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 92.83    loss: 1472.780    train acc: 0.255    val acc: 0.250\n","saving best model...\n","epoch: 2      time: 81.85    loss: 1466.467    train acc: 0.263    val acc: 0.244\n","epoch: 3      time: 80.49    loss: 1463.676    train acc: 0.272    val acc: 0.255\n","saving best model...\n","epoch: 4      time: 80.74    loss: 1461.695    train acc: 0.278    val acc: 0.286\n","saving best model...\n","epoch: 5      time: 76.67    loss: 1458.708    train acc: 0.282    val acc: 0.293\n","saving best model...\n","epoch: 6      time: 77.29    loss: 1455.895    train acc: 0.288    val acc: 0.295\n","saving best model...\n","epoch: 7      time: 80.02    loss: 1451.225    train acc: 0.299    val acc: 0.306\n","saving best model...\n","epoch: 8      time: 80.44    loss: 1440.769    train acc: 0.314    val acc: 0.315\n","saving best model...\n","epoch: 9      time: 79.99    loss: 1428.534    train acc: 0.328    val acc: 0.358\n","saving best model...\n","epoch: 10     time: 79.60    loss: 1418.619    train acc: 0.339    val acc: 0.364\n","saving best model...\n","epoch: 11     time: 78.14    loss: 1407.973    train acc: 0.347    val acc: 0.358\n","epoch: 12     time: 76.69    loss: 1396.178    train acc: 0.357    val acc: 0.377\n","saving best model...\n","epoch: 13     time: 75.86    loss: 1385.008    train acc: 0.366    val acc: 0.388\n","saving best model...\n","epoch: 14     time: 81.09    loss: 1369.971    train acc: 0.377    val acc: 0.410\n","saving best model...\n","epoch: 15     time: 81.84    loss: 1354.325    train acc: 0.392    val acc: 0.393\n","epoch: 16     time: 81.77    loss: 1341.293    train acc: 0.402    val acc: 0.433\n","saving best model...\n","epoch: 17     time: 78.96    loss: 1329.065    train acc: 0.413    val acc: 0.442\n","saving best model...\n","epoch: 18     time: 79.40    loss: 1316.669    train acc: 0.421    val acc: 0.418\n","epoch: 19     time: 76.12    loss: 1304.037    train acc: 0.432    val acc: 0.442\n","saving best model...\n","epoch: 20     time: 76.25    loss: 1293.705    train acc: 0.437    val acc: 0.452\n","saving best model...\n","epoch: 21     time: 81.39    loss: 1283.356    train acc: 0.443    val acc: 0.449\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B1ECCLkmrcpY"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"a2dc2e3a-d607-456c-b1b1-9304ec57db5b","executionInfo":{"status":"error","timestamp":1584340756855,"user_tz":420,"elapsed":8061,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"t4Ir1dpQrcpZ","colab":{"base_uri":"https://localhost:8080/","height":365}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-2da70f53cf2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_cwt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cwt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_cwt_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcwt_data2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_levels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTestRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_cwt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cwt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_cwt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvote_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvote_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mTestRNN\u001b[0;34m(model, X_test, y_test, p_test, aug_type, window_size, vote_num)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mX_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# type: (Tensor, Tensor, Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    157\u001b[0m             raise RuntimeError(\n\u001b[1;32m    158\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 159\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 5, got 22"]}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5E0dETQjrcpb","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qfJxIIL5rkCc"},"source":["### CWT 0.2 & 0.4"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"0e778c34-257b-44d6-a20b-c50dfa2d3788","executionInfo":{"status":"ok","timestamp":1584320850712,"user_tz":420,"elapsed":20022,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"RO0D9RQvrkCc","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.4\n","bottom_scale = 0.2\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"177dd2b6-526d-44df-b74b-e980ad8afde8","executionInfo":{"status":"ok","timestamp":1584322522815,"user_tz":420,"elapsed":1672106,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"y2HkezXGrkCg","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 33.69    loss: 1471.898    train acc: 0.256    val acc: 0.249\n","saving best model...\n","epoch: 2      time: 33.67    loss: 1465.754    train acc: 0.264    val acc: 0.268\n","saving best model...\n","epoch: 3      time: 33.47    loss: 1461.695    train acc: 0.275    val acc: 0.329\n","saving best model...\n","epoch: 4      time: 33.69    loss: 1457.330    train acc: 0.287    val acc: 0.330\n","saving best model...\n","epoch: 5      time: 33.75    loss: 1452.199    train acc: 0.296    val acc: 0.332\n","saving best model...\n","epoch: 6      time: 33.77    loss: 1441.770    train acc: 0.312    val acc: 0.355\n","saving best model...\n","epoch: 7      time: 33.69    loss: 1433.320    train acc: 0.322    val acc: 0.354\n","epoch: 8      time: 33.64    loss: 1425.350    train acc: 0.332    val acc: 0.401\n","saving best model...\n","epoch: 9      time: 33.61    loss: 1416.394    train acc: 0.342    val acc: 0.377\n","epoch: 10     time: 33.56    loss: 1398.971    train acc: 0.358    val acc: 0.413\n","saving best model...\n","epoch: 11     time: 33.76    loss: 1378.735    train acc: 0.376    val acc: 0.416\n","saving best model...\n","epoch: 12     time: 33.83    loss: 1360.103    train acc: 0.394    val acc: 0.399\n","epoch: 13     time: 33.56    loss: 1342.890    train acc: 0.408    val acc: 0.429\n","saving best model...\n","epoch: 14     time: 33.84    loss: 1327.337    train acc: 0.420    val acc: 0.446\n","saving best model...\n","epoch: 15     time: 33.71    loss: 1311.776    train acc: 0.430    val acc: 0.418\n","epoch: 16     time: 33.69    loss: 1297.239    train acc: 0.439    val acc: 0.424\n","epoch: 17     time: 33.71    loss: 1282.544    train acc: 0.447    val acc: 0.423\n","epoch: 18     time: 33.70    loss: 1270.328    train acc: 0.454    val acc: 0.453\n","saving best model...\n","epoch: 19     time: 33.60    loss: 1257.919    train acc: 0.459    val acc: 0.451\n","epoch: 20     time: 33.39    loss: 1247.405    train acc: 0.466    val acc: 0.428\n","epoch: 21     time: 33.12    loss: 1238.009    train acc: 0.471    val acc: 0.448\n","epoch: 22     time: 33.04    loss: 1227.079    train acc: 0.476    val acc: 0.447\n","epoch: 23     time: 32.91    loss: 1218.223    train acc: 0.481    val acc: 0.450\n","epoch: 24     time: 33.00    loss: 1209.231    train acc: 0.486    val acc: 0.463\n","saving best model...\n","epoch: 25     time: 32.66    loss: 1201.145    train acc: 0.491    val acc: 0.490\n","saving best model...\n","epoch: 26     time: 32.72    loss: 1193.187    train acc: 0.494    val acc: 0.469\n","epoch: 27     time: 32.64    loss: 1184.667    train acc: 0.500    val acc: 0.490\n","saving best model...\n","epoch: 28     time: 32.61    loss: 1176.006    train acc: 0.503    val acc: 0.466\n","epoch: 29     time: 32.77    loss: 1168.737    train acc: 0.509    val acc: 0.513\n","saving best model...\n","epoch: 30     time: 32.82    loss: 1162.190    train acc: 0.510    val acc: 0.461\n","epoch: 31     time: 33.22    loss: 1153.375    train acc: 0.515    val acc: 0.512\n","epoch: 32     time: 33.30    loss: 1146.973    train acc: 0.518    val acc: 0.479\n","epoch: 33     time: 32.94    loss: 1141.068    train acc: 0.523    val acc: 0.471\n","epoch: 34     time: 33.05    loss: 1133.125    train acc: 0.527    val acc: 0.504\n","epoch: 35     time: 32.81    loss: 1126.492    train acc: 0.530    val acc: 0.485\n","epoch: 36     time: 32.95    loss: 1120.217    train acc: 0.534    val acc: 0.502\n","epoch: 37     time: 32.80    loss: 1113.909    train acc: 0.540    val acc: 0.479\n","epoch: 38     time: 32.85    loss: 1108.629    train acc: 0.541    val acc: 0.482\n","epoch: 39     time: 32.93    loss: 1099.753    train acc: 0.546    val acc: 0.502\n","epoch: 40     time: 32.94    loss: 1095.164    train acc: 0.549    val acc: 0.485\n","epoch: 41     time: 32.94    loss: 1088.228    train acc: 0.551    val acc: 0.505\n","epoch: 42     time: 32.81    loss: 1083.402    train acc: 0.555    val acc: 0.500\n","epoch: 43     time: 32.98    loss: 1075.004    train acc: 0.559    val acc: 0.498\n","epoch: 44     time: 32.75    loss: 1069.434    train acc: 0.563    val acc: 0.496\n","epoch: 45     time: 32.80    loss: 1063.484    train acc: 0.565    val acc: 0.483\n","epoch: 46     time: 32.70    loss: 1058.001    train acc: 0.567    val acc: 0.501\n","epoch: 47     time: 32.75    loss: 1052.471    train acc: 0.571    val acc: 0.502\n","epoch: 48     time: 32.95    loss: 1046.286    train acc: 0.573    val acc: 0.498\n","epoch: 49     time: 32.71    loss: 1039.823    train acc: 0.578    val acc: 0.501\n","epoch: 50     time: 32.71    loss: 1035.211    train acc: 0.579    val acc: 0.499\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WKxvqfIMrkCi"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"e6fbed8f-a949-4764-854b-c4bf0bb12e8e","executionInfo":{"status":"ok","timestamp":1584322533618,"user_tz":420,"elapsed":10813,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"nBI0lMtYrkCi","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.4903\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DnruaPIY7Myh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xXFWscQq7QeY"},"source":["### CWT 0.2 & 0.3"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"a536f17a-3a3d-470e-d2f7-3c5b5180507d","executionInfo":{"status":"ok","timestamp":1584323213571,"user_tz":420,"elapsed":20607,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"xkvZClBG7Qed","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.3\n","bottom_scale = 0.2\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"5bae47b1-6a34-4fcd-db05-896d838b2c7a","executionInfo":{"status":"ok","timestamp":1584324849562,"user_tz":420,"elapsed":1656569,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"WLdZDqB97Qeh","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 32.89    loss: 1473.532    train acc: 0.255    val acc: 0.254\n","saving best model...\n","epoch: 2      time: 32.38    loss: 1466.318    train acc: 0.265    val acc: 0.270\n","saving best model...\n","epoch: 3      time: 32.36    loss: 1463.646    train acc: 0.270    val acc: 0.287\n","saving best model...\n","epoch: 4      time: 32.54    loss: 1460.814    train acc: 0.278    val acc: 0.315\n","saving best model...\n","epoch: 5      time: 32.31    loss: 1456.566    train acc: 0.290    val acc: 0.340\n","saving best model...\n","epoch: 6      time: 32.62    loss: 1451.076    train acc: 0.299    val acc: 0.347\n","saving best model...\n","epoch: 7      time: 32.56    loss: 1441.178    train acc: 0.315    val acc: 0.345\n","epoch: 8      time: 32.62    loss: 1422.182    train acc: 0.339    val acc: 0.372\n","saving best model...\n","epoch: 9      time: 32.69    loss: 1407.554    train acc: 0.353    val acc: 0.378\n","saving best model...\n","epoch: 10     time: 32.52    loss: 1390.172    train acc: 0.367    val acc: 0.369\n","epoch: 11     time: 32.57    loss: 1365.510    train acc: 0.389    val acc: 0.416\n","saving best model...\n","epoch: 12     time: 32.36    loss: 1324.940    train acc: 0.423    val acc: 0.383\n","epoch: 13     time: 32.61    loss: 1301.709    train acc: 0.437    val acc: 0.410\n","epoch: 14     time: 32.50    loss: 1283.681    train acc: 0.448    val acc: 0.421\n","saving best model...\n","epoch: 15     time: 32.51    loss: 1268.940    train acc: 0.457    val acc: 0.444\n","saving best model...\n","epoch: 16     time: 32.52    loss: 1253.735    train acc: 0.466    val acc: 0.435\n","epoch: 17     time: 32.43    loss: 1240.884    train acc: 0.473    val acc: 0.447\n","saving best model...\n","epoch: 18     time: 32.57    loss: 1228.456    train acc: 0.479    val acc: 0.442\n","epoch: 19     time: 32.41    loss: 1215.428    train acc: 0.488    val acc: 0.451\n","saving best model...\n","epoch: 20     time: 32.57    loss: 1203.203    train acc: 0.494    val acc: 0.430\n","epoch: 21     time: 32.71    loss: 1194.449    train acc: 0.496    val acc: 0.472\n","saving best model...\n","epoch: 22     time: 32.64    loss: 1182.962    train acc: 0.504    val acc: 0.458\n","epoch: 23     time: 32.57    loss: 1174.498    train acc: 0.510    val acc: 0.476\n","saving best model...\n","epoch: 24     time: 32.50    loss: 1164.858    train acc: 0.514    val acc: 0.453\n","epoch: 25     time: 32.63    loss: 1156.302    train acc: 0.520    val acc: 0.468\n","epoch: 26     time: 32.53    loss: 1146.873    train acc: 0.524    val acc: 0.464\n","epoch: 27     time: 32.54    loss: 1138.788    train acc: 0.529    val acc: 0.459\n","epoch: 28     time: 32.42    loss: 1131.280    train acc: 0.533    val acc: 0.458\n","epoch: 29     time: 32.59    loss: 1122.816    train acc: 0.537    val acc: 0.470\n","epoch: 30     time: 32.46    loss: 1113.809    train acc: 0.542    val acc: 0.469\n","epoch: 31     time: 32.21    loss: 1106.362    train acc: 0.546    val acc: 0.456\n","epoch: 32     time: 32.33    loss: 1098.258    train acc: 0.550    val acc: 0.460\n","epoch: 33     time: 32.07    loss: 1091.677    train acc: 0.552    val acc: 0.453\n","epoch: 34     time: 32.30    loss: 1082.341    train acc: 0.558    val acc: 0.453\n","epoch: 35     time: 32.16    loss: 1076.690    train acc: 0.560    val acc: 0.464\n","epoch: 36     time: 32.20    loss: 1068.770    train acc: 0.565    val acc: 0.441\n","epoch: 37     time: 32.48    loss: 1062.418    train acc: 0.567    val acc: 0.451\n","epoch: 38     time: 32.49    loss: 1053.310    train acc: 0.572    val acc: 0.445\n","epoch: 39     time: 32.99    loss: 1044.698    train acc: 0.576    val acc: 0.457\n","epoch: 40     time: 32.75    loss: 1040.383    train acc: 0.579    val acc: 0.432\n","epoch: 41     time: 32.95    loss: 1032.605    train acc: 0.582    val acc: 0.432\n","epoch: 42     time: 32.63    loss: 1022.992    train acc: 0.587    val acc: 0.434\n","epoch: 43     time: 32.61    loss: 1019.007    train acc: 0.590    val acc: 0.448\n","epoch: 44     time: 32.37    loss: 1011.310    train acc: 0.593    val acc: 0.447\n","epoch: 45     time: 32.30    loss: 1006.321    train acc: 0.597    val acc: 0.458\n","epoch: 46     time: 32.66    loss: 998.143    train acc: 0.600    val acc: 0.444\n","epoch: 47     time: 32.55    loss: 991.568    train acc: 0.603    val acc: 0.448\n","epoch: 48     time: 32.61    loss: 983.952    train acc: 0.607    val acc: 0.450\n","epoch: 49     time: 32.24    loss: 977.507    train acc: 0.610    val acc: 0.426\n","epoch: 50     time: 32.31    loss: 970.031    train acc: 0.614    val acc: 0.446\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Bz8jYtvt7Qei"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MKTVY8kW7Qej","outputId":"ab811251-6397-4ab9-8826-8dfc4b447a9d","executionInfo":{"status":"ok","timestamp":1584324860300,"user_tz":420,"elapsed":1667303,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.4777\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FZXMC2Hp7Qel","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kgdjzymx7ZI_"},"source":["### CWT 0.1 & 0.2"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"ad1bd0cd-74eb-4a90-d46e-0a8efa90dd67","executionInfo":{"status":"ok","timestamp":1584324880015,"user_tz":420,"elapsed":1687008,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"CbIoZ3lG7ZJA","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment for window\n","# train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","\n","# Uncomment for CWT -> Window\n","num_levels = 5\n","top_scale = 0.2\n","bottom_scale = 0.1\n","X_cwt, y_cwt, p_cwt = cwt_data2(X_train_valid, y_train_valid, person_train_valid, num_levels, bottom_scale = bottom_scale, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_cwt, y_cwt)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8460, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"9aeae60b-16d5-490a-b57d-790458d0c73c","executionInfo":{"status":"ok","timestamp":1584326515084,"user_tz":420,"elapsed":3322065,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"Qqdx-yri7ZJE","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 50\n","k = 0\n","dropout = 0.75\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.0001]\n","X_train, y_train, p_train = X_cwt[train_fold[k]], y_cwt[train_fold[k]], p_cwt[train_fold[k]]\n","X_val, y_val, p_val = X_cwt[val_fold[k]], y_cwt[val_fold[k]], p_cwt[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.0001\n","lrn_rt 0.0001\n","epoch: 1      time: 32.29    loss: 1471.897    train acc: 0.256    val acc: 0.247\n","saving best model...\n","epoch: 2      time: 32.39    loss: 1465.893    train acc: 0.262    val acc: 0.261\n","saving best model...\n","epoch: 3      time: 32.16    loss: 1463.173    train acc: 0.272    val acc: 0.282\n","saving best model...\n","epoch: 4      time: 32.35    loss: 1459.217    train acc: 0.282    val acc: 0.302\n","saving best model...\n","epoch: 5      time: 32.22    loss: 1453.787    train acc: 0.293    val acc: 0.309\n","saving best model...\n","epoch: 6      time: 32.36    loss: 1445.405    train acc: 0.307    val acc: 0.272\n","epoch: 7      time: 32.21    loss: 1430.902    train acc: 0.326    val acc: 0.356\n","saving best model...\n","epoch: 8      time: 32.37    loss: 1410.171    train acc: 0.344    val acc: 0.363\n","saving best model...\n","epoch: 9      time: 32.38    loss: 1394.141    train acc: 0.355    val acc: 0.381\n","saving best model...\n","epoch: 10     time: 32.29    loss: 1381.911    train acc: 0.361    val acc: 0.373\n","epoch: 11     time: 32.26    loss: 1370.813    train acc: 0.368    val acc: 0.351\n","epoch: 12     time: 32.28    loss: 1360.711    train acc: 0.373    val acc: 0.361\n","epoch: 13     time: 32.33    loss: 1351.079    train acc: 0.380    val acc: 0.374\n","epoch: 14     time: 32.21    loss: 1342.174    train acc: 0.384    val acc: 0.348\n","epoch: 15     time: 32.48    loss: 1333.351    train acc: 0.388    val acc: 0.390\n","saving best model...\n","epoch: 16     time: 32.40    loss: 1323.483    train acc: 0.395    val acc: 0.376\n","epoch: 17     time: 32.22    loss: 1315.397    train acc: 0.401    val acc: 0.360\n","epoch: 18     time: 32.32    loss: 1306.605    train acc: 0.408    val acc: 0.359\n","epoch: 19     time: 32.37    loss: 1298.101    train acc: 0.414    val acc: 0.387\n","epoch: 20     time: 32.65    loss: 1287.973    train acc: 0.421    val acc: 0.390\n","saving best model...\n","epoch: 21     time: 32.63    loss: 1276.825    train acc: 0.431    val acc: 0.418\n","saving best model...\n","epoch: 22     time: 32.72    loss: 1262.562    train acc: 0.443    val acc: 0.409\n","epoch: 23     time: 32.69    loss: 1250.812    train acc: 0.452    val acc: 0.424\n","saving best model...\n","epoch: 24     time: 32.56    loss: 1239.255    train acc: 0.459    val acc: 0.431\n","saving best model...\n","epoch: 25     time: 32.72    loss: 1230.379    train acc: 0.465    val acc: 0.433\n","saving best model...\n","epoch: 26     time: 32.72    loss: 1219.567    train acc: 0.472    val acc: 0.413\n","epoch: 27     time: 32.75    loss: 1208.595    train acc: 0.478    val acc: 0.433\n","epoch: 28     time: 32.58    loss: 1202.886    train acc: 0.482    val acc: 0.434\n","saving best model...\n","epoch: 29     time: 32.89    loss: 1192.958    train acc: 0.488    val acc: 0.435\n","saving best model...\n","epoch: 30     time: 32.56    loss: 1183.516    train acc: 0.495    val acc: 0.431\n","epoch: 31     time: 32.15    loss: 1175.763    train acc: 0.497    val acc: 0.435\n","epoch: 32     time: 32.41    loss: 1166.870    train acc: 0.504    val acc: 0.445\n","saving best model...\n","epoch: 33     time: 32.20    loss: 1159.546    train acc: 0.507    val acc: 0.449\n","saving best model...\n","epoch: 34     time: 32.43    loss: 1150.341    train acc: 0.512    val acc: 0.443\n","epoch: 35     time: 32.60    loss: 1140.718    train acc: 0.517    val acc: 0.435\n","epoch: 36     time: 32.71    loss: 1132.557    train acc: 0.521    val acc: 0.449\n","epoch: 37     time: 32.52    loss: 1125.029    train acc: 0.526    val acc: 0.462\n","saving best model...\n","epoch: 38     time: 32.43    loss: 1118.454    train acc: 0.531    val acc: 0.464\n","saving best model...\n","epoch: 39     time: 32.57    loss: 1110.596    train acc: 0.534    val acc: 0.447\n","epoch: 40     time: 32.41    loss: 1103.001    train acc: 0.537    val acc: 0.456\n","epoch: 41     time: 32.48    loss: 1096.802    train acc: 0.542    val acc: 0.458\n","epoch: 42     time: 32.47    loss: 1088.700    train acc: 0.546    val acc: 0.453\n","epoch: 43     time: 32.54    loss: 1081.995    train acc: 0.549    val acc: 0.446\n","epoch: 44     time: 32.67    loss: 1073.491    train acc: 0.552    val acc: 0.453\n","epoch: 45     time: 32.58    loss: 1066.918    train acc: 0.558    val acc: 0.452\n","epoch: 46     time: 32.49    loss: 1061.412    train acc: 0.560    val acc: 0.447\n","epoch: 47     time: 32.53    loss: 1055.076    train acc: 0.565    val acc: 0.448\n","epoch: 48     time: 32.48    loss: 1048.393    train acc: 0.566    val acc: 0.464\n","epoch: 49     time: 32.51    loss: 1042.044    train acc: 0.570    val acc: 0.455\n","epoch: 50     time: 32.49    loss: 1037.935    train acc: 0.572    val acc: 0.459\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"EOy_j9th7ZJH"},"source":["#### Training and Testing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GbIBJG7r7ZJI","outputId":"4ca8be93-615a-4268-fc7b-feecb1b89c7a","executionInfo":{"status":"ok","timestamp":1584326525763,"user_tz":420,"elapsed":3332740,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","X_cwt_test, y_cwt_test, person_cwt_test = cwt_data2(X_test, y_test, person_test, num_levels, top_scale=top_scale)\n","\n","TestRNN(model, X_cwt_test, y_cwt_test, person_cwt_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.4506\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IzJOB7HsrkCk","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"87Jw3J2R11Lf","colab_type":"text"},"source":["#ICA 15"]},{"cell_type":"code","metadata":{"id":"2pRdeLBeiHW6","colab_type":"code","colab":{}},"source":["X_train_ICA = np.load(dataset_path + \"X_train_ICA15.npy\")\n","X_test_ICA  = np.load(dataset_path + \"X_test_ICA15.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"el553ed8dYy6","colab_type":"code","outputId":"7f6eb959-67c7-408c-e196-4f1b90b6bebd","executionInfo":{"status":"ok","timestamp":1584381193176,"user_tz":420,"elapsed":7838,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_fold, val_fold = Train_Val_Data(X_train_ICA, y_train_valid)\n","X_train_ICA[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1692, 15, 1000)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"V6gDszTNihf7","colab_type":"code","outputId":"2bea837d-e314-4d84-a0bc-3a970080fd63","executionInfo":{"status":"error","timestamp":1584381203631,"user_tz":420,"elapsed":15772,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":452}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 500\n","stride = 200 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 100\n","k = 0\n","dropout = 0.25\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.001]\n","X_train, y_train, p_train = X_train_ICA[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","X_val, y_val, p_val = X_train_ICA[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', input_size=X_train.shape[1], dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.001\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-6972c4d1a9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlrn_rt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlrn_rt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# indicate hyperparameters here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInitRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'GRU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlrn_rt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'lrn_rt {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrn_rt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mInitRNN\u001b[0;34m(rnn_type, input_size, rnn_input_size, hidden_size, rnn2_input_size, hidden_size2, output_dim, dropout, lr, weight_decay)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mrnn_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"GRU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mrnn_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"GRU2HiddenDimsnet\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# Resets _flat_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"gf0EEKot1Wmp","colab_type":"code","outputId":"8754e170-2a24-416e-e80c-ba8c6fed2d18","executionInfo":{"status":"ok","timestamp":1584303322314,"user_tz":420,"elapsed":6192,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","TestRNN(model, X_test_ICA, y_test, person_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.2641\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ahtwDVB0w102","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DTAZ-yDKw2ZM"},"source":["#ICA 5"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xluHHe_Ow2ZP","colab":{}},"source":["X_train_ICA = np.load(dataset_path + \"X_train_ICA5.npy\")\n","X_test_ICA  = np.load(dataset_path + \"X_test_ICA5.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"9a3f6c8a-3c4e-4ff2-b6f6-e13aa31abdcc","executionInfo":{"status":"ok","timestamp":1584322535476,"user_tz":420,"elapsed":175,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"ddKEuCXpw2ZS","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_fold, val_fold = Train_Val_Data(X_train_ICA, y_train_valid)\n","X_train_ICA[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1692, 5, 1000)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"1b395ec9-5c24-4ed2-b78c-9769b10ba94b","executionInfo":{"status":"ok","timestamp":1584323187942,"user_tz":420,"elapsed":652471,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"8e5oXTPuw2ZV","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 500\n","stride = 200 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 100\n","k = 0\n","dropout = 0.25\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.001]\n","X_train, y_train, p_train = X_train_ICA[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","X_val, y_val, p_val = X_train_ICA[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', input_size=X_train.shape[1], dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.001\n","lrn_rt 0.001\n","epoch: 1      time: 6.51    loss: 37.522    train acc: 0.245    val acc: 0.251\n","saving best model...\n","epoch: 2      time: 6.51    loss: 37.445    train acc: 0.237    val acc: 0.243\n","epoch: 3      time: 6.52    loss: 37.428    train acc: 0.252    val acc: 0.251\n","saving best model...\n","epoch: 4      time: 6.52    loss: 37.438    train acc: 0.260    val acc: 0.251\n","saving best model...\n","epoch: 5      time: 6.49    loss: 37.438    train acc: 0.259    val acc: 0.251\n","saving best model...\n","epoch: 6      time: 6.50    loss: 37.442    train acc: 0.251    val acc: 0.251\n","saving best model...\n","epoch: 7      time: 6.49    loss: 37.424    train acc: 0.259    val acc: 0.251\n","saving best model...\n","epoch: 8      time: 6.50    loss: 37.430    train acc: 0.254    val acc: 0.251\n","saving best model...\n","epoch: 9      time: 6.51    loss: 37.438    train acc: 0.260    val acc: 0.251\n","saving best model...\n","epoch: 10     time: 6.53    loss: 37.433    train acc: 0.254    val acc: 0.251\n","saving best model...\n","epoch: 11     time: 6.53    loss: 37.432    train acc: 0.257    val acc: 0.251\n","saving best model...\n","epoch: 12     time: 6.51    loss: 37.427    train acc: 0.260    val acc: 0.251\n","saving best model...\n","epoch: 13     time: 6.52    loss: 37.426    train acc: 0.261    val acc: 0.239\n","epoch: 14     time: 6.50    loss: 37.440    train acc: 0.255    val acc: 0.251\n","saving best model...\n","epoch: 15     time: 6.50    loss: 37.430    train acc: 0.244    val acc: 0.248\n","epoch: 16     time: 6.51    loss: 37.429    train acc: 0.251    val acc: 0.243\n","epoch: 17     time: 6.53    loss: 37.447    train acc: 0.256    val acc: 0.251\n","saving best model...\n","epoch: 18     time: 6.52    loss: 37.435    train acc: 0.251    val acc: 0.251\n","saving best model...\n","epoch: 19     time: 6.51    loss: 37.423    train acc: 0.257    val acc: 0.251\n","saving best model...\n","epoch: 20     time: 6.52    loss: 37.415    train acc: 0.258    val acc: 0.251\n","saving best model...\n","epoch: 21     time: 6.50    loss: 37.417    train acc: 0.259    val acc: 0.251\n","saving best model...\n","epoch: 22     time: 6.50    loss: 37.435    train acc: 0.254    val acc: 0.251\n","saving best model...\n","epoch: 23     time: 6.51    loss: 37.433    train acc: 0.254    val acc: 0.251\n","saving best model...\n","epoch: 24     time: 6.53    loss: 37.432    train acc: 0.256    val acc: 0.251\n","saving best model...\n","epoch: 25     time: 6.52    loss: 37.433    train acc: 0.244    val acc: 0.251\n","saving best model...\n","epoch: 26     time: 6.51    loss: 37.416    train acc: 0.259    val acc: 0.243\n","epoch: 27     time: 6.51    loss: 37.418    train acc: 0.261    val acc: 0.251\n","saving best model...\n","epoch: 28     time: 6.51    loss: 37.415    train acc: 0.269    val acc: 0.251\n","saving best model...\n","epoch: 29     time: 6.51    loss: 37.407    train acc: 0.266    val acc: 0.251\n","saving best model...\n","epoch: 30     time: 6.52    loss: 37.416    train acc: 0.255    val acc: 0.251\n","saving best model...\n","epoch: 31     time: 6.53    loss: 37.409    train acc: 0.253    val acc: 0.251\n","saving best model...\n","epoch: 32     time: 6.52    loss: 37.416    train acc: 0.261    val acc: 0.248\n","epoch: 33     time: 6.51    loss: 37.403    train acc: 0.257    val acc: 0.251\n","saving best model...\n","epoch: 34     time: 6.52    loss: 37.413    train acc: 0.257    val acc: 0.262\n","saving best model...\n","epoch: 35     time: 6.51    loss: 37.403    train acc: 0.259    val acc: 0.251\n","epoch: 36     time: 6.51    loss: 37.392    train acc: 0.263    val acc: 0.253\n","epoch: 37     time: 6.52    loss: 37.402    train acc: 0.258    val acc: 0.251\n","epoch: 38     time: 6.54    loss: 37.401    train acc: 0.253    val acc: 0.243\n","epoch: 39     time: 6.52    loss: 37.388    train acc: 0.262    val acc: 0.253\n","epoch: 40     time: 6.51    loss: 37.388    train acc: 0.269    val acc: 0.227\n","epoch: 41     time: 6.51    loss: 37.396    train acc: 0.266    val acc: 0.251\n","epoch: 42     time: 6.50    loss: 37.378    train acc: 0.272    val acc: 0.251\n","epoch: 43     time: 6.50    loss: 37.389    train acc: 0.260    val acc: 0.227\n","epoch: 44     time: 6.51    loss: 37.372    train acc: 0.275    val acc: 0.251\n","epoch: 45     time: 6.54    loss: 37.363    train acc: 0.269    val acc: 0.232\n","epoch: 46     time: 6.52    loss: 37.364    train acc: 0.274    val acc: 0.251\n","epoch: 47     time: 6.51    loss: 37.339    train acc: 0.280    val acc: 0.232\n","epoch: 48     time: 6.52    loss: 37.359    train acc: 0.272    val acc: 0.217\n","epoch: 49     time: 6.51    loss: 37.354    train acc: 0.273    val acc: 0.248\n","epoch: 50     time: 6.51    loss: 37.364    train acc: 0.269    val acc: 0.241\n","epoch: 51     time: 6.53    loss: 37.332    train acc: 0.279    val acc: 0.262\n","saving best model...\n","epoch: 52     time: 6.53    loss: 37.347    train acc: 0.270    val acc: 0.215\n","epoch: 53     time: 6.53    loss: 37.361    train acc: 0.272    val acc: 0.251\n","epoch: 54     time: 6.51    loss: 37.322    train acc: 0.276    val acc: 0.260\n","epoch: 55     time: 6.52    loss: 37.301    train acc: 0.281    val acc: 0.234\n","epoch: 56     time: 6.51    loss: 37.317    train acc: 0.287    val acc: 0.213\n","epoch: 57     time: 6.51    loss: 37.359    train acc: 0.269    val acc: 0.246\n","epoch: 58     time: 6.52    loss: 37.323    train acc: 0.277    val acc: 0.241\n","epoch: 59     time: 6.54    loss: 37.304    train acc: 0.278    val acc: 0.258\n","epoch: 60     time: 6.53    loss: 37.293    train acc: 0.281    val acc: 0.265\n","saving best model...\n","epoch: 61     time: 6.51    loss: 37.333    train acc: 0.273    val acc: 0.229\n","epoch: 62     time: 6.52    loss: 37.312    train acc: 0.282    val acc: 0.229\n","epoch: 63     time: 6.51    loss: 37.270    train acc: 0.277    val acc: 0.208\n","epoch: 64     time: 6.51    loss: 37.288    train acc: 0.289    val acc: 0.227\n","epoch: 65     time: 6.52    loss: 37.294    train acc: 0.288    val acc: 0.253\n","epoch: 66     time: 6.54    loss: 37.260    train acc: 0.286    val acc: 0.236\n","epoch: 67     time: 6.52    loss: 37.253    train acc: 0.286    val acc: 0.246\n","epoch: 68     time: 6.52    loss: 37.275    train acc: 0.288    val acc: 0.258\n","epoch: 69     time: 6.52    loss: 37.194    train acc: 0.286    val acc: 0.246\n","epoch: 70     time: 6.51    loss: 37.238    train acc: 0.284    val acc: 0.265\n","saving best model...\n","epoch: 71     time: 6.52    loss: 37.243    train acc: 0.277    val acc: 0.272\n","saving best model...\n","epoch: 72     time: 6.52    loss: 37.188    train acc: 0.291    val acc: 0.274\n","saving best model...\n","epoch: 73     time: 6.55    loss: 37.204    train acc: 0.291    val acc: 0.281\n","saving best model...\n","epoch: 74     time: 6.53    loss: 37.170    train acc: 0.286    val acc: 0.255\n","epoch: 75     time: 6.53    loss: 37.103    train acc: 0.292    val acc: 0.253\n","epoch: 76     time: 6.52    loss: 37.120    train acc: 0.288    val acc: 0.251\n","epoch: 77     time: 6.51    loss: 37.085    train acc: 0.298    val acc: 0.260\n","epoch: 78     time: 6.51    loss: 37.110    train acc: 0.295    val acc: 0.251\n","epoch: 79     time: 6.52    loss: 37.094    train acc: 0.291    val acc: 0.281\n","saving best model...\n","epoch: 80     time: 6.54    loss: 37.049    train acc: 0.295    val acc: 0.255\n","epoch: 81     time: 6.52    loss: 37.064    train acc: 0.292    val acc: 0.262\n","epoch: 82     time: 6.52    loss: 37.055    train acc: 0.293    val acc: 0.284\n","saving best model...\n","epoch: 83     time: 6.53    loss: 36.980    train acc: 0.297    val acc: 0.248\n","epoch: 84     time: 6.51    loss: 36.975    train acc: 0.298    val acc: 0.251\n","epoch: 85     time: 6.52    loss: 37.028    train acc: 0.287    val acc: 0.260\n","epoch: 86     time: 6.54    loss: 37.030    train acc: 0.290    val acc: 0.291\n","saving best model...\n","epoch: 87     time: 6.56    loss: 36.888    train acc: 0.301    val acc: 0.291\n","saving best model...\n","epoch: 88     time: 6.55    loss: 36.864    train acc: 0.303    val acc: 0.246\n","epoch: 89     time: 6.53    loss: 36.936    train acc: 0.300    val acc: 0.251\n","epoch: 90     time: 6.54    loss: 36.849    train acc: 0.307    val acc: 0.286\n","epoch: 91     time: 6.53    loss: 36.889    train acc: 0.309    val acc: 0.288\n","epoch: 92     time: 6.54    loss: 36.819    train acc: 0.300    val acc: 0.310\n","saving best model...\n","epoch: 93     time: 6.56    loss: 36.781    train acc: 0.304    val acc: 0.260\n","epoch: 94     time: 6.56    loss: 36.833    train acc: 0.300    val acc: 0.303\n","epoch: 95     time: 6.55    loss: 36.803    train acc: 0.305    val acc: 0.251\n","epoch: 96     time: 6.54    loss: 36.683    train acc: 0.317    val acc: 0.267\n","epoch: 97     time: 6.53    loss: 36.736    train acc: 0.319    val acc: 0.296\n","epoch: 98     time: 6.54    loss: 36.683    train acc: 0.323    val acc: 0.286\n","epoch: 99     time: 6.53    loss: 36.689    train acc: 0.313    val acc: 0.300\n","epoch: 100    time: 6.54    loss: 36.674    train acc: 0.309    val acc: 0.286\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"311c9b9d-980c-4fc8-b945-2710e150af2c","executionInfo":{"status":"ok","timestamp":1584323192944,"user_tz":420,"elapsed":5009,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"OmGIof_Bw2ZW","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Uncomment if using cwt\n","TestRNN(model, X_test_ICA, y_test, person_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.2935\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5o4B0FrQCtqI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m2p1w8gqCt6Q"},"source":["#ICA 10 BP filtered (30,50hz)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Kzq4cV16Ct6V","colab":{}},"source":["X_train_ICA = np.load(dataset_path + \"X_train_ICA10.npy\")\n","X_test_ICA  = np.load(dataset_path + \"X_test_ICA10.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"5d76ed51-aa9d-42ac-922b-0625d7977071","executionInfo":{"status":"ok","timestamp":1584408677663,"user_tz":420,"elapsed":1711,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"id":"TjLATThFCt6Y","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_fold, val_fold = Train_Val_Data(X_train_ICA, y_train_valid)\n","X_train_ICA[train_fold[0]].shape"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1692, 10, 1000)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"5dd5744b-17fc-4dd8-b731-b52c5ef66749","executionInfo":{"status":"error","timestamp":1584382085450,"user_tz":420,"elapsed":841178,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"dZrkpjl_Ct6a","colab":{"base_uri":"https://localhost:8080/","height":485}},"source":["# setting up the data augmentation here\n","aug_type = \"window\"\n","window_size = 200\n","stride = 50 # Make 20 normally\n","vote_num = 50 # Make 20 normally\n","num_folds = 1\n","num_epochs = 100\n","k = 0\n","dropout = 0.25\n","\n","#drops = [0.5, 0.75]\n","learn_rates = [0.001, 0.0005, 0.0001]\n","lrn_rt = [0.001]\n","X_train, y_train, p_train = X_train_ICA[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","X_val, y_val, p_val = X_train_ICA[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","\n","for lrn_rt in lrn_rt:\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='GRU', input_size=X_train.shape[1], dropout=dropout, weight_decay=0, lr=lrn_rt)\n","    print ('lrn_rt {}'.format(lrn_rt))\n","    \n","    # Uncomment for just windowing\n","    # X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    # X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","\n","    # Uncomment for cwt\n","    best_model = TrainValRNN(model, criterion, optimizer, EEG_trainloader, EEG_valloader, num_epochs=num_epochs, aug_type=aug_type, window_size=window_size, vote_num=vote_num)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RNN TYPE: GRU\n","WEIGHT DECAY: 0\n","LEARNING RATE: 0.001\n","lrn_rt 0.001\n","epoch: 1      time: 7.01    loss: 294.036    train acc: 0.253    val acc: 0.243\n","saving best model...\n","epoch: 2      time: 6.98    loss: 293.933    train acc: 0.253    val acc: 0.251\n","saving best model...\n","epoch: 3      time: 7.01    loss: 293.878    train acc: 0.255    val acc: 0.255\n","saving best model...\n","epoch: 4      time: 7.02    loss: 293.876    train acc: 0.258    val acc: 0.251\n","epoch: 5      time: 6.98    loss: 293.893    train acc: 0.257    val acc: 0.251\n","epoch: 6      time: 6.99    loss: 293.884    train acc: 0.255    val acc: 0.251\n","epoch: 7      time: 6.96    loss: 293.851    train acc: 0.256    val acc: 0.251\n","epoch: 8      time: 6.97    loss: 293.868    train acc: 0.257    val acc: 0.267\n","saving best model...\n","epoch: 9      time: 6.96    loss: 293.831    train acc: 0.257    val acc: 0.243\n","epoch: 10     time: 6.99    loss: 293.812    train acc: 0.256    val acc: 0.251\n","epoch: 11     time: 7.00    loss: 293.804    train acc: 0.257    val acc: 0.267\n","saving best model...\n","epoch: 12     time: 7.00    loss: 293.791    train acc: 0.260    val acc: 0.243\n","epoch: 13     time: 6.96    loss: 293.760    train acc: 0.261    val acc: 0.255\n","epoch: 14     time: 7.01    loss: 293.742    train acc: 0.259    val acc: 0.251\n","epoch: 15     time: 6.93    loss: 293.714    train acc: 0.260    val acc: 0.251\n","epoch: 16     time: 7.01    loss: 293.649    train acc: 0.264    val acc: 0.253\n","epoch: 17     time: 6.99    loss: 293.533    train acc: 0.269    val acc: 0.251\n","epoch: 18     time: 7.04    loss: 293.355    train acc: 0.275    val acc: 0.253\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"0973c988-fc23-4e57-f7b7-318f9de1966c","executionInfo":{"status":"error","timestamp":1584382086731,"user_tz":420,"elapsed":1259,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"id":"lp_TR4pdCt6c","colab":{"base_uri":"https://localhost:8080/","height":331}},"source":["# Uncomment if using cwt\n","TestRNN(model, X_test_ICA, y_test, person_test, aug_type=aug_type, window_size=window_size, vote_num=vote_num)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-af1f79e060ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTestRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_ICA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvote_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvote_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mTestRNN\u001b[0;34m(model, X_test, y_test, p_test, aug_type, window_size, vote_num)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0mX_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# type: (Tensor, Tensor, Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    157\u001b[0m             raise RuntimeError(\n\u001b[1;32m    158\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 159\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 10, got 5"]}]},{"cell_type":"code","metadata":{"id":"5veOEtUpiFfb","colab_type":"code","outputId":"7a1c44da-6738-45c8-e4c2-7e4a5a9bc40b","executionInfo":{"status":"ok","timestamp":1584382115992,"user_tz":420,"elapsed":1293,"user":{"displayName":"EDEN HANEY","photoUrl":"","userId":"04611419970615248408"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_test_ICA.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(443, 5, 1000)"]},"metadata":{"tags":[]},"execution_count":14}]}]}