{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAP4Xq9ChQlShHyvtD4kfl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuaghannan/ECEC247_Project/blob/jgh_tests/PyTorch_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRC_TvBW95cp",
        "colab_type": "code",
        "outputId": "3d47754f-5bec-4e92-a15d-2512f4812d85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LmV7rk2-CZi",
        "colab_type": "code",
        "outputId": "6b2cd416-e04d-4b3b-8037-ebda171d3774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "# Create a folder \"C247\" and then store the project datasets within that folder\n",
        "# Check that your datasets are setup correctly\n",
        "\n",
        "!ls \"/content/gdrive/My Drive/C247\" # File path"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EEG_loading.ipynb\tPyTorch_Experiments.ipynb  y_test.npy\n",
            "person_test.npy\t\tX_test.npy\t\t   y_train_valid.npy\n",
            "person_train_valid.npy\tX_train_valid.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amxahzg9-USr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5R4bd9RA9P-",
        "colab_type": "text"
      },
      "source": [
        "### Load the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uct22u9G--Er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_test = np.load(\"X_test.npy\")\n",
        "# y_test = np.load(\"y_test.npy\")\n",
        "# person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "# X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "# y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "# person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "# Change if your directory is different\n",
        "dataset_path = \"/content/gdrive/My Drive/C247/\" \n",
        "\n",
        "X_test = np.load(dataset_path + \"X_test.npy\")\n",
        "y_test = np.load(dataset_path + \"y_test.npy\")\n",
        "person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n",
        "X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n",
        "y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n",
        "person_test = np.load(dataset_path + \"person_test.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkAvOL9zAZY8",
        "colab_type": "text"
      },
      "source": [
        "### Shape of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfS5NWq-_E_r",
        "colab_type": "code",
        "outputId": "9d6fcb63-6e11-44c4-b130-e386e235aeed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A-pffLsBXQ5",
        "colab_type": "text"
      },
      "source": [
        "### Setting Up PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAITlVTI9GQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4KP5Jzw9umr",
        "colab_type": "code",
        "outputId": "a9ee8523-286a-4e9d-8228-c226740f0a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7.8273e-20, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 2.8026e-45],\n",
            "        [0.0000e+00, 1.1210e-44, 0.0000e+00],\n",
            "        [1.4013e-45, 0.0000e+00, 0.0000e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIhJ9SnH9392",
        "colab_type": "code",
        "outputId": "ea79dd11-6226-4c24-ca00-9952307d2999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.rand(5, 3)\n",
        "print(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3476, 0.1593, 0.6721],\n",
            "        [0.8787, 0.9533, 0.8951],\n",
            "        [0.6239, 0.0484, 0.4140],\n",
            "        [0.0075, 0.7418, 0.3758],\n",
            "        [0.6572, 0.3513, 0.8094]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oQmnw3G98L2",
        "colab_type": "code",
        "outputId": "ffdf99a6-4606-4f00-d84e-612c46508417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "x = torch.zeros(5, 3, dtype=torch.long)\n",
        "print(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9ROQVO2-AcG",
        "colab_type": "code",
        "outputId": "eac81636-5559-4569-c635-80c8d29d4c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.tensor([5.5, 3])\n",
        "print(x)\n",
        "print(x.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.5000, 3.0000])\n",
            "torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DX-SZfYB-HHd",
        "colab_type": "code",
        "outputId": "38f0a626-f88d-42ab-9044-a95beb56c8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = torch.rand(1, 2)\n",
        "print(x+y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.5341, 3.9683]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq7EPXVl-UXP",
        "colab_type": "code",
        "outputId": "6eb4024c-4c67-4c8f-e2f4-53a473f0b700",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "result = torch.empty(1,2)\n",
        "torch.add(x, y, out=result)\n",
        "print(result)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.5341, 3.9683]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n-dFrDv-aq3",
        "colab_type": "code",
        "outputId": "4da84cc1-2a41-47d2-edc1-e79ca1886836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.add_(x)\n",
        "print(y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5.5341, 3.9683]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIB8sQm5_Ycu",
        "colab_type": "code",
        "outputId": "cd8072f3-9138-4a59-f385-728da50f6128",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "q = torch.rand(5,3)\n",
        "print(q)\n",
        "print(q[1][:])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3645, 0.8456, 0.7205],\n",
            "        [0.1364, 0.6892, 0.0677],\n",
            "        [0.1496, 0.9523, 0.8470],\n",
            "        [0.1503, 0.1617, 0.4301],\n",
            "        [0.2088, 0.3136, 0.1768]])\n",
            "tensor([0.1364, 0.6892, 0.0677])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RsCt38n_hgj",
        "colab_type": "code",
        "outputId": "5e98229b-6b6d-4229-b78b-ffe80f37275c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "b = a.numpy()\n",
        "print(b)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI6rDol3CsuS",
        "colab_type": "code",
        "outputId": "ddad7dae-10bd-4390-b5b5-4d418ba6fc14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([6.5000, 4.0000], device='cuda:0')\n",
            "tensor([6.5000, 4.0000], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl6xZWrkCxCV",
        "colab_type": "code",
        "outputId": "36f0f0fc-4177-416f-9ea7-6b00187b6281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oxa_Nzg0yd-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbg9pfFYyp0o",
        "colab_type": "code",
        "outputId": "01d48703-81b5-412f-a773-12296b297243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(y)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdI1_rNryq3n",
        "colab_type": "code",
        "outputId": "2f54327e-49c7-43ba-e6ea-387343110f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<AddBackward0 object at 0x7f1184c33198>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybntYITuyuxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = y*x*2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_eVsTevyy8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = z.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSw47RNay15W",
        "colab_type": "code",
        "outputId": "6c8eec1a-dca4-4934-c4d2-883a36362efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(z,out)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.]], grad_fn=<MulBackward0>) tensor(6., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT-YAkKby2zv",
        "colab_type": "code",
        "outputId": "e520aaca-5fcd-44f0-9d42-8b98a0b50e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mVm6wgry6NH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDrhdUA1zP8c",
        "colab_type": "code",
        "outputId": "28169b49-9c70-4e1f-8b15-07dce13256aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 2.],\n",
            "        [2., 2.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpueIuETzlDT",
        "colab_type": "code",
        "outputId": "c2842033-2027-4fb1-a57a-0f419abfb947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.0374, -0.4126,  0.6264], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9abHlqNOz3aJ",
        "colab_type": "code",
        "outputId": "c315ea01-3120-45ee-cc65-082fc36f8d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ -76.6755, -844.9108, 1282.9456], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9pHhttMz8_J",
        "colab_type": "code",
        "outputId": "6360cf61-7e1a-49b4-fb3d-8e601783c925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
        "y.backward(v)\n",
        "\n",
        "print(x.grad)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXYpyeYz0f2u",
        "colab_type": "code",
        "outputId": "dab28628-5e42-4dc7-ca2d-e61ab4d0c40e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "print((x ** 2).requires_grad)\n",
        "\n",
        "with torch.no_grad(): # blocks from tracking gradient history\n",
        "    print((x ** 2).requires_grad)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81pp3fkC02l-",
        "colab_type": "code",
        "outputId": "661539a1-4cb0-4ee7-8816-f90d1610cb0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x.requires_grad)\n",
        "y = x.detach() # creates new tensor with same content that doesn't require gradients\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all()) # check that they're the same"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts_KqB9p1J20",
        "colab_type": "text"
      },
      "source": [
        "### Creating NNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKbGWYTz1CYc",
        "colab_type": "code",
        "outputId": "b063691c-2927-4761-e512-b819ec47f636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    # Backward function is automatically computed \n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-edRRTkJ2klD",
        "colab_type": "code",
        "outputId": "c1a05270-26bf-4777-df18-d43411bfbec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's .weight"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6WwYw-p3HLR",
        "colab_type": "code",
        "outputId": "2c257494-2536-4e24-b89f-7b4e48eb292f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0109, -0.0495,  0.0846,  0.0580, -0.0097,  0.0049,  0.0533,  0.0519,\n",
            "          0.1561,  0.0312]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVeMT5d13s-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkS9Fasq3x1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PyTorch only supports minibatching"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7erd7m-84nk",
        "colab_type": "text"
      },
      "source": [
        "### Creating a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUiPurPo38FW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNwqeh1NDYLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ebd7a358-fc7d-4abf-985f-333cca2017dc"
      },
      "source": [
        "num_in = 10\n",
        "num_hidden = 50\n",
        "\n",
        "# for h = relu(Wx + b)\n",
        "# they actually have values (unlike TF)\n",
        "# use requires_grad=True so it can calc gradients\n",
        "# Pytorch Variables are wrappers for tensors\n",
        "  # Stores the value of the tensor (x.data)\n",
        "  # if requires_grad = true, holds another varaible\n",
        "  # (x.grad which holds grads). Thus, x.grad.data is pytorch tensor that contains\n",
        "  # the values of the gradient of x\n",
        "\n",
        "# x = Variable(torch.randn(num_in), requires_grad=True)\n",
        "# W = Variable(torch.randn(num_hidden, num_in), requires_grad=True)\n",
        "# b = Variable(torch.randn(num_hidden), requires_grad=True)\n",
        "\n",
        "# use .cuda() to enable GPU use\n",
        "x = Variable(torch.randn(num_in).cuda(), requires_grad=True)\n",
        "W = Variable(torch.randn(num_hidden, num_in).cuda(), requires_grad=True)\n",
        "b = Variable(torch.randn(num_hidden).cuda(), requires_grad=True)\n",
        "\n",
        "z = torch.matmul(W,x) + b\n",
        "h = torch.max(z, torch.zeros(num_hidden).cuda())\n",
        "\n",
        "# loss function\n",
        "loss = (torch.sum(h)-1).pow(2)\n",
        "\n",
        "# takes loss function, does back prop to calc gradient\n",
        "# for each variable with req_gradient = true\n",
        "loss.backward()\n",
        "print(x.grad.data.shape)\n",
        "print(W.grad.data.shape)\n",
        "print(b.grad.data.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n",
            "torch.Size([50, 10])\n",
            "torch.Size([50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS98UG95sxOt",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch CNN Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC0008P8D4zD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn # imports all nn layers\n",
        "\n",
        "import torch.optim as optim # imports different optimizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THOEsSs4MZLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NN for CIFAR-10\n",
        "model = nn.Sequential (\n",
        "    # Conv2d: depth, # filters, filter size (7x7xdepth)\n",
        "    nn.Conv2d(3, 32, kernel_size=7, stride=1), # 32x32x3 input, 10 outputs\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.BatchNorm2d(num_features=32),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2), # 13x13x32 feature map, with 5408 values\n",
        "    # keep track of dimensions\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(5408, 1024), # Default weight initialization is Xavier Uniform\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(1024, 10), # Default weight initialization is Xavier Uniform\n",
        ")\n",
        "\n",
        "# To run on CPU:\n",
        "# dtype = torch.FloatTensor \n",
        "\n",
        "# To run on GPU:\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "model.type(dtype)\n",
        "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=1e-02)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2jfvBqeRbgy",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKH2ZlBpRe6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "fb7e7c20-3631-457d-a520-9d345f95f89b"
      },
      "source": [
        "# Run on GPU\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "N, C, H, W = 128, 3, 32, 32 # 128 examples, 32x32x3 random numbers\n",
        "x = Variable(torch.randn(N, C, H, W).cuda()) # input\n",
        "y = np.random.randint(0, 10, size=128) # labels\n",
        "y = Variable(torch.Tensor(y).cuda(), requires_grad=False)\n",
        "x.type(dtype)\n",
        "y.type(dtype)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 4., 3., 8., 3., 7., 8., 9., 3., 5., 6., 6., 1., 9., 1., 8., 2., 2.,\n",
              "        5., 6., 2., 3., 6., 5., 8., 6., 1., 7., 5., 5., 7., 9., 5., 0., 1., 6.,\n",
              "        4., 4., 2., 0., 4., 4., 8., 6., 3., 9., 9., 0., 8., 6., 4., 6., 0., 4.,\n",
              "        5., 5., 9., 7., 6., 4., 9., 7., 0., 5., 5., 1., 9., 0., 2., 4., 5., 0.,\n",
              "        0., 1., 9., 1., 0., 9., 4., 6., 5., 3., 4., 9., 3., 8., 0., 1., 1., 6.,\n",
              "        7., 5., 6., 5., 5., 8., 8., 0., 0., 7., 7., 0., 6., 0., 2., 9., 5., 9.,\n",
              "        4., 7., 5., 1., 1., 1., 1., 4., 5., 1., 4., 8., 4., 0., 3., 1., 5., 4.,\n",
              "        6., 1.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkVa0NsYSOsA",
        "colab_type": "text"
      },
      "source": [
        "### Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDv6b7mpSP6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential (\n",
        "    # Conv2d: depth, # filters, filter size (7x7xdepth)\n",
        "    nn.Conv2d(3, 32, kernel_size=7, stride=1), # 32x32x3 input, 10 outputs\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.BatchNorm2d(num_features=32),\n",
        "    nn.MaxPool2d(kernel_size=2, stride=2), # 13x13x32 feature map, with 5408 values\n",
        "    # keep track of dimensions\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(5408, 1024), # Default weight initialization is Xavier Uniform\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Linear(1024, 10), # Default weight initialization is Xavier Uniform\n",
        ")\n",
        "\n",
        "model.type(dtype)\n",
        "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=1e-02)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JXtnWe8TOi4",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQJnxxsKSr2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1968f2be-0a43-4928-e32b-7043c4d420c0"
      },
      "source": [
        "for t in range(10):\n",
        "\n",
        "  # Calculate the loss\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y.type(torch.LongTensor).cuda())\n",
        "\n",
        "  # Do backprop\n",
        "  model.zero_grad() # do this so that PyTorch doesn't add gradients for CNNs (don't call for RNN)\n",
        "  loss.backward()\n",
        "\n",
        "  # Optimize the parameters\n",
        "  optimizer.step()\n",
        "\n",
        "  print(t)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sp-CzSpVaS9",
        "colab_type": "text"
      },
      "source": [
        "### Model Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDetN-kVTqxf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b293ecb-ba13-4211-8932-c058f4faa325"
      },
      "source": [
        "y_pred = model(x)\n",
        "loss = loss_fn(y_pred, y.type(torch.LongTensor).cuda())\n",
        "print(loss)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0., device='cuda:0', grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhqXDsZVVlGj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f6ebbadb-0ead-44f1-f7fd-6df84086dffd"
      },
      "source": [
        "model # prints the model params"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(1, 1))\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (4): Flatten()\n",
              "  (5): Linear(in_features=5408, out_features=1024, bias=True)\n",
              "  (6): ReLU(inplace=True)\n",
              "  (7): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKZNkS9ZVwNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use DataLoader to input new data (also does minibatching, shuffling, etc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eApqynzuV4Pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use import torchvision to get pretrained models (alexnet, vgg, etc.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c2CVJ7paxGz",
        "colab_type": "text"
      },
      "source": [
        "### TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5ydpUAhV9pR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c0aa8038-50ff-416d-dd88-ec2e4ff73b6e"
      },
      "source": [
        "import numpy as np\n",
        "# import tensorflow as tf\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lifvWnVbjD4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b95871f4-295b-453a-b825-7d5cc7df04d9"
      },
      "source": [
        "tf.reset_default_graph() # clear old variables\n",
        "# tf.compat.v1.reset_default_graph()\n",
        "\n",
        "# define input (data that changes every batch)\n",
        "# first dim is None, so the data is automatically based on batch size fed in\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
        "y = tf.placeholder(tf.int64, [None])\n",
        "\n",
        "# Define the model\n",
        "# variables (unlike placeholders) need to be initialized to some value (using Xavier)\n",
        "W1 = tf.get_variable('W1', shape=[7, 7, 3, 32])\n",
        "b1 = tf.get_variable('b1', shape=[32])\n",
        "W2 = tf.get_variable('W2', shape=[5408, 1024])\n",
        "b2 = tf.get_variable('b2', shape=[1024])\n",
        "W3 = tf.get_variable('W3', shape=[1024, 10])\n",
        "b3 = tf.get_variable('b3', shape=[10])\n",
        "\n",
        "# Define the computational graph\n",
        "a1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='VALID') +b1\n",
        "h1 = tf.nn.relu(a1)\n",
        "z2 = tf.nn.max_pool(h1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"VALID\")\n",
        "z2_flat = tf.reshape(z2, [-1, 5408])\n",
        "a2 = tf.matmul(z2_flat, W2) + b2\n",
        "h2 = tf.nn.relu(a2)\n",
        "y_out = tf.matmul(h2, W3) + b3\n",
        "\n",
        "# define loss and optimizer\n",
        "# logits are scroes\n",
        "# cross entropy accepts onehot input (instead of classes like 1 - 10)\n",
        "total_loss = tf.losses.softmax_cross_entropy(tf.one_hot(y,10), logits=y_out)\n",
        "# total_loss = tf.nn.softmax_cross_entroy_with_logits_v2(tf.one_hot(y,10), logits=y_out)\n",
        "mean_loss = tf.reduce_mean(total_loss)\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBhaZ-Jtg41S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tf.config.set_soft_device_placement(True)\n",
        "\n",
        "# define te weight updates\n",
        "learning_rate = 1e-02\n",
        "grad_W1, grad_b1, grad_W2, grad_b2, grad_W3, grad_b3 = tf.gradients(mean_loss, (W1, b1, W2, b2, W3, b3))\n",
        "new_W1 = W1.assign(W1 - learning_rate * grad_W1)\n",
        "new_W2 = W2.assign(W2 - learning_rate * grad_W2)\n",
        "new_W3 = W3.assign(W3 - learning_rate * grad_W3)\n",
        "new_b1 = b1.assign(b1 - learning_rate * grad_b1)\n",
        "new_b2 = b2.assign(b2 - learning_rate * grad_b2)\n",
        "new_b3 = b3.assign(b3 - learning_rate * grad_b3)\n",
        "\n",
        "# data set\n",
        "x_train = np.random.randn(64, 32, 32, 3)\n",
        "y_train = np.random.randint(0, 10, 64)\n",
        "\n",
        "losses=[]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  # with tf.device(\"/GPU:0\"): # \"/gpu:0\" or \"/cpu:0\"\n",
        "    tf.global_variables_initializer().run() # initial all the variable\n",
        "    feed_dict = {X: x_train,\n",
        "                 y: y_train,\n",
        "                 }\n",
        "    for t in range(50):\n",
        "      out = sess.run(mean_loss, feed_dict=feed_dict)\n",
        "      losses.append(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0rfbS7AmRiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "57c4a916-9378-433c-f968-35b1616160e0"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.show()\n",
        "# Didn't work because didn't compute new nodes"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxmFbhggAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4jOKAwGmqPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "tf.config.set_soft_device_placement(True)\n",
        "\n",
        "# define te weight updates\n",
        "learning_rate = 1e-02\n",
        "grad_W1, grad_b1, grad_W2, grad_b2, grad_W3, grad_b3 = tf.gradients(mean_loss, (W1, b1, W2, b2, W3, b3))\n",
        "new_W1 = W1.assign(W1 - learning_rate * grad_W1)\n",
        "new_W2 = W2.assign(W2 - learning_rate * grad_W2)\n",
        "new_W3 = W3.assign(W3 - learning_rate * grad_W3)\n",
        "new_b1 = b1.assign(b1 - learning_rate * grad_b1)\n",
        "new_b2 = b2.assign(b2 - learning_rate * grad_b2)\n",
        "new_b3 = b3.assign(b3 - learning_rate * grad_b3)\n",
        "# Tells it to calculate updates\n",
        "updates = tf.group(new_W1, new_W2, new_W3, new_b1, new_b2, new_b3)\n",
        "\n",
        "# data set\n",
        "x_train = np.random.randn(64, 32, 32, 3)\n",
        "y_train = np.random.randint(0, 10, 64)\n",
        "\n",
        "losses=[]\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  # with tf.device(\"/GPU:0\"): # \"/gpu:0\" or \"/cpu:0\"\n",
        "    tf.global_variables_initializer().run() # initial all the variable\n",
        "    feed_dict = {X: x_train,\n",
        "                 y: y_train,\n",
        "                 }\n",
        "    for t in range(50):\n",
        "      # Add updates\n",
        "      out = sess.run([mean_loss, updates], feed_dict=feed_dict)\n",
        "      losses.append(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4E42mRBnA6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "1b73aef1-0824-46eb-8e23-0851bad7036f"
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.show()\n",
        "# Updates better"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY7D7Nc3nMdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}