{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Updated_pipeline.ipynb","provenance":[],"collapsed_sections":["oQ7mRTjzEI2m"],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/joshuaghannan/ECEC247_Project/blob/master/Updated_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"A6BvVAE2tvB0","colab_type":"text"},"source":["#Setup"]},{"cell_type":"code","metadata":{"id":"ZsCG9DHzEI2B","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import scipy.signal as sig\n","import pywt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o80JLlxyEI2H","colab_type":"text"},"source":["### Set up the Device"]},{"cell_type":"code","metadata":{"id":"-HjZycAvEI2J","colab_type":"code","outputId":"80665227-41d7-48c2-ab44-b1b617b7aab1","executionInfo":{"status":"ok","timestamp":1583788911406,"user_tz":420,"elapsed":3509,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    # device = torch.device(\"cuda:1\") # For Yiming \n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["GPU not available, CPU used\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"26wpkKr9Em1E","colab_type":"text"},"source":["### If Using Colab"]},{"cell_type":"code","metadata":{"id":"KQwpQEszAQ9u","colab_type":"code","outputId":"6d3d643b-c26f-4bc4-d818-74a3e5304307","executionInfo":{"status":"ok","timestamp":1583788911407,"user_tz":420,"elapsed":3491,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["########################################################\n","\n","# If running with Google Colab\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E-S67grVAoSt","colab_type":"code","outputId":"fb7bfb7a-2e69-4608-97c4-592bab31dc61","executionInfo":{"status":"ok","timestamp":1583788912390,"user_tz":420,"elapsed":4456,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["########################################################\n","\n","# If running with Google Colab\n","# Create a folder \"C247\" and then store the project datasets within that folder\n","# Check that your datasets are setup correctly\n","\n","!ls \"/content/gdrive/My Drive/C247\" # File path"],"execution_count":5,"outputs":[{"output_type":"stream","text":["EEG_loading.ipynb  person_train_valid.npy  X_train_valid.npy\n","FinalProject\t   Updated_pipeline.ipynb  y_test.npy\n","person_test.npy    X_test.npy\t\t   y_train_valid.npy\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NiE2fkEzA3VO","colab_type":"text"},"source":["### Load the Datasets"]},{"cell_type":"code","metadata":{"id":"TJfyBLNLA686","colab_type":"code","outputId":"20917c9f-3219-4c61-b658-9ec6bcb327d4","executionInfo":{"status":"ok","timestamp":1583788920841,"user_tz":420,"elapsed":12892,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["# X_test = np.load(\"X_test.npy\")\n","# y_test = np.load(\"y_test.npy\")\n","# person_train_valid = np.load(\"person_train_valid.npy\")\n","# X_train_valid = np.load(\"X_train_valid.npy\")\n","# y_train_valid = np.load(\"y_train_valid.npy\")\n","# person_test = np.load(\"person_test.npy\")\n","\n","# Change if your directory is different\n","\n","# dataset_path = './data/' # Yiming Path\n","dataset_path = \"/content/gdrive/My Drive/C247/\" \n","\n","X_test = np.load(dataset_path + \"X_test.npy\")\n","y_test = np.load(dataset_path + \"y_test.npy\")\n","person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n","X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n","y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n","person_test = np.load(dataset_path + \"person_test.npy\")\n","print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n","print ('Test data shape: {}'.format(X_test.shape))\n","print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n","print ('Test target shape: {}'.format(y_test.shape))\n","print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n","print ('Person test shape: {}'.format(person_test.shape))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Training/Valid data shape: (2115, 22, 1000)\n","Test data shape: (443, 22, 1000)\n","Training/Valid target shape: (2115,)\n","Test target shape: (443,)\n","Person train/valid shape: (2115, 1)\n","Person test shape: (443, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gQEPDT85uAON","colab_type":"text"},"source":["# Data Manipulation"]},{"cell_type":"markdown","metadata":{"id":"JzSs4ByOEI2V","colab_type":"text"},"source":["### K-Fold"]},{"cell_type":"code","metadata":{"id":"LNKfnV6iEI2W","colab_type":"code","colab":{}},"source":["# some major changes here for the Train_Val_Data function\n","def Train_Val_Data(X_train_valid, y_train_val):\n","    '''\n","    split the train_valid into k folds (we fix k = 5 here)\n","    return: list of index of train data and val data of k folds\n","    train_fold[i], val_fold[i] is the index for training and validation in the i-th fold \n","\n","    '''\n","    fold_idx = []\n","    train_fold = []\n","    val_fold = []\n","    train_val_num = X_train_valid.shape[0]\n","    fold_num = int(train_val_num / 5)\n","    perm = np.random.permutation(train_val_num)\n","    for k in range(5):\n","        fold_idx.append(np.arange(k*fold_num, (k+1)*fold_num, 1))\n","    for k in range(5):\n","        val_fold.append(fold_idx[k])\n","        count = 0\n","        for i in range(5):\n","            if i != k:\n","                if count == 0:\n","                    train_idx = fold_idx[i]\n","                else:\n","                    train_idx = np.concatenate((train_idx, fold_idx[i]))\n","                count += 1\n","        train_fold.append(train_idx)\n","\n","    return train_fold, val_fold"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UuWOwEaeEI23","colab_type":"text"},"source":["### Customized Dataset"]},{"cell_type":"code","metadata":{"id":"b-Kbua1ZEI28","colab_type":"code","colab":{}},"source":["class EEG_Dataset(Dataset):\n","    '''\n","    use use fold_idx to instantiate different train val datasets for k-fold cross validation\n","\n","    '''\n","    def __init__ (self, X_train=None, y_train=None, p_train=None, X_val=None, y_val=None, p_val=None, X_test=None, y_test=None, p_test=None, mode='train'):\n","        if mode == 'train':\n","            self.X = X_train\n","            self.y = y_train- 769\n","            self.p = p_train\n","            \n","        elif mode == 'val':\n","            self.X = X_val\n","            self.y = y_val- 769\n","            self.p = p_val\n","\n","        elif mode == 'test':\n","            self.X = X_test\n","            self.y = y_test - 769        \n","            self.p = p_test\n","\n","    def __len__(self):\n","        return (self.X.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        '''\n","        X: (augmented) time sequence \n","        y: class label\n","        p: person id\n","\n","        '''\n","        X = torch.from_numpy(self.X[idx,:,:]).float()\n","        y = torch.tensor(self.y[idx]).long()\n","        p = torch.tensor(self.p[idx]).long()\n","        #p = torch.from_numpy(self.p[idx,:]).long()     \n","        sample = {'X': X, 'y': y, 'p':p}\n","\n","        return sample"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hbiGv8ouEI2b","colab_type":"text"},"source":["## Data Augmentation Functions"]},{"cell_type":"markdown","metadata":{"id":"P_y4pb5vEI2d","colab_type":"text"},"source":["### 1. Window Data"]},{"cell_type":"code","metadata":{"id":"T5dPzOfbEI2e","colab_type":"code","colab":{}},"source":["def window_data(X, y, p, window_size, stride):\n","  '''\n","  X (a 3-d tensor) of size (#trials, #electrodes, #time series)\n","  y (#trials,): label \n","  p (#trials, 1): person id\n","\n","  X_new1: The first output stacks the windowed data in a new dimension, resulting \n","    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\n","  X_new2: The second option makes the windows into new trails, resulting in a new\n","    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \n","    for the larger number of trials, we also need to augment the y data.\n","  y_new: The augmented y vector of size (#trials*#windows) to match X_new2.\n","  p_new: The augmented p vector of size (#trials*#windows) to match X_new2\n"," \n","  '''\n","  num_sub_trials = int((X.shape[2]-window_size)/stride)\n","  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\n","  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\n","  y_new = np.empty([X.shape[0]*num_sub_trials])\n","  p_new = np.empty([X.shape[0]*num_sub_trials])\n","  for i in range(X.shape[0]):\n","    for j in range(X.shape[1]):\n","      for k in range(num_sub_trials):\n","        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\n","        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\n","        y_new[i*num_sub_trials+k] = y[i]\n","        p_new[i*num_sub_trials+k] = p[i]\n","  return X_new1, X_new2, y_new, p_new"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQ7mRTjzEI2m","colab_type":"text"},"source":["### 2. STFT"]},{"cell_type":"code","metadata":{"id":"RU7uZckAEI2n","colab_type":"code","colab":{}},"source":["# Function that computes the short-time fourier transform of the data and returns the spectrogram\n","def stft_data(X, window, stride):\n","    '''\n","    Inputs:\n","    X - input data, last dimension is one which transform will be taken across.\n","    window - size of sliding window to take transform across\n","    stride - stride of sliding window across time-series\n","\n","    Returns:\n","    X_STFT - Output data, same shape as input with last dimension replaced with two new dimensions, F x T.\n","            where F = window//2 + 1 is the frequency axis\n","            and T = (input_length - window)//stride + 1, similar to the formula for aconvolutional filter.\n","    t - the corresponding times for the time axis, T\n","    f - the corresponding frequencies on the frequency axis, F.\n","\n","    reshape X_STFT (N, C, F, T) to (N, C*F, T) to fit the input of rnn\n","\n","    Note that a smaller window means only higher frequencies may be found, but give finer time resolution.\n","    Conversely, a large window gives better frequency resolution, but poor time resolution.\n","\n","    '''\n","    noverlap = window-stride\n","    #print(noverlap)\n","    if noverlap < 0 :\n","        print('Stride results in skipped data!')\n","        return\n","    f, t, X_STFT = sig.spectrogram(X,nperseg=window,noverlap=noverlap,fs=250, return_onesided=True)\n","    N, C, F, T = X_STFT.shape\n","    X_STFT = X_STFT.reshape(N, C*F, T)\n","    return X_STFT"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oKn0SF9dEI2s","colab_type":"text"},"source":["### 3. CWT"]},{"cell_type":"code","metadata":{"id":"HCxP0HCQEI2t","colab_type":"code","colab":{}},"source":["def cwt_data(X, num_levels, top_scale=3):\n","    '''\n","    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\n","    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\n","    Appends to the data a new dimension, of size 'num_levels'\n","    New dimension corresponds to wavelet content at num_levels different scalings (linear)\n","    also returns the central frequencies that the scalings correspond to\n","    input data is N x C X T\n","    output data is N x C x T x F\n","    note: CWT is fairly slow to compute\n","\n","    # EXAMPLE USAGE\n","    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\n","    '''\n","    scales = np.logspace(start=0,stop=top_scale,num=num_levels)\n","    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\n","    for i in range(X.shape[0]):\n","        for j in range(X.shape[1]):\n","            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\n","            out[i,j,:] = coef.T\n","    freqs = pywt.scale2frequency('mexh',scales)*250\n","    N, C, T, F = out.shape\n","    X_CWT = np.transpose(out, (0,1,3,2)).reshape(N, C*F, T)\n","    return X_CWT"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLD4Nd_4DLFe","colab_type":"text"},"source":["### 4. Independent Component Analysis (ICA)"]},{"cell_type":"code","metadata":{"id":"8NBd6c-3DOy2","colab_type":"code","colab":{}},"source":["def ica_data(X, n_components):\n","  # FUNCTION TO COMPUTE THE ICA OF DATA\n","  out = np.empty((X.shape[0], n_components, X.shape[-1]))\n","  for i in range(X.shape[0]):\n","    ica = FastICA(n_components=n_components, whiten=True, max_iter=300, tol=0.01)\n","    out[i,:,:] = ica.fit_transform(X[i,:,:].T).T  # Reconstruct signals\n","  return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LU9E1jC7_hdJ","colab_type":"text"},"source":["## Define data augmentation wrapper"]},{"cell_type":"code","metadata":{"id":"zSFCOa05EI2y","colab_type":"code","colab":{}},"source":["def Aug_Data(X, y, p, aug_type=None, window_size=200, window_stride=20, stft_size=None, stft_stride=None, cwt_level=None, cwt_scale=None):\n","    if aug_type == None:\n","        X_aug, y_aug, p_aug = X, y, p\n","    elif aug_type == \"window\":\n","        _, X_aug, y_aug, p_aug = window_data(X, y, p, window_size, window_stride)\n","    elif aug_type == \"stft\":\n","        X_aug = stft_data(X, stft_size, stft_stride)\n","        y_aug, p_aug = y, p\n","    elif aug_type == 'cwt':\n","        X_aug = cwt_data(X, cwt_level, cwt_scale)\n","        y_aug, p_aug = y, p\n","    \n","    return X_aug, y_aug, p_aug"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jOKsX1Xm-O42","colab_type":"text"},"source":["# Architectures"]},{"cell_type":"markdown","metadata":{"id":"pTAZw5n7EI3B","colab_type":"text"},"source":["### Define Basic LSTM"]},{"cell_type":"code","metadata":{"id":"2-drfGKkEI3D","colab_type":"code","colab":{}},"source":["class LSTMnet(nn.Module):\n","    '''\n","    Create Basic LSTM:\n","    2 layers\n","\n","    TODO: make number of layers, dropout, activation function, regularization all params\n","    see ex: https://blog.floydhub.com/gru-with-pytorch/\n","    '''\n","\n","    def __init__(self, input_size, hidden_size, output_dim, dropout):\n","        super(LSTMnet, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_dim = output_dim\n","        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, output_dim)\n","    \n","    def forward(self, x, h=None):\n","        if type(h) == type(None):\n","            out, hn = self.rnn(x)\n","        else:\n","            out, hn = self.rnn(x, h.detach())\n","        out = self.fc(out[-1, :, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNUej_RTEI3H","colab_type":"text"},"source":["### Define Basic GRU"]},{"cell_type":"code","metadata":{"id":"G48clZrtEI3J","colab_type":"code","colab":{}},"source":["class GRUnet(nn.Module):\n","    '''\n","    Create Basic GRU:\n","    2 layers\n","\n","    TODO: make number of layers, dropout, activation function, regularization all params\n","    see ex: https://blog.floydhub.com/gru-with-pytorch/\n","    '''\n","\n","    def __init__(self, input_size, hidden_size, output_dim, dropout):\n","        super(GRUnet, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_dim = output_dim\n","        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, output_dim)\n","    \n","    def forward(self, x, h=None):\n","        if type(h) == type(None):\n","            out, hn = self.rnn(x)\n","        else:\n","            out, hn = self.rnn(x, h.detach())\n","        out = self.fc(out[-1, :, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-u6gCZLEI3P","colab_type":"text"},"source":["# RNN Initialization"]},{"cell_type":"code","metadata":{"id":"e-90NzPjEI3R","colab_type":"code","colab":{}},"source":["def InitRNN(rnn_type=\"LSTM\", input_size=22, hidden_size=50, output_dim=4, dropout=0.5, lr=1e-3):\n","    '''\n","    Function to initialize RNN\n","    \n","    input: RNN type(LSTM, GRU), and other params if neccessary (regularization, acitvation, dropout, num layers, etc.)\n","\n","    output: model, criterion, optimizer\n","\n","    TODO: Eventually should also take in params such as dropout, number of layers, and activation function(s), etc.\n","    '''\n","\n","    if rnn_type==\"LSTM\":\n","        model = LSTMnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n","\n","    elif rnn_type==\"GRU\":\n","        model = GRUnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    return model, criterion, optimizer\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJwC6_vOEI3Y","colab_type":"text"},"source":["### K-Fold Training and Cross Validation"]},{"cell_type":"code","metadata":{"id":"36PDvdn1EI3g","colab_type":"code","colab":{}},"source":["def TrainRNN(trainloader, valloader, num_epochs=8, verbose=True, aug_type=None):\n","    val_acc_list = []\n","    for ep in range(num_epochs):\n","        tstart = time.time()\n","        running_loss = 0.0\n","        correct, total = 0, 0\n","        for idx, batch in enumerate(EEG_trainloader):\n","            optimizer.zero_grad()\n","            X = batch['X'].permute(2, 0, 1).to(device)\n","            y = batch['y'].to(device)\n","            output = model(X)\n","            loss = criterion(output, y)\n","            running_loss += loss.item()\n","            loss.backward()\n","            optimizer.step()\n","            pred = torch.argmax(output, dim=1)\n","            correct += torch.sum(pred == y).item()\n","            total += y.shape[0]\n","        train_acc = correct / total\n","        train_loss = running_loss\n","        '''\n","        The validation need to be customized according to the data augmenation type\n","        for stft and cwt: they didn't increase the number of trials, we can directly pass the augmented data to the model\n","        for window: it increase the number of trials, we need to do a voting for different subsequences in one trial\n","        \n","        '''\n","        if aug_type == 'window':\n","            correct, total = 0, 0\n","            for idx, batch in enumerate(EEG_valloader):\n","                X = batch['X'].permute(2, 0, 1).to(device)\n","                y = batch['y'].to(device)\n","                vote_idx = np.random.choice(1000-window_size, vote_num)\n","                vote_pred = np.zeros(y.shape[0])\n","                for i in range(len(vote_idx)):\n","                    X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","                    output = model(X_sub)\n","                    pred = torch.argmax(output, dim=1)\n","                    if i == 0:\n","                        vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","                    else:\n","                        vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","                    for row in range(y.shape[0]):\n","                        vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","                vote_pred = torch.from_numpy(vote_pred).long()\n","                correct += torch.sum(vote_pred == y.cpu()).item()\n","                total += y.shape[0]\n","            val_acc = correct / total        \n","        else:\n","            correct, total = 0, 0\n","            for idx, batch in enumerate(EEG_valloader):\n","                X = batch['X'].permute(2, 0, 1).to(device)\n","                y = batch['y'].to(device)\n","                output = model(X)                    \n","                pred = torch.argmax(output, dim=1)\n","                correct += torch.sum(pred == y.cpu()).item()\n","                total += y.shape[0]\n","            val_acc = correct / total\n","        tend = time.time()\n","        if verbose:\n","            print('epoch: {:<3d}    time: {:<3.2f}    loss: {:<3.3f}    train acc: {:<1.3f}    val acc: {:<1.3f}'.format(ep+1, tend - tstart, train_loss, train_acc, val_acc))\n","        val_acc_list.append(val_acc)\n","    best_val_acc = max(val_acc_list)\n","    return best_val_acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YyEi2-f-EI3u","colab_type":"text"},"source":["# Pipeline"]},{"cell_type":"markdown","metadata":{"id":"mdrFodRqEI3v","colab_type":"text"},"source":["## 1. Split the data to train and validation"]},{"cell_type":"code","metadata":{"id":"FBPsXoMTEI3x","colab_type":"code","outputId":"a1328204-2c49-4805-96d2-f8886dcc047b","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1583788921143,"user_tz":420,"elapsed":13070,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}}},"source":["train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","X_train_valid[train_fold[0]].shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1692, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"Y_dtSFRAEI36","colab_type":"text"},"source":["## 2. Initialize the model"]},{"cell_type":"code","metadata":{"id":"CLP8d7J3EI37","colab_type":"code","colab":{}},"source":["# indicate hyperparameters here\n","model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XeStPdgKEI4A","colab_type":"text"},"source":["## 3. Do K-Fold training and validation with windowed augmentation"]},{"cell_type":"code","metadata":{"id":"mpaoajnlEI4B","colab_type":"code","outputId":"9d80111b-7ff7-4821-98eb-019bf1de5923","colab":{"base_uri":"https://localhost:8080/","height":417},"executionInfo":{"status":"error","timestamp":1583787463684,"user_tz":420,"elapsed":3007,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}}},"source":["aug_type = \"window\"\n","window_size = 200\n","vote_num = 20\n","best_val_acc = 0.0\n","for k in range(5):\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n","    print ('fold {}'.format(k+1))\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type) / 5\n","print ('average best validation accuracy of 5 folds is :{}'.format(best_val_acc))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["fold 1\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-e1eaf60fd69d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_train_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_train_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_fold\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAug_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maug_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'window'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAug_Data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-fc329e430e01>\u001b[0m in \u001b[0;36mAug_Data\u001b[0;34m(X, y, p, aug_type, window_size, window_stride, stft_size, stft_stride, cwt_level, cwt_scale)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mX_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0maug_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"window\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_aug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0maug_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"stft\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstft_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstft_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-d5f29e20f2c6>\u001b[0m in \u001b[0;36mwindow_data\u001b[0;34m(X, y, p, window_size, stride)\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_sub_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mX_new1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mX_new2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_sub_trials\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0my_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_sub_trials\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mp_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_sub_trials\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"d8dOg38mEI4G","colab_type":"code","outputId":"bb1a8a97-b77e-4aa6-83b7-588849591d22","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","if aug_type == 'window':\n","    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        vote_idx = np.random.choice(1000-window_size, vote_num)\n","        vote_pred = np.zeros(y.shape[0])\n","        for i in range(len(vote_idx)):\n","            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","            output = model(X_sub)\n","            pred = torch.argmax(output, dim=1)\n","            if i == 0:\n","                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","            else:\n","                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","            for row in range(y.shape[0]):\n","                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","        vote_pred = torch.from_numpy(vote_pred).long()\n","        correct += torch.sum(vote_pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total \n","else:\n","    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test)\n","    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        output = model(X)                    \n","        pred = torch.argmax(output, dim=1)\n","        correct += torch.sum(pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.3634\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y0kRQ1Zg-t8s"},"source":["## 4. Do K-Fold training and validation with CWT augmentation"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"e14b270c-9f9f-456e-b6d3-64a44225e64e","id":"C_R_S0Di-t8u","colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["aug_type = \"cwt\"\n","num_levels = 5\n","top_scale = 3\n","window_size = 200\n","vote_num = 20\n","best_val_acc = 0.0\n","    \n","for k in range(5):\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size = 22*num_levels)\n","    print ('fold {}'.format(k+1))\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type) / 5\n","print ('average best validation accuracy of 5 folds is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fold 1\n","epoch: 1      time: 25.46    loss: 5.598    train acc: 0.236    val acc: 0.317\n","epoch: 2      time: 26.15    loss: 5.496    train acc: 0.303    val acc: 0.364\n","epoch: 3      time: 26.08    loss: 5.460    train acc: 0.364    val acc: 0.418\n","epoch: 4      time: 26.18    loss: 5.393    train acc: 0.421    val acc: 0.459\n","epoch: 5      time: 26.19    loss: 5.342    train acc: 0.449    val acc: 0.461\n","epoch: 6      time: 26.60    loss: 5.299    train acc: 0.504    val acc: 0.522\n","epoch: 7      time: 26.59    loss: 5.237    train acc: 0.487    val acc: 0.527\n","epoch: 8      time: 26.83    loss: 5.162    train acc: 0.544    val acc: 0.556\n","fold 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5OyShp4PN-OZ","colab_type":"code","colab":{}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","print(X_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"23e16571-b4ae-43a1-b2dc-df67a9381f30","id":"jTafPsT0-t8x","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1583789281997,"user_tz":420,"elapsed":4439,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}}},"source":["EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","correct, total = 0, 0\n","for idx, batch in enumerate(EEG_testloader):\n","    X = batch['X'].permute(2, 0, 1).to(device)\n","    y = batch['y'].to(device)\n","    output = model(X)                    \n","    pred = torch.argmax(output, dim=1)\n","    correct += torch.sum(pred == y.cpu()).item()\n","    total += y.shape[0]\n","test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.2573\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vgOHEAcQLExg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JyqlTv6m-t8z","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}