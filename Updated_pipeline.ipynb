{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Updated_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuaghannan/ECEC247_Project/blob/master/Updated_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsCG9DHzEI2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import scipy.signal as sig\n",
        "import pywt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o80JLlxyEI2H",
        "colab_type": "text"
      },
      "source": [
        "### Set up the Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HjZycAvEI2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbaeaf12-6776-454d-84c7-5ab9c6685ad9"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    # device = torch.device(\"cuda:1\") # For Yiming \n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26wpkKr9Em1E",
        "colab_type": "text"
      },
      "source": [
        "### If Using Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQwpQEszAQ9u",
        "colab_type": "code",
        "outputId": "1ab500d1-13e9-4bb8-a2e6-9e3d23b05410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-S67grVAoSt",
        "colab_type": "code",
        "outputId": "075c9942-7a50-4d23-e36d-7091159eb746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "# Create a folder \"C247\" and then store the project datasets within that folder\n",
        "# Check that your datasets are setup correctly\n",
        "\n",
        "!ls \"/content/gdrive/My Drive/C247\" # File path"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EEG_loading.ipynb\tPyTorch_Experiments.ipynb  y_test.npy\n",
            "person_test.npy\t\tX_test.npy\t\t   y_train_valid.npy\n",
            "person_train_valid.npy\tX_train_valid.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiE2fkEzA3VO",
        "colab_type": "text"
      },
      "source": [
        "### Load the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJfyBLNLA686",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c7881a01-2823-449c-806e-c710c083d28c"
      },
      "source": [
        "# X_test = np.load(\"X_test.npy\")\n",
        "# y_test = np.load(\"y_test.npy\")\n",
        "# person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "# X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "# y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "# person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "# Change if your directory is different\n",
        "\n",
        "# dataset_path = './data/' # Yiming Path\n",
        "dataset_path = \"/content/gdrive/My Drive/C247/\" \n",
        "\n",
        "X_test = np.load(dataset_path + \"X_test.npy\")\n",
        "y_test = np.load(dataset_path + \"y_test.npy\")\n",
        "person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n",
        "X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n",
        "y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n",
        "person_test = np.load(dataset_path + \"person_test.npy\")\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzSs4ByOEI2V",
        "colab_type": "text"
      },
      "source": [
        "### K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNKfnV6iEI2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some major changes here for the Train_Val_Data function\n",
        "def Train_Val_Data(X_train_valid, y_train_val):\n",
        "    '''\n",
        "    split the train_valid into k folds (we fix k = 5 here)\n",
        "    return: list of index of train data and val data of k folds\n",
        "    train_fold[i], val_fold[i] is the index for training and validation in the i-th fold \n",
        "\n",
        "    '''\n",
        "    fold_idx = []\n",
        "    train_fold = []\n",
        "    val_fold = []\n",
        "    train_val_num = X_train_valid.shape[0]\n",
        "    fold_num = int(train_val_num / 5)\n",
        "    perm = np.random.permutation(train_val_num)\n",
        "    for k in range(5):\n",
        "        fold_idx.append(np.arange(k*fold_num, (k+1)*fold_num, 1))\n",
        "    for k in range(5):\n",
        "        val_fold.append(fold_idx[k])\n",
        "        count = 0\n",
        "        for i in range(5):\n",
        "            if i != k:\n",
        "                if count == 0:\n",
        "                    train_idx = fold_idx[i]\n",
        "                else:\n",
        "                    train_idx = np.concatenate((train_idx, fold_idx[i]))\n",
        "                count += 1\n",
        "        train_fold.append(train_idx)\n",
        "\n",
        "    return train_fold, val_fold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbiGv8ouEI2b",
        "colab_type": "text"
      },
      "source": [
        "### Data Augmentation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_y4pb5vEI2d",
        "colab_type": "text"
      },
      "source": [
        "### 1. Window Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5dPzOfbEI2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def window_data(X, y, p, window_size, stride):\n",
        "  '''\n",
        "  X (a 3-d tensor) of size (#trials, #electrodes, #time series)\n",
        "  y (#trials,): label \n",
        "  p (#trials, 1): person id\n",
        "\n",
        "  X_new1: The first output stacks the windowed data in a new dimension, resulting \n",
        "    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\n",
        "  X_new2: The second option makes the windows into new trails, resulting in a new\n",
        "    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \n",
        "    for the larger number of trials, we also need to augment the y data.\n",
        "  y_new: The augmented y vector of size (#trials*#windows) to match X_new2.\n",
        "  p_new: The augmented p vector of size (#trials*#windows) to match X_new2\n",
        " \n",
        "  '''\n",
        "  num_sub_trials = int((X.shape[2]-window_size)/stride)\n",
        "  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\n",
        "  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\n",
        "  y_new = np.empty([X.shape[0]*num_sub_trials])\n",
        "  p_new = np.empty([X.shape[0]*num_sub_trials])\n",
        "  for i in range(X.shape[0]):\n",
        "    for j in range(X.shape[1]):\n",
        "      for k in range(num_sub_trials):\n",
        "        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\n",
        "        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\n",
        "        y_new[i*num_sub_trials+k] = y[i]\n",
        "        p_new[i*num_sub_trials+k] = p[i]\n",
        "  return X_new1, X_new2, y_new, p_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ7mRTjzEI2m",
        "colab_type": "text"
      },
      "source": [
        "### 2. STFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU7uZckAEI2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that computes the short-time fourier transform of the data and returns the spectrogram\n",
        "def stft_data(X, window, stride):\n",
        "    '''\n",
        "    Inputs:\n",
        "    X - input data, last dimension is one which transform will be taken across.\n",
        "    window - size of sliding window to take transform across\n",
        "    stride - stride of sliding window across time-series\n",
        "\n",
        "    Returns:\n",
        "    X_STFT - Output data, same shape as input with last dimension replaced with two new dimensions, F x T.\n",
        "            where F = window//2 + 1 is the frequency axis\n",
        "            and T = (input_length - window)//stride + 1, similar to the formula for aconvolutional filter.\n",
        "    t - the corresponding times for the time axis, T\n",
        "    f - the corresponding frequencies on the frequency axis, F.\n",
        "\n",
        "    reshape X_STFT (N, C, F, T) to (N, C*F, T) to fit the input of rnn\n",
        "\n",
        "    Note that a smaller window means only higher frequencies may be found, but give finer time resolution.\n",
        "    Conversely, a large window gives better frequency resolution, but poor time resolution.\n",
        "\n",
        "    '''\n",
        "    noverlap = window-stride\n",
        "    #print(noverlap)\n",
        "    if noverlap < 0 :\n",
        "        print('Stride results in skipped data!')\n",
        "        return\n",
        "    f, t, X_STFT = sig.spectrogram(X,nperseg=window,noverlap=noverlap,fs=250, return_onesided=True)\n",
        "    N, C, F, T = X_STFT.shape\n",
        "    X_STFT = X_STFT.reshape(N, C*F, T)\n",
        "    return X_STFT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKn0SF9dEI2s",
        "colab_type": "text"
      },
      "source": [
        "### 3. CWT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCxP0HCQEI2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cwt_data(X, num_levels, top_scale=3):\n",
        "    '''\n",
        "    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\n",
        "    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\n",
        "    Appends to the data a new dimension, of size 'num_levels'\n",
        "    New dimension corresponds to wavelet content at num_levels different scalings (linear)\n",
        "    also returns the central frequencies that the scalings correspond to\n",
        "    input data is N x C X T\n",
        "    output data is N x C x T x F\n",
        "    note: CWT is fairly slow to compute\n",
        "\n",
        "    # EXAMPLE USAGE\n",
        "    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\n",
        "    '''\n",
        "    scales = np.logspace(start=0,stop=top_scale,num=num_levels)\n",
        "    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\n",
        "    for i in range(X.shape[0]):\n",
        "        for j in range(X.shape[1]):\n",
        "            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\n",
        "            out[i,j,:] = coef.T\n",
        "    freqs = pywt.scale2frequency('mexh',scales)*250\n",
        "    N, C, T, F = out.shape\n",
        "    X_CWT = np.transpose(out, (0,1,3,2)).reshape(N, C*F, T)\n",
        "    return X_CWT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSFCOa05EI2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Aug_Data(X, y, p, aug_type=None, window_size=200, window_stride=20, stft_size=None, stft_stride=None, cwt_level=None, cwt_scale=None):\n",
        "    if aug_type == None:\n",
        "        X_aug, y_aug, p_aug = X, y, p\n",
        "    elif aug_type == \"window\":\n",
        "        _, X_aug, y_aug, p_aug = window_data(X, y, p, window_size, window_stride)\n",
        "    elif aug_type == \"stft\":\n",
        "        X_aug = stft_data(X, stft_size, stft_stride)\n",
        "        y_aug, p_aug = y, p\n",
        "    elif aug_type == 'cwt':\n",
        "        X_aug = cwt_data(X, cwt_level, cwt_scale)\n",
        "        y_aug, p_aug = y, p\n",
        "    \n",
        "    return X_aug, y_aug, p_aug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuWOwEaeEI23",
        "colab_type": "text"
      },
      "source": [
        "### Customized Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Kbua1ZEI28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EEG_Dataset(Dataset):\n",
        "    '''\n",
        "    use use fold_idx to instantiate different train val datasets for k-fold cross validation\n",
        "\n",
        "    '''\n",
        "    def __init__ (self, X_train=None, y_train=None, p_train=None, X_val=None, y_val=None, p_val=None, X_test=None, y_test=None, p_test=None, mode='train'):\n",
        "        if mode == 'train':\n",
        "            self.X = X_train\n",
        "            self.y = y_train- 769\n",
        "            self.p = p_train\n",
        "            \n",
        "        elif mode == 'val':\n",
        "            self.X = X_val\n",
        "            self.y = y_val- 769\n",
        "            self.p = p_val\n",
        "\n",
        "        elif mode == 'test':\n",
        "            self.X = X_test\n",
        "            self.y = y_test - 769        \n",
        "            self.p = p_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.X.shape[0])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        X: (augmented) time sequence \n",
        "        y: class label\n",
        "        p: person id\n",
        "\n",
        "        '''\n",
        "        X = torch.from_numpy(self.X[idx,:,:]).float()\n",
        "        y = torch.tensor(self.y[idx]).long()\n",
        "        p = torch.tensor(self.p[idx]).long()\n",
        "        #p = torch.from_numpy(self.p[idx,:]).long()     \n",
        "        sample = {'X': X, 'y': y, 'p':p}\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTAZw5n7EI3B",
        "colab_type": "text"
      },
      "source": [
        "### Define Basic LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-drfGKkEI3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMnet(nn.Module):\n",
        "    '''\n",
        "    Create Basic LSTM:\n",
        "    2 layers\n",
        "\n",
        "    TODO: make number of layers, dropout, activation function, regularization all params\n",
        "    see ex: https://blog.floydhub.com/gru-with-pytorch/\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_dim, dropout):\n",
        "        super(LSTMnet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_dim = output_dim\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_dim)\n",
        "    \n",
        "    def forward(self, x, h=None):\n",
        "        if type(h) == type(None):\n",
        "            out, hn = self.rnn(x)\n",
        "        else:\n",
        "            out, hn = self.rnn(x, h.detach())\n",
        "        out = self.fc(out[-1, :, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNUej_RTEI3H",
        "colab_type": "text"
      },
      "source": [
        "### Define Basic GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G48clZrtEI3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUnet(nn.Module):\n",
        "    '''\n",
        "    Create Basic GRU:\n",
        "    2 layers\n",
        "\n",
        "    TODO: make number of layers, dropout, activation function, regularization all params\n",
        "    see ex: https://blog.floydhub.com/gru-with-pytorch/\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_dim, dropout):\n",
        "        super(GRUnet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_dim = output_dim\n",
        "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_dim)\n",
        "    \n",
        "    def forward(self, x, h=None):\n",
        "        if type(h) == type(None):\n",
        "            out, hn = self.rnn(x)\n",
        "        else:\n",
        "            out, hn = self.rnn(x, h.detach())\n",
        "        out = self.fc(out[-1, :, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-u6gCZLEI3P",
        "colab_type": "text"
      },
      "source": [
        "### RNN Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-90NzPjEI3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def InitRNN(rnn_type=\"LSTM\", input_size=22, hidden_size=50, output_dim=4, dropout=0.5, lr=1e-3):\n",
        "    '''\n",
        "    Function to initialize RNN\n",
        "    \n",
        "    input: RNN type(LSTM, GRU), and other params if neccessary (regularization, acitvation, dropout, num layers, etc.)\n",
        "\n",
        "    output: model, criterion, optimizer\n",
        "\n",
        "    TODO: Eventually should also take in params such as dropout, number of layers, and activation function(s), etc.\n",
        "    '''\n",
        "\n",
        "    if rnn_type==\"LSTM\":\n",
        "        model = LSTMnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n",
        "\n",
        "    elif rnn_type==\"GRU\":\n",
        "        model = GRUnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    return model, criterion, optimizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJwC6_vOEI3Y",
        "colab_type": "text"
      },
      "source": [
        "### K-Fold Training and Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36PDvdn1EI3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TrainRNN(trainloader, valloader, num_epochs=20, verbose=True, aug_type=None):\n",
        "    val_acc_list = []\n",
        "    for ep in range(num_epochs):\n",
        "        tstart = time.time()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for idx, batch in enumerate(EEG_trainloader):\n",
        "            optimizer.zero_grad()\n",
        "            X = batch['X'].permute(2, 0, 1).to(device)\n",
        "            y = batch['y'].to(device)\n",
        "            output = model(X)\n",
        "            loss = criterion(output, y)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            correct += torch.sum(pred == y).item()\n",
        "            total += y.shape[0]\n",
        "        train_acc = correct / total\n",
        "        train_loss = running_loss\n",
        "        '''\n",
        "        The validation need to be customized according to the data augmenation type\n",
        "        for stft and cwt: they didn't increase the number of trials, we can directly pass the augmented data to the model\n",
        "        for window: it increase the number of trials, we need to do a voting for different subsequences in one trial\n",
        "        \n",
        "        '''\n",
        "        if aug_type == 'window':\n",
        "            correct, total = 0, 0\n",
        "            for idx, batch in enumerate(EEG_valloader):\n",
        "                X = batch['X'].permute(2, 0, 1).to(device)\n",
        "                y = batch['y'].to(device)\n",
        "                vote_idx = np.random.choice(1000-window_size, vote_num)\n",
        "                vote_pred = np.zeros(y.shape[0])\n",
        "                for i in range(len(vote_idx)):\n",
        "                    X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n",
        "                    output = model(X_sub)\n",
        "                    pred = torch.argmax(output, dim=1)\n",
        "                    if i == 0:\n",
        "                        vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n",
        "                    else:\n",
        "                        vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n",
        "                    for row in range(y.shape[0]):\n",
        "                        vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n",
        "                vote_pred = torch.from_numpy(vote_pred).long()\n",
        "                correct += torch.sum(vote_pred == y.cpu()).item()\n",
        "                total += y.shape[0]\n",
        "            val_acc = correct / total        \n",
        "        else:\n",
        "            correct, total = 0, 0\n",
        "            for idx, batch in enumerate(EEG_valloader):\n",
        "                X = batch['X'].permute(2, 0, 1).to(device)\n",
        "                y = batch['y'].to(device)\n",
        "                output = model(X)                    \n",
        "                pred = torch.argmax(output, dim=1)\n",
        "                correct += torch.sum(pred == y.cpu()).item()\n",
        "                total += y.shape[0]\n",
        "            val_acc = correct / total\n",
        "        tend = time.time()\n",
        "        if verbose:\n",
        "            print('epoch: {:<3d}    time: {:<3.2f}    loss: {:<3.3f}    train acc: {:<1.3f}    val acc: {:<1.3f}'.format(ep+1, tend - tstart, train_loss, train_acc, val_acc))\n",
        "        val_acc_list.append(val_acc)\n",
        "    best_val_acc = max(val_acc_list)\n",
        "    return best_val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyEi2-f-EI3u",
        "colab_type": "text"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdrFodRqEI3v",
        "colab_type": "text"
      },
      "source": [
        "### 1.Split the data to train and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBPsXoMTEI3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22bb062a-9715-4fdf-a785-81af52174f4f"
      },
      "source": [
        "train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n",
        "X_train_valid[train_fold[0]].shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1692, 22, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_dtSFRAEI36",
        "colab_type": "text"
      },
      "source": [
        "### 2. Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLP8d7J3EI37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# indicate hyperparameters here\n",
        "model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeStPdgKEI4A",
        "colab_type": "text"
      },
      "source": [
        "### 3. Do K-Fold training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpaoajnlEI4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f7b173b-bd46-4fa7-8223-fff7445ace32"
      },
      "source": [
        "aug_type = \"window\"\n",
        "window_size = 200\n",
        "vote_num = 20\n",
        "best_val_acc = 0.0\n",
        "for k in range(5):\n",
        "    # indicate hyperparameters here\n",
        "    model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type)\n",
        "    if aug_type != 'window':\n",
        "        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type) / 5\n",
        "print ('average best validation accuracy of 5 folds is :{}'.format(best_val_acc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "epoch: 1      time: 41.75    loss: 731.825    train acc: 0.270    val acc: 0.265\n",
            "epoch: 2      time: 33.53    loss: 727.864    train acc: 0.293    val acc: 0.355\n",
            "epoch: 3      time: 33.19    loss: 726.328    train acc: 0.297    val acc: 0.265\n",
            "epoch: 4      time: 32.38    loss: 730.566    train acc: 0.281    val acc: 0.267\n",
            "epoch: 5      time: 32.20    loss: 728.238    train acc: 0.292    val acc: 0.300\n",
            "epoch: 6      time: 33.23    loss: 722.948    train acc: 0.311    val acc: 0.312\n",
            "epoch: 7      time: 31.62    loss: 701.857    train acc: 0.366    val acc: 0.329\n",
            "epoch: 8      time: 32.22    loss: 680.838    train acc: 0.400    val acc: 0.362\n",
            "epoch: 9      time: 33.38    loss: 664.825    train acc: 0.424    val acc: 0.409\n",
            "epoch: 10     time: 33.64    loss: 642.864    train acc: 0.455    val acc: 0.371\n",
            "epoch: 11     time: 32.16    loss: 620.518    train acc: 0.485    val acc: 0.374\n",
            "epoch: 12     time: 32.17    loss: 596.044    train acc: 0.509    val acc: 0.397\n",
            "epoch: 13     time: 33.54    loss: 574.507    train acc: 0.532    val acc: 0.383\n",
            "epoch: 14     time: 31.80    loss: 548.522    train acc: 0.559    val acc: 0.388\n",
            "epoch: 15     time: 32.25    loss: 526.616    train acc: 0.578    val acc: 0.392\n",
            "epoch: 16     time: 33.47    loss: 505.205    train acc: 0.599    val acc: 0.385\n",
            "epoch: 17     time: 33.18    loss: 484.311    train acc: 0.619    val acc: 0.357\n",
            "epoch: 18     time: 32.26    loss: 465.927    train acc: 0.636    val acc: 0.366\n",
            "epoch: 19     time: 32.19    loss: 448.161    train acc: 0.650    val acc: 0.381\n",
            "epoch: 20     time: 33.17    loss: 432.034    train acc: 0.664    val acc: 0.390\n",
            "fold 2\n",
            "epoch: 1      time: 33.15    loss: 731.509    train acc: 0.276    val acc: 0.248\n",
            "epoch: 2      time: 33.36    loss: 730.585    train acc: 0.280    val acc: 0.288\n",
            "epoch: 3      time: 33.14    loss: 727.188    train acc: 0.295    val acc: 0.274\n",
            "epoch: 4      time: 36.02    loss: 728.061    train acc: 0.291    val acc: 0.241\n",
            "epoch: 5      time: 33.48    loss: 727.792    train acc: 0.292    val acc: 0.248\n",
            "epoch: 6      time: 33.23    loss: 724.117    train acc: 0.308    val acc: 0.239\n",
            "epoch: 7      time: 34.99    loss: 729.583    train acc: 0.286    val acc: 0.303\n",
            "epoch: 8      time: 32.48    loss: 725.333    train acc: 0.301    val acc: 0.331\n",
            "epoch: 9      time: 33.22    loss: 720.218    train acc: 0.320    val acc: 0.343\n",
            "epoch: 10     time: 36.40    loss: 715.470    train acc: 0.331    val acc: 0.265\n",
            "epoch: 11     time: 34.49    loss: 713.110    train acc: 0.336    val acc: 0.239\n",
            "epoch: 12     time: 33.27    loss: 708.682    train acc: 0.342    val acc: 0.270\n",
            "epoch: 13     time: 34.74    loss: 701.167    train acc: 0.358    val acc: 0.324\n",
            "epoch: 14     time: 34.59    loss: 681.425    train acc: 0.393    val acc: 0.395\n",
            "epoch: 15     time: 32.29    loss: 656.579    train acc: 0.431    val acc: 0.423\n",
            "epoch: 16     time: 34.50    loss: 631.652    train acc: 0.466    val acc: 0.376\n",
            "epoch: 17     time: 34.44    loss: 607.922    train acc: 0.495    val acc: 0.381\n",
            "epoch: 18     time: 33.56    loss: 583.125    train acc: 0.522    val acc: 0.428\n",
            "epoch: 19     time: 33.21    loss: 561.913    train acc: 0.545    val acc: 0.409\n",
            "epoch: 20     time: 34.17    loss: 539.683    train acc: 0.568    val acc: 0.397\n",
            "fold 3\n",
            "epoch: 1      time: 32.85    loss: 730.413    train acc: 0.277    val acc: 0.298\n",
            "epoch: 2      time: 31.22    loss: 728.598    train acc: 0.289    val acc: 0.255\n",
            "epoch: 3      time: 32.21    loss: 726.702    train acc: 0.295    val acc: 0.286\n",
            "epoch: 4      time: 33.41    loss: 726.673    train acc: 0.296    val acc: 0.281\n",
            "epoch: 5      time: 33.09    loss: 726.472    train acc: 0.294    val acc: 0.305\n",
            "epoch: 6      time: 32.37    loss: 729.445    train acc: 0.285    val acc: 0.293\n",
            "epoch: 7      time: 32.18    loss: 723.134    train acc: 0.305    val acc: 0.286\n",
            "epoch: 8      time: 32.93    loss: 717.622    train acc: 0.321    val acc: 0.274\n",
            "epoch: 9      time: 31.25    loss: 692.799    train acc: 0.374    val acc: 0.262\n",
            "epoch: 10     time: 32.16    loss: 672.329    train acc: 0.409    val acc: 0.307\n",
            "epoch: 11     time: 32.92    loss: 651.555    train acc: 0.436    val acc: 0.319\n",
            "epoch: 12     time: 32.48    loss: 628.007    train acc: 0.466    val acc: 0.307\n",
            "epoch: 13     time: 32.17    loss: 603.234    train acc: 0.497    val acc: 0.314\n",
            "epoch: 14     time: 32.16    loss: 575.318    train acc: 0.529    val acc: 0.279\n",
            "epoch: 15     time: 33.41    loss: 549.616    train acc: 0.552    val acc: 0.312\n",
            "epoch: 16     time: 31.69    loss: 526.501    train acc: 0.573    val acc: 0.319\n",
            "epoch: 17     time: 32.14    loss: 504.577    train acc: 0.595    val acc: 0.307\n",
            "epoch: 18     time: 33.33    loss: 480.746    train acc: 0.615    val acc: 0.350\n",
            "epoch: 19     time: 32.98    loss: 464.344    train acc: 0.631    val acc: 0.331\n",
            "epoch: 20     time: 32.20    loss: 448.033    train acc: 0.646    val acc: 0.303\n",
            "fold 4\n",
            "epoch: 1      time: 32.11    loss: 732.189    train acc: 0.264    val acc: 0.355\n",
            "epoch: 2      time: 33.44    loss: 730.630    train acc: 0.277    val acc: 0.338\n",
            "epoch: 3      time: 31.78    loss: 729.217    train acc: 0.283    val acc: 0.241\n",
            "epoch: 4      time: 32.23    loss: 730.961    train acc: 0.276    val acc: 0.350\n",
            "epoch: 5      time: 33.29    loss: 729.453    train acc: 0.280    val acc: 0.265\n",
            "epoch: 6      time: 32.90    loss: 730.026    train acc: 0.278    val acc: 0.307\n",
            "epoch: 7      time: 32.13    loss: 728.558    train acc: 0.284    val acc: 0.293\n",
            "epoch: 8      time: 32.16    loss: 726.927    train acc: 0.292    val acc: 0.357\n",
            "epoch: 9      time: 33.42    loss: 725.756    train acc: 0.292    val acc: 0.300\n",
            "epoch: 10     time: 31.74    loss: 729.443    train acc: 0.278    val acc: 0.291\n",
            "epoch: 11     time: 32.16    loss: 718.827    train acc: 0.310    val acc: 0.338\n",
            "epoch: 12     time: 33.30    loss: 706.867    train acc: 0.338    val acc: 0.333\n",
            "epoch: 13     time: 32.86    loss: 685.865    train acc: 0.373    val acc: 0.383\n",
            "epoch: 14     time: 32.14    loss: 662.014    train acc: 0.413    val acc: 0.414\n",
            "epoch: 15     time: 32.16    loss: 634.969    train acc: 0.447    val acc: 0.402\n",
            "epoch: 16     time: 33.50    loss: 610.810    train acc: 0.476    val acc: 0.400\n",
            "epoch: 17     time: 31.84    loss: 585.753    train acc: 0.503    val acc: 0.440\n",
            "epoch: 18     time: 32.22    loss: 560.146    train acc: 0.529    val acc: 0.440\n",
            "epoch: 19     time: 33.40    loss: 540.883    train acc: 0.545    val acc: 0.435\n",
            "epoch: 20     time: 33.39    loss: 516.129    train acc: 0.573    val acc: 0.461\n",
            "fold 5\n",
            "epoch: 1      time: 32.12    loss: 730.763    train acc: 0.277    val acc: 0.284\n",
            "epoch: 2      time: 32.11    loss: 727.167    train acc: 0.294    val acc: 0.296\n",
            "epoch: 3      time: 32.96    loss: 727.735    train acc: 0.292    val acc: 0.288\n",
            "epoch: 4      time: 31.33    loss: 724.307    train acc: 0.306    val acc: 0.305\n",
            "epoch: 5      time: 32.16    loss: 725.860    train acc: 0.300    val acc: 0.291\n",
            "epoch: 6      time: 33.11    loss: 725.353    train acc: 0.300    val acc: 0.296\n",
            "epoch: 7      time: 32.86    loss: 717.551    train acc: 0.323    val acc: 0.319\n",
            "epoch: 8      time: 32.12    loss: 706.958    train acc: 0.342    val acc: 0.307\n",
            "epoch: 9      time: 32.17    loss: 689.097    train acc: 0.377    val acc: 0.331\n",
            "epoch: 10     time: 33.52    loss: 665.045    train acc: 0.415    val acc: 0.400\n",
            "epoch: 11     time: 31.83    loss: 637.731    train acc: 0.453    val acc: 0.388\n",
            "epoch: 12     time: 32.23    loss: 611.272    train acc: 0.481    val acc: 0.374\n",
            "epoch: 13     time: 33.38    loss: 580.861    train acc: 0.517    val acc: 0.385\n",
            "epoch: 14     time: 33.32    loss: 552.327    train acc: 0.545    val acc: 0.414\n",
            "epoch: 15     time: 32.16    loss: 526.536    train acc: 0.571    val acc: 0.400\n",
            "epoch: 16     time: 32.14    loss: 501.860    train acc: 0.594    val acc: 0.414\n",
            "epoch: 17     time: 33.54    loss: 480.738    train acc: 0.612    val acc: 0.423\n",
            "epoch: 18     time: 31.88    loss: 460.033    train acc: 0.633    val acc: 0.426\n",
            "epoch: 19     time: 32.30    loss: 441.007    train acc: 0.652    val acc: 0.433\n",
            "epoch: 20     time: 34.30    loss: 423.498    train acc: 0.669    val acc: 0.414\n",
            "average best validation accuracy of 5 folds is :0.41607565011820336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8dOg38mEI4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb1a8a97-b77e-4aa6-83b7-588849591d22"
      },
      "source": [
        "X_test, y_test, p_test = X_test, y_test, person_test\n",
        "if aug_type == 'window':\n",
        "    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n",
        "    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n",
        "    correct, total = 0, 0\n",
        "    for idx, batch in enumerate(EEG_testloader):\n",
        "        X = batch['X'].permute(2, 0, 1).to(device)\n",
        "        y = batch['y'].to(device)\n",
        "        vote_idx = np.random.choice(1000-window_size, vote_num)\n",
        "        vote_pred = np.zeros(y.shape[0])\n",
        "        for i in range(len(vote_idx)):\n",
        "            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n",
        "            output = model(X_sub)\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            if i == 0:\n",
        "                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n",
        "            else:\n",
        "                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n",
        "            for row in range(y.shape[0]):\n",
        "                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n",
        "        vote_pred = torch.from_numpy(vote_pred).long()\n",
        "        correct += torch.sum(vote_pred == y.cpu()).item()\n",
        "        total += y.shape[0]\n",
        "    test_acc = correct / total \n",
        "else:\n",
        "    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test)\n",
        "    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n",
        "    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n",
        "    correct, total = 0, 0\n",
        "    for idx, batch in enumerate(EEG_testloader):\n",
        "        X = batch['X'].permute(2, 0, 1).to(device)\n",
        "        y = batch['y'].to(device)\n",
        "        output = model(X)                    \n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct += torch.sum(pred == y.cpu()).item()\n",
        "        total += y.shape[0]\n",
        "    test_acc = correct / total\n",
        "print ('Testing Accuracy: {:.4f}'.format(test_acc))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.3634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxvyzCM1EI4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}