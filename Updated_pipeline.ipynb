{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Updated_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuaghannan/ECEC247_Project/blob/jgh_tests/Updated_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsCG9DHzEI2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import scipy.signal as sig\n",
        "import pywt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o80JLlxyEI2H",
        "colab_type": "text"
      },
      "source": [
        "### Set up the Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HjZycAvEI2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d805985a-1bf4-41eb-c265-6c8d360a45b0"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    # device = torch.device(\"cuda:1\") # For Yiming \n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26wpkKr9Em1E",
        "colab_type": "text"
      },
      "source": [
        "### If Using Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQwpQEszAQ9u",
        "colab_type": "code",
        "outputId": "304b5a69-296d-4f3b-b7b5-6a9337124952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-S67grVAoSt",
        "colab_type": "code",
        "outputId": "fbbaaba0-88a4-4ca5-c979-793e3531e7c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "# Create a folder \"C247\" and then store the project datasets within that folder\n",
        "# Check that your datasets are setup correctly\n",
        "\n",
        "!ls \"/content/gdrive/My Drive/C247\" # File path"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EEG_loading.ipynb\tPyTorch_Experiments.ipynb  y_test.npy\n",
            "person_test.npy\t\tX_test.npy\t\t   y_train_valid.npy\n",
            "person_train_valid.npy\tX_train_valid.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiE2fkEzA3VO",
        "colab_type": "text"
      },
      "source": [
        "### Load the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJfyBLNLA686",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8115ef5d-e89f-4ac9-9b92-67bb70a8903c"
      },
      "source": [
        "# X_test = np.load(\"X_test.npy\")\n",
        "# y_test = np.load(\"y_test.npy\")\n",
        "# person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "# X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "# y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "# person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "# Change if your directory is different\n",
        "\n",
        "# dataset_path = './data/' # Yiming Path\n",
        "dataset_path = \"/content/gdrive/My Drive/C247/\" \n",
        "\n",
        "X_test = np.load(dataset_path + \"X_test.npy\")\n",
        "y_test = np.load(dataset_path + \"y_test.npy\")\n",
        "person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n",
        "X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n",
        "y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n",
        "person_test = np.load(dataset_path + \"person_test.npy\")\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzSs4ByOEI2V",
        "colab_type": "text"
      },
      "source": [
        "### K-Fold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNKfnV6iEI2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# some major changes here for the Train_Val_Data function\n",
        "def Train_Val_Data(X_train_valid, y_train_val):\n",
        "    '''\n",
        "    split the train_valid into k folds (we fix k = 5 here)\n",
        "    return: list of index of train data and val data of k folds\n",
        "    train_fold[i], val_fold[i] is the index for training and validation in the i-th fold \n",
        "\n",
        "    '''\n",
        "    fold_idx = []\n",
        "    train_fold = []\n",
        "    val_fold = []\n",
        "    train_val_num = X_train_valid.shape[0]\n",
        "    fold_num = int(train_val_num / 5)\n",
        "    perm = np.random.permutation(train_val_num)\n",
        "    for k in range(5):\n",
        "        fold_idx.append(np.arange(k*fold_num, (k+1)*fold_num, 1))\n",
        "    for k in range(5):\n",
        "        val_fold.append(fold_idx[k])\n",
        "        count = 0\n",
        "        for i in range(5):\n",
        "            if i != k:\n",
        "                if count == 0:\n",
        "                    train_idx = fold_idx[i]\n",
        "                else:\n",
        "                    train_idx = np.concatenate((train_idx, fold_idx[i]))\n",
        "                count += 1\n",
        "        train_fold.append(train_idx)\n",
        "\n",
        "    return train_fold, val_fold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbiGv8ouEI2b",
        "colab_type": "text"
      },
      "source": [
        "### Data Augmentation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_y4pb5vEI2d",
        "colab_type": "text"
      },
      "source": [
        "### 1. Window Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5dPzOfbEI2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def window_data(X, y, p, window_size, stride):\n",
        "  '''\n",
        "  X (a 3-d tensor) of size (#trials, #electrodes, #time series)\n",
        "  y (#trials,): label \n",
        "  p (#trials, 1): person id\n",
        "\n",
        "  X_new1: The first output stacks the windowed data in a new dimension, resulting \n",
        "    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\n",
        "  X_new2: The second option makes the windows into new trails, resulting in a new\n",
        "    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \n",
        "    for the larger number of trials, we also need to augment the y data.\n",
        "  y_new: The augmented y vector of size (#trials*#windows) to match X_new2.\n",
        "  p_new: The augmented p vector of size (#trials*#windows) to match X_new2\n",
        " \n",
        "  '''\n",
        "  num_sub_trials = int((X.shape[2]-window_size)/stride)\n",
        "  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\n",
        "  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\n",
        "  y_new = np.empty([X.shape[0]*num_sub_trials])\n",
        "  p_new = np.empty([X.shape[0]*num_sub_trials])\n",
        "  for i in range(X.shape[0]):\n",
        "    for j in range(X.shape[1]):\n",
        "      for k in range(num_sub_trials):\n",
        "        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\n",
        "        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\n",
        "        y_new[i*num_sub_trials+k] = y[i]\n",
        "        p_new[i*num_sub_trials+k] = p[i]\n",
        "  return X_new1, X_new2, y_new, p_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQ7mRTjzEI2m",
        "colab_type": "text"
      },
      "source": [
        "### 2. STFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU7uZckAEI2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function that computes the short-time fourier transform of the data and returns the spectrogram\n",
        "def stft_data(X, window, stride):\n",
        "    '''\n",
        "    Inputs:\n",
        "    X - input data, last dimension is one which transform will be taken across.\n",
        "    window - size of sliding window to take transform across\n",
        "    stride - stride of sliding window across time-series\n",
        "\n",
        "    Returns:\n",
        "    X_STFT - Output data, same shape as input with last dimension replaced with two new dimensions, F x T.\n",
        "            where F = window//2 + 1 is the frequency axis\n",
        "            and T = (input_length - window)//stride + 1, similar to the formula for aconvolutional filter.\n",
        "    t - the corresponding times for the time axis, T\n",
        "    f - the corresponding frequencies on the frequency axis, F.\n",
        "\n",
        "    reshape X_STFT (N, C, F, T) to (N, C*F, T) to fit the input of rnn\n",
        "\n",
        "    Note that a smaller window means only higher frequencies may be found, but give finer time resolution.\n",
        "    Conversely, a large window gives better frequency resolution, but poor time resolution.\n",
        "\n",
        "    '''\n",
        "    noverlap = window-stride\n",
        "    #print(noverlap)\n",
        "    if noverlap < 0 :\n",
        "        print('Stride results in skipped data!')\n",
        "        return\n",
        "    f, t, X_STFT = sig.spectrogram(X,nperseg=window,noverlap=noverlap,fs=250, return_onesided=True)\n",
        "    N, C, F, T = X_STFT.shape\n",
        "    X_STFT = X_STFT.reshape(N, C*F, T)\n",
        "    return X_STFT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKn0SF9dEI2s",
        "colab_type": "text"
      },
      "source": [
        "### 3. CWT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCxP0HCQEI2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cwt_data(X, num_levels, top_scale=3):\n",
        "    '''\n",
        "    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\n",
        "    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\n",
        "    Appends to the data a new dimension, of size 'num_levels'\n",
        "    New dimension corresponds to wavelet content at num_levels different scalings (linear)\n",
        "    also returns the central frequencies that the scalings correspond to\n",
        "    input data is N x C X T\n",
        "    output data is N x C x T x F\n",
        "    note: CWT is fairly slow to compute\n",
        "\n",
        "    # EXAMPLE USAGE\n",
        "    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\n",
        "    '''\n",
        "    scales = np.logspace(start=0,stop=top_scale,num=num_levels)\n",
        "    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\n",
        "    for i in range(X.shape[0]):\n",
        "        for j in range(X.shape[1]):\n",
        "            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\n",
        "            out[i,j,:] = coef.T\n",
        "    freqs = pywt.scale2frequency('mexh',scales)*250\n",
        "    N, C, T, F = out.shape\n",
        "    X_CWT = np.transpose(out, (0,1,3,2)).reshape(N, C*F, T)\n",
        "    return X_CWT"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSFCOa05EI2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Aug_Data(X, y, p, aug_type=None, window_size=200, window_stride=20, stft_size=None, stft_stride=None, cwt_level=None, cwt_scale=None):\n",
        "    if aug_type == None:\n",
        "        X_aug, y_aug, p_aug = X, y, p\n",
        "    elif aug_type == \"window\":\n",
        "        _, X_aug, y_aug, p_aug = window_data(X, y, p, window_size, window_stride)\n",
        "    elif aug_type == \"stft\":\n",
        "        X_aug = stft_data(X, stft_size, stft_stride)\n",
        "        y_aug, p_aug = y, p\n",
        "    elif aug_type == 'cwt':\n",
        "        X_aug = cwt_data(X, cwt_level, cwt_scale)\n",
        "        y_aug, p_aug = y, p\n",
        "    \n",
        "    return X_aug, y_aug, p_aug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuWOwEaeEI23",
        "colab_type": "text"
      },
      "source": [
        "### Customized Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Kbua1ZEI28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EEG_Dataset(Dataset):\n",
        "    '''\n",
        "    use use fold_idx to instantiate different train val datasets for k-fold cross validation\n",
        "\n",
        "    '''\n",
        "    def __init__ (self, X_train=None, y_train=None, p_train=None, X_val=None, y_val=None, p_val=None, X_test=None, y_test=None, p_test=None, mode='train'):\n",
        "        if mode == 'train':\n",
        "            self.X = X_train\n",
        "            self.y = y_train- 769\n",
        "            self.p = p_train\n",
        "            \n",
        "        elif mode == 'val':\n",
        "            self.X = X_val\n",
        "            self.y = y_val- 769\n",
        "            self.p = p_val\n",
        "\n",
        "        elif mode == 'test':\n",
        "            self.X = X_test\n",
        "            self.y = y_test - 769        \n",
        "            self.p = p_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.X.shape[0])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        '''\n",
        "        X: (augmented) time sequence \n",
        "        y: class label\n",
        "        p: person id\n",
        "\n",
        "        '''\n",
        "        X = torch.from_numpy(self.X[idx,:,:]).float()\n",
        "        y = torch.tensor(self.y[idx]).long()\n",
        "        p = torch.tensor(self.p[idx]).long()\n",
        "        #p = torch.from_numpy(self.p[idx,:]).long()     \n",
        "        sample = {'X': X, 'y': y, 'p':p}\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTAZw5n7EI3B",
        "colab_type": "text"
      },
      "source": [
        "### Define Basic LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-drfGKkEI3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMnet(nn.Module):\n",
        "    '''\n",
        "    Create Basic LSTM:\n",
        "    2 layers\n",
        "\n",
        "    TODO: make number of layers, dropout, activation function, regularization all params\n",
        "    see ex: https://blog.floydhub.com/gru-with-pytorch/\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_dim, dropout):\n",
        "        super(LSTMnet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_dim = output_dim\n",
        "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_dim)\n",
        "    \n",
        "    def forward(self, x, h=None):\n",
        "        if type(h) == type(None):\n",
        "            out, hn = self.rnn(x)\n",
        "        else:\n",
        "            out, hn = self.rnn(x, h.detach())\n",
        "        out = self.fc(out[-1, :, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNUej_RTEI3H",
        "colab_type": "text"
      },
      "source": [
        "### Define Basic GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G48clZrtEI3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUnet(nn.Module):\n",
        "    '''\n",
        "    Create Basic GRU:\n",
        "    2 layers\n",
        "\n",
        "    TODO: make number of layers, dropout, activation function, regularization all params\n",
        "    see ex: https://blog.floydhub.com/gru-with-pytorch/\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_dim, dropout):\n",
        "        super(GRUnet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_dim = output_dim\n",
        "        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_dim)\n",
        "    \n",
        "    def forward(self, x, h=None):\n",
        "        if type(h) == type(None):\n",
        "            out, hn = self.rnn(x)\n",
        "        else:\n",
        "            out, hn = self.rnn(x, h.detach())\n",
        "        out = self.fc(out[-1, :, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-u6gCZLEI3P",
        "colab_type": "text"
      },
      "source": [
        "### RNN Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-90NzPjEI3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def InitRNN(rnn_type=\"LSTM\", input_size=22, hidden_size=50, output_dim=4, dropout=0.5, lr=1e-3):\n",
        "    '''\n",
        "    Function to initialize RNN\n",
        "    \n",
        "    input: RNN type(LSTM, GRU), and other params if neccessary (regularization, acitvation, dropout, num layers, etc.)\n",
        "\n",
        "    output: model, criterion, optimizer\n",
        "\n",
        "    TODO: Eventually should also take in params such as dropout, number of layers, and activation function(s), etc.\n",
        "    '''\n",
        "\n",
        "    if rnn_type==\"LSTM\":\n",
        "        model = LSTMnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n",
        "\n",
        "    elif rnn_type==\"GRU\":\n",
        "        model = GRUnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)\n",
        "\n",
        "    return model, criterion, optimizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJwC6_vOEI3Y",
        "colab_type": "text"
      },
      "source": [
        "### K-Fold Training and Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36PDvdn1EI3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TrainRNN(trainloader, valloader, num_epochs=20, verbose=True, aug_type=None):\n",
        "    val_acc_list = []\n",
        "    for ep in range(num_epochs):\n",
        "        tstart = time.time()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "        for idx, batch in enumerate(EEG_trainloader):\n",
        "            optimizer.zero_grad()\n",
        "            X = batch['X'].permute(2, 0, 1).to(device)\n",
        "            y = batch['y'].to(device)\n",
        "            output = model(X)\n",
        "            loss = criterion(output, y)\n",
        "            running_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            correct += torch.sum(pred == y).item()\n",
        "            total += y.shape[0]\n",
        "        train_acc = correct / total\n",
        "        train_loss = running_loss\n",
        "        '''\n",
        "        The validation need to be customized according to the data augmenation type\n",
        "        for stft and cwt: they didn't increase the number of trials, we can directly pass the augmented data to the model\n",
        "        for window: it increase the number of trials, we need to do a voting for different subsequences in one trial\n",
        "        \n",
        "        '''\n",
        "        if aug_type == 'window':\n",
        "            correct, total = 0, 0\n",
        "            for idx, batch in enumerate(EEG_valloader):\n",
        "                X = batch['X'].permute(2, 0, 1).to(device)\n",
        "                y = batch['y'].to(device)\n",
        "                vote_idx = np.random.choice(1000-window_size, vote_num)\n",
        "                vote_pred = np.zeros(y.shape[0])\n",
        "                for i in range(len(vote_idx)):\n",
        "                    X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n",
        "                    output = model(X_sub)\n",
        "                    pred = torch.argmax(output, dim=1)\n",
        "                    if i == 0:\n",
        "                        vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n",
        "                    else:\n",
        "                        vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n",
        "                    for row in range(y.shape[0]):\n",
        "                        vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n",
        "                vote_pred = torch.from_numpy(vote_pred).long()\n",
        "                correct += torch.sum(vote_pred == y.cpu()).item()\n",
        "                total += y.shape[0]\n",
        "            val_acc = correct / total        \n",
        "        else:\n",
        "            correct, total = 0, 0\n",
        "            for idx, batch in enumerate(EEG_valloader):\n",
        "                X = batch['X'].permute(2, 0, 1).to(device)\n",
        "                y = batch['y'].to(device)\n",
        "                output = model(X)                    \n",
        "                pred = torch.argmax(output, dim=1)\n",
        "                correct += torch.sum(pred == y.cpu()).item()\n",
        "                total += y.shape[0]\n",
        "            val_acc = correct / total\n",
        "        tend = time.time()\n",
        "        if verbose:\n",
        "            print('epoch: {:<3d}    time: {:<3.2f}    loss: {:<3.3f}    train acc: {:<1.3f}    val acc: {:<1.3f}'.format(ep+1, tend - tstart, train_loss, train_acc, val_acc))\n",
        "        val_acc_list.append(val_acc)\n",
        "    best_val_acc = max(val_acc_list)\n",
        "    return best_val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyEi2-f-EI3u",
        "colab_type": "text"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdrFodRqEI3v",
        "colab_type": "text"
      },
      "source": [
        "### 1.Split the data to train and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBPsXoMTEI3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "975676fa-9f5f-431b-cb19-ac511b6862aa"
      },
      "source": [
        "train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n",
        "X_train_valid[train_fold[0]].shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1692, 22, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_dtSFRAEI36",
        "colab_type": "text"
      },
      "source": [
        "### 2. Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLP8d7J3EI37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# indicate hyperparameters here\n",
        "model, criterion, optimizer = InitRNN(rnn_type='GRU')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeStPdgKEI4A",
        "colab_type": "text"
      },
      "source": [
        "### 3. Do K-Fold training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpaoajnlEI4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70685193-29c1-4135-bbbf-24a72bb4e126"
      },
      "source": [
        "aug_type = \"window\"\n",
        "window_size = 200\n",
        "vote_num = 20\n",
        "best_val_acc = 0.0\n",
        "for k in range(5):\n",
        "    # indicate hyperparameters here\n",
        "    model, criterion, optimizer = InitRNN(rnn_type='GRU')\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type)\n",
        "    if aug_type != 'window':\n",
        "        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type) / 5\n",
        "print ('average best validation accuracy of 5 folds is :{}'.format(best_val_acc))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1\n",
            "epoch: 1      time: 15.20    loss: 733.187    train acc: 0.269    val acc: 0.298\n",
            "epoch: 2      time: 15.50    loss: 729.091    train acc: 0.284    val acc: 0.298\n",
            "epoch: 3      time: 15.12    loss: 719.502    train acc: 0.317    val acc: 0.310\n",
            "epoch: 4      time: 15.12    loss: 698.060    train acc: 0.370    val acc: 0.395\n",
            "epoch: 5      time: 15.15    loss: 671.727    train acc: 0.408    val acc: 0.381\n",
            "epoch: 6      time: 15.24    loss: 654.064    train acc: 0.431    val acc: 0.400\n",
            "epoch: 7      time: 15.21    loss: 638.317    train acc: 0.450    val acc: 0.421\n",
            "epoch: 8      time: 15.21    loss: 622.342    train acc: 0.468    val acc: 0.426\n",
            "epoch: 9      time: 15.09    loss: 607.048    train acc: 0.485    val acc: 0.440\n",
            "epoch: 10     time: 15.18    loss: 590.031    train acc: 0.505    val acc: 0.456\n",
            "epoch: 11     time: 15.17    loss: 576.813    train acc: 0.519    val acc: 0.437\n",
            "epoch: 12     time: 15.18    loss: 562.671    train acc: 0.533    val acc: 0.390\n",
            "epoch: 13     time: 15.28    loss: 550.140    train acc: 0.547    val acc: 0.430\n",
            "epoch: 14     time: 15.43    loss: 540.680    train acc: 0.556    val acc: 0.430\n",
            "epoch: 15     time: 15.08    loss: 526.580    train acc: 0.573    val acc: 0.409\n",
            "epoch: 16     time: 15.60    loss: 517.345    train acc: 0.581    val acc: 0.404\n",
            "epoch: 17     time: 15.09    loss: 504.764    train acc: 0.592    val acc: 0.390\n",
            "epoch: 18     time: 15.20    loss: 496.392    train acc: 0.601    val acc: 0.423\n",
            "epoch: 19     time: 15.18    loss: 485.218    train acc: 0.613    val acc: 0.388\n",
            "epoch: 20     time: 15.14    loss: 478.954    train acc: 0.619    val acc: 0.409\n",
            "fold 2\n",
            "epoch: 1      time: 14.96    loss: 732.556    train acc: 0.274    val acc: 0.272\n",
            "epoch: 2      time: 15.17    loss: 724.895    train acc: 0.302    val acc: 0.284\n",
            "epoch: 3      time: 15.07    loss: 711.143    train acc: 0.336    val acc: 0.246\n",
            "epoch: 4      time: 15.13    loss: 688.354    train acc: 0.379    val acc: 0.340\n",
            "epoch: 5      time: 15.07    loss: 663.303    train acc: 0.415    val acc: 0.350\n",
            "epoch: 6      time: 15.24    loss: 644.164    train acc: 0.438    val acc: 0.374\n",
            "epoch: 7      time: 14.96    loss: 628.434    train acc: 0.453    val acc: 0.383\n",
            "epoch: 8      time: 15.05    loss: 612.323    train acc: 0.472    val acc: 0.421\n",
            "epoch: 9      time: 15.03    loss: 599.555    train acc: 0.487    val acc: 0.407\n",
            "epoch: 10     time: 15.16    loss: 587.065    train acc: 0.500    val acc: 0.400\n",
            "epoch: 11     time: 15.08    loss: 573.716    train acc: 0.515    val acc: 0.428\n",
            "epoch: 12     time: 15.14    loss: 562.635    train acc: 0.528    val acc: 0.357\n",
            "epoch: 13     time: 15.14    loss: 549.837    train acc: 0.542    val acc: 0.421\n",
            "epoch: 14     time: 15.06    loss: 536.556    train acc: 0.556    val acc: 0.376\n",
            "epoch: 15     time: 14.96    loss: 525.959    train acc: 0.567    val acc: 0.390\n",
            "epoch: 16     time: 15.04    loss: 515.936    train acc: 0.578    val acc: 0.416\n",
            "epoch: 17     time: 15.01    loss: 503.798    train acc: 0.588    val acc: 0.378\n",
            "epoch: 18     time: 15.01    loss: 495.395    train acc: 0.600    val acc: 0.449\n",
            "epoch: 19     time: 15.04    loss: 488.838    train acc: 0.604    val acc: 0.383\n",
            "epoch: 20     time: 14.91    loss: 477.858    train acc: 0.615    val acc: 0.392\n",
            "fold 3\n",
            "epoch: 1      time: 15.18    loss: 731.841    train acc: 0.275    val acc: 0.286\n",
            "epoch: 2      time: 15.20    loss: 714.973    train acc: 0.321    val acc: 0.291\n",
            "epoch: 3      time: 15.05    loss: 691.739    train acc: 0.373    val acc: 0.314\n",
            "epoch: 4      time: 15.05    loss: 663.592    train acc: 0.419    val acc: 0.314\n",
            "epoch: 5      time: 15.19    loss: 640.542    train acc: 0.444    val acc: 0.331\n",
            "epoch: 6      time: 15.02    loss: 620.551    train acc: 0.468    val acc: 0.305\n",
            "epoch: 7      time: 15.14    loss: 604.170    train acc: 0.486    val acc: 0.317\n",
            "epoch: 8      time: 14.99    loss: 590.544    train acc: 0.502    val acc: 0.279\n",
            "epoch: 9      time: 15.03    loss: 574.154    train acc: 0.518    val acc: 0.352\n",
            "epoch: 10     time: 15.06    loss: 558.777    train acc: 0.534    val acc: 0.348\n",
            "epoch: 11     time: 15.01    loss: 547.270    train acc: 0.545    val acc: 0.293\n",
            "epoch: 12     time: 14.96    loss: 534.819    train acc: 0.560    val acc: 0.336\n",
            "epoch: 13     time: 15.22    loss: 521.578    train acc: 0.573    val acc: 0.326\n",
            "epoch: 14     time: 15.13    loss: 515.768    train acc: 0.578    val acc: 0.350\n",
            "epoch: 15     time: 15.20    loss: 501.271    train acc: 0.593    val acc: 0.364\n",
            "epoch: 16     time: 15.01    loss: 490.961    train acc: 0.603    val acc: 0.364\n",
            "epoch: 17     time: 15.05    loss: 478.043    train acc: 0.615    val acc: 0.324\n",
            "epoch: 18     time: 15.07    loss: 468.168    train acc: 0.626    val acc: 0.352\n",
            "epoch: 19     time: 15.11    loss: 459.693    train acc: 0.635    val acc: 0.355\n",
            "epoch: 20     time: 15.08    loss: 452.337    train acc: 0.641    val acc: 0.352\n",
            "fold 4\n",
            "epoch: 1      time: 15.29    loss: 733.766    train acc: 0.263    val acc: 0.326\n",
            "epoch: 2      time: 14.99    loss: 730.175    train acc: 0.277    val acc: 0.371\n",
            "epoch: 3      time: 15.01    loss: 718.626    train acc: 0.313    val acc: 0.366\n",
            "epoch: 4      time: 14.94    loss: 704.940    train acc: 0.342    val acc: 0.407\n",
            "epoch: 5      time: 15.04    loss: 693.596    train acc: 0.360    val acc: 0.428\n",
            "epoch: 6      time: 14.96    loss: 680.419    train acc: 0.381    val acc: 0.385\n",
            "epoch: 7      time: 14.96    loss: 666.629    train acc: 0.398    val acc: 0.430\n",
            "epoch: 8      time: 14.91    loss: 652.166    train acc: 0.418    val acc: 0.444\n",
            "epoch: 9      time: 15.23    loss: 635.031    train acc: 0.439    val acc: 0.449\n",
            "epoch: 10     time: 15.31    loss: 624.644    train acc: 0.450    val acc: 0.466\n",
            "epoch: 11     time: 15.13    loss: 610.452    train acc: 0.463    val acc: 0.444\n",
            "epoch: 12     time: 15.11    loss: 598.773    train acc: 0.476    val acc: 0.435\n",
            "epoch: 13     time: 15.35    loss: 587.572    train acc: 0.488    val acc: 0.473\n",
            "epoch: 14     time: 15.13    loss: 577.640    train acc: 0.496    val acc: 0.478\n",
            "epoch: 15     time: 15.12    loss: 565.531    train acc: 0.508    val acc: 0.456\n",
            "epoch: 16     time: 15.16    loss: 555.098    train acc: 0.515    val acc: 0.437\n",
            "epoch: 17     time: 15.18    loss: 544.493    train acc: 0.528    val acc: 0.407\n",
            "epoch: 18     time: 14.94    loss: 535.064    train acc: 0.538    val acc: 0.478\n",
            "epoch: 19     time: 15.24    loss: 528.079    train acc: 0.543    val acc: 0.461\n",
            "epoch: 20     time: 15.42    loss: 519.849    train acc: 0.550    val acc: 0.416\n",
            "fold 5\n",
            "epoch: 1      time: 15.23    loss: 732.977    train acc: 0.270    val acc: 0.288\n",
            "epoch: 2      time: 15.57    loss: 722.388    train acc: 0.308    val acc: 0.326\n",
            "epoch: 3      time: 15.24    loss: 708.628    train acc: 0.337    val acc: 0.333\n",
            "epoch: 4      time: 15.26    loss: 696.797    train acc: 0.357    val acc: 0.312\n",
            "epoch: 5      time: 15.58    loss: 678.319    train acc: 0.391    val acc: 0.364\n",
            "epoch: 6      time: 15.22    loss: 659.385    train acc: 0.419    val acc: 0.444\n",
            "epoch: 7      time: 15.18    loss: 643.387    train acc: 0.439    val acc: 0.435\n",
            "epoch: 8      time: 15.25    loss: 627.801    train acc: 0.456    val acc: 0.437\n",
            "epoch: 9      time: 15.34    loss: 613.035    train acc: 0.475    val acc: 0.463\n",
            "epoch: 10     time: 15.18    loss: 596.991    train acc: 0.493    val acc: 0.485\n",
            "epoch: 11     time: 15.15    loss: 585.671    train acc: 0.505    val acc: 0.461\n",
            "epoch: 12     time: 15.41    loss: 573.528    train acc: 0.516    val acc: 0.466\n",
            "epoch: 13     time: 15.43    loss: 560.742    train acc: 0.529    val acc: 0.409\n",
            "epoch: 14     time: 15.16    loss: 552.281    train acc: 0.539    val acc: 0.440\n",
            "epoch: 15     time: 15.39    loss: 539.016    train acc: 0.551    val acc: 0.449\n",
            "epoch: 16     time: 15.51    loss: 529.621    train acc: 0.562    val acc: 0.428\n",
            "epoch: 17     time: 15.25    loss: 517.121    train acc: 0.575    val acc: 0.473\n",
            "epoch: 18     time: 15.24    loss: 509.360    train acc: 0.583    val acc: 0.487\n",
            "epoch: 19     time: 15.30    loss: 500.686    train acc: 0.590    val acc: 0.466\n",
            "epoch: 20     time: 15.22    loss: 489.831    train acc: 0.601    val acc: 0.470\n",
            "average best validation accuracy of 5 folds is :0.44680851063829785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8dOg38mEI4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "732dea70-8fee-46a3-a652-6d18ec3b7a5e"
      },
      "source": [
        "X_test, y_test, p_test = X_test, y_test, person_test\n",
        "if aug_type == 'window':\n",
        "    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n",
        "    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n",
        "    correct, total = 0, 0\n",
        "    for idx, batch in enumerate(EEG_testloader):\n",
        "        X = batch['X'].permute(2, 0, 1).to(device)\n",
        "        y = batch['y'].to(device)\n",
        "        vote_idx = np.random.choice(1000-window_size, vote_num)\n",
        "        vote_pred = np.zeros(y.shape[0])\n",
        "        for i in range(len(vote_idx)):\n",
        "            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n",
        "            output = model(X_sub)\n",
        "            pred = torch.argmax(output, dim=1)\n",
        "            if i == 0:\n",
        "                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n",
        "            else:\n",
        "                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n",
        "            for row in range(y.shape[0]):\n",
        "                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n",
        "        vote_pred = torch.from_numpy(vote_pred).long()\n",
        "        correct += torch.sum(vote_pred == y.cpu()).item()\n",
        "        total += y.shape[0]\n",
        "    test_acc = correct / total \n",
        "else:\n",
        "    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test)\n",
        "    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n",
        "    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n",
        "    correct, total = 0, 0\n",
        "    for idx, batch in enumerate(EEG_testloader):\n",
        "        X = batch['X'].permute(2, 0, 1).to(device)\n",
        "        y = batch['y'].to(device)\n",
        "        output = model(X)                    \n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct += torch.sum(pred == y.cpu()).item()\n",
        "        total += y.shape[0]\n",
        "    test_acc = correct / total\n",
        "print ('Testing Accuracy: {:.4f}'.format(test_acc))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 0.4424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxvyzCM1EI4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding junk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g90Qp-L7__mb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keep running"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A1m5vUhDY2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}