{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Eden_tests1.ipynb","provenance":[],"collapsed_sections":["-DDfijHMPeas"],"toc_visible":true,"machine_shape":"hm"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/joshuaghannan/ECEC247_Project/blob/master/Updated_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"A6BvVAE2tvB0","colab_type":"text"},"source":["#Setup"]},{"cell_type":"code","metadata":{"id":"ZsCG9DHzEI2B","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import scipy.signal as sig\n","import pywt\n","from sklearn.decomposition import FastICA"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o80JLlxyEI2H","colab_type":"text"},"source":["### Set up the Device"]},{"cell_type":"code","metadata":{"id":"-HjZycAvEI2J","colab_type":"code","colab":{}},"source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    # device = torch.device(\"cuda:1\") # For Yiming \n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"26wpkKr9Em1E","colab_type":"text"},"source":["### If Using Colab"]},{"cell_type":"code","metadata":{"id":"KQwpQEszAQ9u","colab_type":"code","colab":{}},"source":["########################################################\n","\n","# If running with Google Colab\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-S67grVAoSt","colab_type":"code","colab":{}},"source":["########################################################\n","\n","# If running with Google Colab\n","# Create a folder \"C247\" and then store the project datasets within that folder\n","# Check that your datasets are setup correctly\n","\n","!ls \"/content/gdrive/My Drive/C247\" # File path"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NiE2fkEzA3VO","colab_type":"text"},"source":["### Load the Datasets"]},{"cell_type":"code","metadata":{"id":"TJfyBLNLA686","colab_type":"code","colab":{}},"source":["# X_test = np.load(\"X_test.npy\")\n","# y_test = np.load(\"y_test.npy\")\n","# person_train_valid = np.load(\"person_train_valid.npy\")\n","# X_train_valid = np.load(\"X_train_valid.npy\")\n","# y_train_valid = np.load(\"y_train_valid.npy\")\n","# person_test = np.load(\"person_test.npy\")\n","\n","# Change if your directory is different\n","\n","# dataset_path = './data/' # Yiming Path\n","dataset_path = \"/content/gdrive/My Drive/C247/\" \n","\n","X_test = np.load(dataset_path + \"X_test.npy\")\n","y_test = np.load(dataset_path + \"y_test.npy\")\n","person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n","X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n","y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n","person_test = np.load(dataset_path + \"person_test.npy\")\n","print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n","print ('Test data shape: {}'.format(X_test.shape))\n","print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n","print ('Test target shape: {}'.format(y_test.shape))\n","print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n","print ('Person test shape: {}'.format(person_test.shape))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gQEPDT85uAON","colab_type":"text"},"source":["# Data Manipulation"]},{"cell_type":"markdown","metadata":{"id":"JzSs4ByOEI2V","colab_type":"text"},"source":["### K-Fold"]},{"cell_type":"code","metadata":{"id":"LNKfnV6iEI2W","colab_type":"code","colab":{}},"source":["# some major changes here for the Train_Val_Data function\n","def Train_Val_Data(X_train_valid, y_train_val):\n","    '''\n","    split the train_valid into k folds (we fix k = 5 here)\n","    return: list of index of train data and val data of k folds\n","    train_fold[i], val_fold[i] is the index for training and validation in the i-th fold \n","\n","    '''\n","    fold_idx = []\n","    train_fold = []\n","    val_fold = []\n","    train_val_num = X_train_valid.shape[0]\n","    fold_num = int(train_val_num / 5)\n","    perm = np.random.permutation(train_val_num)\n","    for k in range(5):\n","        fold_idx.append(np.arange(k*fold_num, (k+1)*fold_num, 1))\n","    for k in range(5):\n","        val_fold.append(fold_idx[k])\n","        count = 0\n","        for i in range(5):\n","            if i != k:\n","                if count == 0:\n","                    train_idx = fold_idx[i]\n","                else:\n","                    train_idx = np.concatenate((train_idx, fold_idx[i]))\n","                count += 1\n","        train_fold.append(train_idx)\n","\n","    return train_fold, val_fold"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UuWOwEaeEI23","colab_type":"text"},"source":["### Customized Dataset"]},{"cell_type":"code","metadata":{"id":"b-Kbua1ZEI28","colab_type":"code","colab":{}},"source":["class EEG_Dataset(Dataset):\n","    '''\n","    use use fold_idx to instantiate different train val datasets for k-fold cross validation\n","\n","    '''\n","    def __init__ (self, X_train=None, y_train=None, p_train=None, X_val=None, y_val=None, p_val=None, X_test=None, y_test=None, p_test=None, mode='train'):\n","        if mode == 'train':\n","            self.X = X_train\n","            self.y = y_train- 769\n","            self.p = p_train\n","            \n","        elif mode == 'val':\n","            self.X = X_val\n","            self.y = y_val- 769\n","            self.p = p_val\n","\n","        elif mode == 'test':\n","            self.X = X_test\n","            self.y = y_test - 769        \n","            self.p = p_test\n","\n","    def __len__(self):\n","        return (self.X.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        '''\n","        X: (augmented) time sequence \n","        y: class label\n","        p: person id\n","\n","        '''\n","        X = torch.from_numpy(self.X[idx,:,:]).float()\n","        y = torch.tensor(self.y[idx]).long()\n","        p = torch.tensor(self.p[idx]).long()\n","        #p = torch.from_numpy(self.p[idx,:]).long()     \n","        sample = {'X': X, 'y': y, 'p':p}\n","\n","        return sample"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hbiGv8ouEI2b","colab_type":"text"},"source":["## Data Augmentation Functions"]},{"cell_type":"markdown","metadata":{"id":"3iVOP_rJtq1X","colab_type":"text"},"source":["###Center and Whiten Data\n","Scales and shifts data to have zero mean and variance 1"]},{"cell_type":"code","metadata":{"id":"X4cxUmsptofA","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","def scale_data(X):\n","  #Takes 3-dim X and outputs scaled and shifted X_new with zero mean and var 1\n","  X_scaled = np.empty_like(X)\n","  for i in range(X.shape[1]):\n","    X_scaled[:,i,:] = preprocessing.scale(X[:,i,:])\n","  return X_scaled"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P_y4pb5vEI2d","colab_type":"text"},"source":["### 1. Window Data"]},{"cell_type":"code","metadata":{"id":"T5dPzOfbEI2e","colab_type":"code","colab":{}},"source":["def window_data(X, y, p, window_size, stride):\n","  '''\n","  X (a 3-d tensor) of size (#trials, #electrodes, #time series)\n","  y (#trials,): label \n","  p (#trials, 1): person id\n","\n","  X_new1: The first output stacks the windowed data in a new dimension, resulting \n","    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\n","  X_new2: The second option makes the windows into new trails, resulting in a new\n","    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \n","    for the larger number of trials, we also need to augment the y data.\n","  y_new: The augmented y vector of size (#trials*#windows) to match X_new2.\n","  p_new: The augmented p vector of size (#trials*#windows) to match X_new2\n"," \n","  '''\n","  num_sub_trials = int((X.shape[2]-window_size)/stride)\n","  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\n","  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\n","  y_new = np.empty([X.shape[0]*num_sub_trials])\n","  p_new = np.empty([X.shape[0]*num_sub_trials])\n","  for i in range(X.shape[0]):\n","    for j in range(X.shape[1]):\n","      for k in range(num_sub_trials):\n","        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\n","        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\n","        y_new[i*num_sub_trials+k] = y[i]\n","        p_new[i*num_sub_trials+k] = p[i]\n","  N, C, NT, T = X_new1.shape\n","  X_new1 = (X_new1.reshape(N, C*NT, T))\n","  return X_new1, X_new2, y_new, p_new"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQ7mRTjzEI2m","colab_type":"text"},"source":["### 2. STFT"]},{"cell_type":"code","metadata":{"id":"RU7uZckAEI2n","colab_type":"code","colab":{}},"source":["# Function that computes the short-time fourier transform of the data and returns the spectrogram\n","def stft_data(X, window, stride):\n","    '''\n","    Inputs:\n","    X - input data, last dimension is one which transform will be taken across.\n","    window - size of sliding window to take transform across\n","    stride - stride of sliding window across time-series\n","\n","    Returns:\n","    X_STFT - Output data, same shape as input with last dimension replaced with two new dimensions, F x T.\n","            where F = window//2 + 1 is the frequency axis\n","            and T = (input_length - window)//stride + 1, similar to the formula for aconvolutional filter.\n","    t - the corresponding times for the time axis, T\n","    f - the corresponding frequencies on the frequency axis, F.\n","\n","    reshape X_STFT (N, C, F, T) to (N, C*F, T) to fit the input of rnn\n","\n","    Note that a smaller window means only higher frequencies may be found, but give finer time resolution.\n","    Conversely, a large window gives better frequency resolution, but poor time resolution.\n","\n","    '''\n","    noverlap = window-stride\n","    #print(noverlap)\n","    if noverlap < 0 :\n","        print('Stride results in skipped data!')\n","        return\n","    f, t, X_STFT = sig.spectrogram(X,nperseg=window,noverlap=noverlap,fs=250, return_onesided=True)\n","    N, C, F, T = X_STFT.shape\n","    X_STFT = X_STFT.reshape(N, C*F, T)\n","    return X_STFT"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oKn0SF9dEI2s","colab_type":"text"},"source":["### 3. CWT"]},{"cell_type":"code","metadata":{"id":"HCxP0HCQEI2t","colab_type":"code","colab":{}},"source":["def cwt_data(X, num_levels, top_scale=3):\n","    '''\n","    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\n","    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\n","    Appends to the data a new dimension, of size 'num_levels'\n","    New dimension corresponds to wavelet content at num_levels different scalings (linear)\n","    also returns the central frequencies that the scalings correspond to\n","    input data is N x C X T\n","    output data is N x C x T x F\n","    note: CWT is fairly slow to compute\n","\n","    # EXAMPLE USAGE\n","    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\n","    '''\n","    scales = np.logspace(start=0,stop=top_scale,num=num_levels)\n","    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\n","    for i in range(X.shape[0]):\n","        for j in range(X.shape[1]):\n","            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\n","            out[i,j,:] = coef.T\n","    freqs = pywt.scale2frequency('mexh',scales)*250\n","    N, C, T, F = out.shape\n","    X_CWT = np.transpose(out, (0,1,3,2)).reshape(N, C*F, T)\n","    return X_CWT"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrbdxGhi7fly","colab_type":"code","colab":{}},"source":["def cwt_data2(X, y, p, num_levels, top_scale=3):\n","    '''\n","    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\n","    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\n","    Appends to the data a new dimension, of size 'num_levels'\n","    New dimension corresponds to wavelet content at num_levels different scalings (linear)\n","    also returns the central frequencies that the scalings correspond to\n","    input data is N x C X T\n","    output data is N x C x T x F\n","    note: CWT is fairly slow to compute\n","\n","    # EXAMPLE USAGE\n","    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\n","    '''\n","    scales = np.logspace(start=0,stop=top_scale,num=num_levels)\n","    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\n","    for i in range(X.shape[0]):\n","        for j in range(X.shape[1]):\n","            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\n","            out[i,j,:] = coef.T\n","    freqs = pywt.scale2frequency('mexh',scales)*250\n","    N, C, T, F = out.shape\n","    X_cwt = np.transpose(out, (0,3,1,2)).reshape(N*F, C, T)\n","    y_cwt = np.empty([X.shape[0]*F])\n","    p_cwt = np.empty([X.shape[0]*F])\n","    for i in range(X.shape[0]):\n","      for k in range(F):\n","        y_cwt[i*F+k] = y[i]\n","        p_cwt[i*F+k] = p[i]\n","    return X_cwt, y_cwt, p_cwt, F"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLD4Nd_4DLFe","colab_type":"text"},"source":["### 4. Independent Component Analysis (ICA)"]},{"cell_type":"code","metadata":{"id":"8NBd6c-3DOy2","colab_type":"code","colab":{}},"source":["# FUNCTION TO COMPUTE THE ICA OF DATA\n","def ica_data(X, n_components):\n","  \"\"\"\n","  ICA is sensitive to low-frequency drifts and therefore requires the data to \n","  be high-pass filtered prior to fitting. Typically, a cutoff frequency of 1 Hz \n","  is recommended.\n","  \"\"\"\n","  #filter data\n","  bp_filter = sig.butter(4, [30,50], 'bandpass', fs=250, output='sos')\n","  X_filtered = np.empty((X_train_valid.shape))\n","  out = np.empty((X.shape[0], n_components, X.shape[-1]))\n","  X_ica = FastICA(n_components=n_components, algorithm='deflation', whiten=True, max_iter=500, tol=0.001)\n","  for i in range(X.shape[0]):\n","    X_filtered[i,:,:] = sig.sosfilt(bp_filter, X_train_valid[i,:,:])\n","    tstart = time.time()\n","    out[i,:,:] = X_ica.fit_transform(X[i,:,:].T).T\n","    tstop = time.time()\n","    total_time = tstop-tstart\n","    print('Done processing data sample {}, time: {:<3.2f}'.format(i, total_time))  # Reconstruct signals\n","  return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdA2_BZK4Qan","colab_type":"code","colab":{}},"source":["n_components = 22\n","hp_filter = sig.butter(10, 1, 'hp', fs=250, output='sos')\n","X_filtered = np.empty((X_train_valid.shape))\n","\n","for i in range(X_filtered.shape[0]):\n","    X_filtered[i,:,:] = sig.sosfilt(hp_filter, X_train_valid[i,:,:])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LU9E1jC7_hdJ","colab_type":"text"},"source":["## Define data augmentation wrapper"]},{"cell_type":"code","metadata":{"id":"zSFCOa05EI2y","colab_type":"code","colab":{}},"source":["def Aug_Data(X, y, p, aug_type=None, window_size=200, window_stride=20, stft_size=None, stft_stride=None, cwt_level=None, cwt_scale=None, ica_num=None):\n","    if aug_type == None:\n","        X_aug, y_aug, p_aug = X, y, p\n","    elif aug_type == \"window\":\n","        _, X_aug, y_aug, p_aug = window_data(X, y, p, window_size, window_stride)\n","    elif aug_type == \"stft\":\n","        X_aug = stft_data(X, stft_size, stft_stride)\n","        y_aug, p_aug = y, p\n","    elif aug_type == 'cwt':\n","        X_aug = cwt_data(X, cwt_level, cwt_scale)\n","        y_aug, p_aug = y, p\n","    elif aug_type == 'cwt2':\n","        X_aug, y_aug, p_aug = cwt_data2(X, y, p, cwt_level, cwt_scale)\n","    elif aug_type == 'ica':\n","        X_aug = ica_data(X, ica_num)\n","        y_aug, p_aug = y, p\n","    \n","    return X_aug, y_aug, p_aug"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jOKsX1Xm-O42","colab_type":"text"},"source":["# Architectures"]},{"cell_type":"markdown","metadata":{"id":"pTAZw5n7EI3B","colab_type":"text"},"source":["### Define Basic LSTM"]},{"cell_type":"code","metadata":{"id":"2-drfGKkEI3D","colab_type":"code","colab":{}},"source":["class LSTMnet(nn.Module):\n","    '''\n","    Create Basic LSTM:\n","    2 layers\n","\n","    TODO: make number of layers, dropout, activation function, regularization all params\n","    see ex: https://blog.floydhub.com/gru-with-pytorch/\n","    '''\n","\n","    def __init__(self, input_size, hidden_size, output_dim, dropout):\n","        super(LSTMnet, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_dim = output_dim\n","        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, output_dim)\n","    \n","    def forward(self, x, h=None):\n","        if type(h) == type(None):\n","            out, hn = self.rnn(x)\n","        else:\n","            out, hn = self.rnn(x, h.detach())\n","        out = self.fc(out[-1, :, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNUej_RTEI3H","colab_type":"text"},"source":["### Define Basic GRU"]},{"cell_type":"code","metadata":{"id":"G48clZrtEI3J","colab_type":"code","colab":{}},"source":["class GRUnet(nn.Module):\n","    '''\n","    Create Basic GRU:\n","    2 layers\n","\n","    TODO: make number of layers, dropout, activation function, regularization all params\n","    see ex: https://blog.floydhub.com/gru-with-pytorch/\n","    '''\n","\n","    def __init__(self, input_size, hidden_size, output_dim, dropout):\n","        super(GRUnet, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_dim = output_dim\n","        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, output_dim)\n","    \n","    def forward(self, x, h=None):\n","        if type(h) == type(None):\n","            out, hn = self.rnn(x)\n","        else:\n","            out, hn = self.rnn(x, h.detach())\n","        out = self.fc(out[-1, :, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-u6gCZLEI3P","colab_type":"text"},"source":["# RNN Initialization"]},{"cell_type":"code","metadata":{"id":"e-90NzPjEI3R","colab_type":"code","colab":{}},"source":["def InitRNN(rnn_type=\"LSTM\", input_size=22, hidden_size=50, output_dim=4, dropout=0.5, lr=1e-3):\n","    '''\n","    Function to initialize RNN\n","    \n","    input: RNN type(LSTM, GRU), and other params if neccessary (regularization, acitvation, dropout, num layers, etc.)\n","\n","    output: model, criterion, optimizer\n","\n","    TODO: Eventually should also take in params such as dropout, number of layers, and activation function(s), etc.\n","    '''\n","\n","    if rnn_type==\"LSTM\":\n","        model = LSTMnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n","\n","    elif rnn_type==\"GRU\":\n","        model = GRUnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    return model, criterion, optimizer\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJwC6_vOEI3Y","colab_type":"text"},"source":["### K-Fold Training and Cross Validation"]},{"cell_type":"code","metadata":{"id":"36PDvdn1EI3g","colab_type":"code","colab":{}},"source":["def TrainRNN(trainloader, valloader, num_epochs=20, verbose=True, aug_type=None):\n","    val_acc_list = []\n","    for ep in range(num_epochs):\n","        tstart = time.time()\n","        running_loss = 0.0\n","        correct, total = 0, 0\n","        for idx, batch in enumerate(EEG_trainloader):\n","            optimizer.zero_grad()\n","            X = batch['X'].permute(2, 0, 1).to(device)\n","            y = batch['y'].to(device)\n","            output = model(X)\n","            loss = criterion(output, y)\n","            running_loss += loss.item()\n","            loss.backward()\n","            optimizer.step()\n","            pred = torch.argmax(output, dim=1)\n","            correct += torch.sum(pred == y).item()\n","            total += y.shape[0]\n","        train_acc = correct / total\n","        train_loss = running_loss\n","        '''\n","        The validation need to be customized according to the data augmenation type\n","        for stft and cwt: they didn't increase the number of trials, we can directly pass the augmented data to the model\n","        for window: it increase the number of trials, we need to do a voting for different subsequences in one trial\n","        \n","        '''\n","        if aug_type == 'window':\n","            correct, total = 0, 0\n","            for idx, batch in enumerate(EEG_valloader):\n","                X = batch['X'].permute(2, 0, 1).to(device)\n","                y = batch['y'].to(device)\n","                vote_idx = np.random.choice(1000-window_size, vote_num)\n","                vote_pred = np.zeros(y.shape[0])\n","                for i in range(len(vote_idx)):\n","                    X_sub = X[vote_idx[i]:vote_idx[i]+window_size,:,:]\n","                    output = model(X_sub)\n","                    pred = torch.argmax(output, dim=1)\n","                    if i == 0:\n","                        vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","                    else:\n","                        vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","                    for row in range(y.shape[0]):\n","                        vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","                vote_pred = torch.from_numpy(vote_pred).long()\n","                correct += torch.sum(vote_pred == y.cpu()).item()\n","                total += y.shape[0]\n","            val_acc = correct / total \n","        elif aug_type == 'cwt2':\n","            correct, total = 0, 0\n","            for idx, batch in enumerate(EEG_valloader):\n","                X = batch['X'].permute(2, 0, 1).to(device)\n","                y = batch['y'].to(device)\n","                vote_idx = np.random.choice(1000-window_size, vote_num)\n","                vote_pred = np.zeros(y.shape[0])\n","                for i in range(len(vote_idx)):\n","                    X_sub = X[vote_idx[i]:vote_idx[i]+window_size,:,:]\n","                    output = model(X_sub)\n","                    pred = torch.argmax(output, dim=1)\n","                    if i == 0:\n","                        vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","                    else:\n","                        vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","                    for row in range(y.shape[0]):\n","                        vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","                vote_pred = torch.from_numpy(vote_pred).long()\n","                correct += torch.sum(vote_pred == y.cpu()).item()\n","                total += y.shape[0]\n","            val_acc = correct / total        \n","        else:\n","            correct, total = 0, 0\n","            for idx, batch in enumerate(EEG_valloader):\n","                X = batch['X'].permute(2, 0, 1).to(device)\n","                y = batch['y'].to(device)\n","                output = model(X)                    \n","                pred = torch.argmax(output, dim=1)\n","                correct += torch.sum(pred == y.cpu()).item()\n","                total += y.shape[0]\n","            val_acc = correct / total\n","        tend = time.time()\n","        if verbose:\n","            print('epoch: {:<3d}    time: {:<3.2f}    loss: {:<3.3f}    train acc: {:<1.3f}    val acc: {:<1.3f}'.format(ep+1, tend - tstart, train_loss, train_acc, val_acc))\n","        val_acc_list.append(val_acc)\n","    best_val_acc = max(val_acc_list)\n","    return best_val_acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YyEi2-f-EI3u","colab_type":"text"},"source":["# Pipeline"]},{"cell_type":"markdown","metadata":{"id":"Y_dtSFRAEI36","colab_type":"text"},"source":["## 2. Initialize the model"]},{"cell_type":"code","metadata":{"id":"CLP8d7J3EI37","colab_type":"code","colab":{}},"source":["# indicate hyperparameters here\n","model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMVxd_6nFVyQ","colab_type":"text"},"source":["# Experiments"]},{"cell_type":"markdown","metadata":{"id":"XeStPdgKEI4A","colab_type":"text"},"source":["##(small) windowed augmentation\n","Done with small number of data points below\n","\n","Testing Accuracy: 0.2596"]},{"cell_type":"markdown","metadata":{"id":"mdrFodRqEI3v","colab_type":"text"},"source":["#### Split the data to train and validation"]},{"cell_type":"code","metadata":{"id":"FBPsXoMTEI3x","colab_type":"code","colab":{}},"source":["train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","X_train_valid[train_fold[0]].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Us-hqlvGhFW","colab_type":"text"},"source":["#### Run the thing"]},{"cell_type":"code","metadata":{"id":"mpaoajnlEI4B","colab_type":"code","colab":{}},"source":["aug_type = 'window'\n","window_size = 80\n","vote_num = 8\n","best_val_acc = 0.0\n","model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n","for k in range(1):\n","    # indicate hyperparameters here\n","    print ('fold {}'.format(k+1))\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train[0:500,:,:], y_train[0:500], p_train[0:500], aug_type=aug_type, window_size=window_size, window_stride=vote_num)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, window_size=window_size, window_stride=vote_num)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type) / 5\n","print ('average best validation accuracy of 5 folds is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8dOg38mEI4G","colab_type":"code","colab":{}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","if aug_type == 'window':\n","    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        vote_idx = np.random.choice(1000-window_size, vote_num)\n","        vote_pred = np.zeros(y.shape[0])\n","        for i in range(len(vote_idx)):\n","            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","            output = model(X_sub)\n","            pred = torch.argmax(output, dim=1)\n","            if i == 0:\n","                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","            else:\n","                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","            for row in range(y.shape[0]):\n","                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","        vote_pred = torch.from_numpy(vote_pred).long()\n","        correct += torch.sum(vote_pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total \n","else:\n","    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test)\n","    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        output = model(X)                    \n","        pred = torch.argmax(output, dim=1)\n","        correct += torch.sum(pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9YEoLj-HURzY","colab_type":"text"},"source":["## (small) windowed augmentation w/ whitening and centering\n","Done with small number of data points below. \n","\n","We see whitening and centering helps with overfitting\n","\n","Testing Accuracy: 0.2460"]},{"cell_type":"markdown","metadata":{"id":"QwJBb1Hrtcjz","colab_type":"text"},"source":["#### Preprocess data"]},{"cell_type":"code","metadata":{"id":"nE0lS5i2tbHL","colab_type":"code","colab":{}},"source":["X_scaled = scale_data(X_train_valid)\n","train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","X_train_valid[train_fold[0]].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rCcHoRCZu6Oy","colab_type":"text"},"source":["#### Run the thing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p69yTM4LuhKz","colab":{}},"source":["aug_type = \"window\"\n","window_size = 80\n","vote_num = 8\n","best_val_acc = 0.0\n","for k in range(1):\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n","    print ('fold {}'.format(k+1))\n","    X_train, y_train, p_train = X_scaled[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_scaled[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train[0:500,:,:], y_train[0:500], p_train[0:500], aug_type=aug_type, window_size=window_size, window_stride=vote_num)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('best validation accuracy is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yXMwk7XXuhK1","colab":{}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","if aug_type == 'window':\n","    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        vote_idx = np.random.choice(1000-window_size, vote_num)\n","        vote_pred = np.zeros(y.shape[0])\n","        for i in range(len(vote_idx)):\n","            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","            output = model(X_sub)\n","            pred = torch.argmax(output, dim=1)\n","            if i == 0:\n","                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","            else:\n","                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","            for row in range(y.shape[0]):\n","                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","        vote_pred = torch.from_numpy(vote_pred).long()\n","        correct += torch.sum(vote_pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total \n","else:\n","    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test)\n","    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        output = model(X)                    \n","        pred = torch.argmax(output, dim=1)\n","        correct += torch.sum(pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6PAjCPdOhYZV","colab_type":"text"},"source":["## Test windowed 2"]},{"cell_type":"markdown","metadata":{"id":"Pfi4RDefhiVv","colab_type":"text"},"source":["### Preprocess data"]},{"cell_type":"code","metadata":{"id":"dkOMlK8ah01M","colab_type":"code","colab":{}},"source":["window_size = 300\n","stride = 100\n","X_wind, _, _, _ = window_data(X_train_valid, y_train_valid, person_train_valid, window_size, stride)\n","train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","X_wind[val_fold[0]].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aVwwG__uhe-U","colab_type":"text"},"source":["### Run the thing"]},{"cell_type":"code","metadata":{"id":"41bF3YzslkHp","colab_type":"code","colab":{}},"source":["aug_type = None\n","best_val_acc = 0.0\n","for k in range(1):\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size=154)\n","    print ('fold {}'.format(k+1))\n","    X_train, y_train, p_train = X_wind[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_wind[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('best validation accuracy is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bPJxfcxUuCKx","colab_type":"text"},"source":["## finding ideal window size for windowed augmentation"]},{"cell_type":"code","metadata":{"id":"8180aZ6Ntk7n","colab_type":"code","colab":{}},"source":["aug_type = \"window\"\n","#window_size = 50\n","windows = [500, 300, 100]\n","vote_num = 50\n","stride = 10\n","best_val_acc = 0.0\n","k = 0\n","for window_size in windows:\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n","    # indicate hyperparameters here\n","    print ('window_size {}'.format(window_size))\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc = TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","#print ('best validation is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8KXy8mleUXbW","colab_type":"text"},"source":["##CWT - test for top_scale and num_levels"]},{"cell_type":"markdown","metadata":{"id":"-DDfijHMPeas","colab_type":"text"},"source":["#### Num Levels"]},{"cell_type":"code","metadata":{"id":"zprJ1T6tUXzl","colab_type":"code","colab":{}},"source":["aug_type = \"cwt\"\n","levels = [20,25,30]\n","#num_levels = 5\n","top_scale = 1\n","best_val_acc = 0.0\n","k = 0\n","    \n","for num_levels in levels:\n","    print('num_levels: {}'.format(num_levels))\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size = 22*num_levels)\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type) / 5\n","print ('average best validation accuracy of 5 folds is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YEWpDbDKPYdB","colab_type":"text"},"source":["#### Top Scale"]},{"cell_type":"code","metadata":{"id":"cs6GDnbhbSui","colab_type":"code","colab":{}},"source":["aug_type = \"cwt\"\n","#levels = [3,5,10,15]\n","scales = [0.3, 0.5, 0.8, 1, 1.2]\n","num_levels = 15\n","#top_scale = 3\n","window_size = 200\n","vote_num = 20\n","best_val_acc = 0.0\n","k = 0\n","    \n","for top_scale in scales:\n","    print('top_scale: {}'.format(top_scale))\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size = 22*num_levels)\n","    print ('fold {}'.format(k+1))\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('average best train accuracy is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"whz4MmYczz0s"},"source":["## CWT augmentation\n","\n","Testing Accuracy: 0.2483"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"p3l-_hKxzz0t"},"source":["#### Split the data to train and validation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UEAPEPh5zz0u","colab":{}},"source":["train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","X_train_valid[train_fold[0]].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hHpnfqA0zz0x"},"source":["###Run the thing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-kf1dj45zz0x","colab":{}},"source":["aug_type = \"cwt\"\n","num_levels = 20\n","top_scale = 1\n","best_val_acc = 0.0\n","k = 0\n","\n","# indicate hyperparameters here\n","print('running cwt with num_levels: {}  and top_scale: {}'.format(num_levels, top_scale))\n","model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size = 22*num_levels)\n","X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('best validation accuracy is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9wbiy0rKzz0z"},"source":["###Test it"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ykwgchKJzz0z","colab":{}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","if aug_type == 'window':\n","    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        vote_idx = np.random.choice(1000-window_size, vote_num)\n","        vote_pred = np.zeros(y.shape[0])\n","        for i in range(len(vote_idx)):\n","            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","            output = model(X_sub)\n","            pred = torch.argmax(output, dim=1)\n","            if i == 0:\n","                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","            else:\n","                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","            for row in range(y.shape[0]):\n","                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","        vote_pred = torch.from_numpy(vote_pred).long()\n","        correct += torch.sum(vote_pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total \n","else:\n","    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        output = model(X)                    \n","        pred = torch.argmax(output, dim=1)\n","        correct += torch.sum(pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mp1dMhb18lNF"},"source":["## CWT augmentation type 2\n","\n","Testing Accuracy: 0.2483"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kiHkJ2sj8lNH"},"source":["#### Split the data to train and validation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3Z6Mdvsf8lNI","colab":{}},"source":["train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","X_train_valid[train_fold[0]].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0LZiXX8e8lNK"},"source":["###Run the thing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pg6cBTGL8lNL","colab":{}},"source":["aug_type = \"cwt2\"\n","num_levels = 20\n","top_scale = 1\n","best_val_acc = 0.0\n","k = 0\n","\n","# indicate hyperparameters here\n","model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size = 22)\n","X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wnQuJsftItvG","colab_type":"code","colab":{}},"source":["X_train, y_train, p_train, window_size = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDg8FKB8Ifft","colab_type":"code","colab":{}},"source":["if aug_type != 'window':\n","    X_val, y_val, p_val, F = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Qozx1o3GJII","colab_type":"code","colab":{}},"source":["X_train.shape[0]/X_train_valid.shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fpbg9XQfD8L5","colab_type":"code","colab":{}},"source":["vote_num = 100\n","print('running cwt2 with num_levels: {}  and top_scale: {}'.format(num_levels, top_scale))\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('best validation accuracy is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"N-rg4c5P8lNN"},"source":["###Test it"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n7myg9J58lNN","colab":{}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","if aug_type == 'window':\n","    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        vote_idx = np.random.choice(1000-window_size, vote_num)\n","        vote_pred = np.zeros(y.shape[0])\n","        for i in range(len(vote_idx)):\n","            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","            output = model(X_sub)\n","            pred = torch.argmax(output, dim=1)\n","            if i == 0:\n","                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","            else:\n","                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","            for row in range(y.shape[0]):\n","                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","        vote_pred = torch.from_numpy(vote_pred).long()\n","        correct += torch.sum(vote_pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total \n","else:\n","    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        output = model(X)                    \n","        pred = torch.argmax(output, dim=1)\n","        correct += torch.sum(pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Sv4-y-_auhKx"},"source":["## CWT augmentation followed by windowing\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-lHPsuJCSA-w"},"source":["####Preprocess data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kCAgAT_5SA-y","colab":{}},"source":["num_levels = 20\n","top_scale = 1\n","X_cwt = cwt_data(X_train_valid, num_levels, top_scale=top_scale)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TAQSoV_E4IcP","colab_type":"code","colab":{}},"source":["train_fold, val_fold = Train_Val_Data(X_cwt, y_train_valid)\n","X_cwt[train_fold[0]].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0CbVpb4hSEuh","colab_type":"text"},"source":["###Run the thing"]},{"cell_type":"code","metadata":{"id":"BPbi8cpNR4Ke","colab_type":"code","colab":{}},"source":["aug_type = 'window'\n","best_val_acc = 0.0\n","window_size = 200\n","stride = 100\n","vote_num = 50\n","k = 0\n","    \n","for k in range(1):\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size = 22*num_levels)\n","    print ('fold {}'.format(k+1))\n","    X_train, y_train, p_train = X_cwt[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_cwt[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('best validation is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hWL-LlzDTQPI","colab_type":"text"},"source":["###Test it"]},{"cell_type":"code","metadata":{"id":"KzSH5i1tTME-","colab_type":"code","colab":{}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","X_test = cwt_data(X_test, num_levels, top_scale=top_scale)\n","\n","if aug_type == 'window':\n","    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        vote_idx = np.random.choice(1000-window_size, vote_num)\n","        vote_pred = np.zeros(y.shape[0])\n","        for i in range(len(vote_idx)):\n","            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","            output = model(X_sub)\n","            pred = torch.argmax(output, dim=1)\n","            if i == 0:\n","                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","            else:\n","                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","            for row in range(y.shape[0]):\n","                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","        vote_pred = torch.from_numpy(vote_pred).long()\n","        correct += torch.sum(vote_pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total \n","else:\n","    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        output = model(X)                    \n","        pred = torch.argmax(output, dim=1)\n","        correct += torch.sum(pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y0kRQ1Zg-t8s"},"source":["#ICA"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wecc6fCK4fsa"},"source":["###Preprocess data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"K1H_PyVS4fsc","colab":{}},"source":["X_scaled = scale_data(X_train_valid)\n","n_components = 10\n","X_ica5 = ica_data(X_scaled, n_components)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"098qVB5XCovH","colab_type":"code","colab":{}},"source":["np.save(dataset_path + \"X_train_ICA10.npy\", X_ica5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OHJONiyMHgnc","colab_type":"code","colab":{}},"source":["X_test_scaled = scale_data(X_test)\n","n_components = 10\n","X_test_ica5 = ica_data(X_test_scaled, n_components)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GHcy4LTfH6Jj","colab_type":"code","colab":{}},"source":["X_test_ica5"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FnM4s1HDZ9kA","colab_type":"text"},"source":["####Load the data"]},{"cell_type":"code","metadata":{"id":"O-ifJOu8Z8q1","colab_type":"code","colab":{}},"source":["X_train_ICA = np.load(dataset_path + \"X_train_ICA.npy\")\n","X_test_ICA  = np.load(dataset_path + \"X_test_ICA.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qTYe510akdH","colab_type":"code","colab":{}},"source":["train_fold, val_fold = Train_Val_Data(X_train_ICA, y_train_valid)\n","X_train_ICA[train_fold[0]].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iQsbDrTD4hPw","colab_type":"text"},"source":["###Run the thing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C_R_S0Di-t8u","colab":{}},"source":["aug_type = 'window'\n","window_size = 200\n","stride = 50\n","vote_num = 50\n","best_val_acc = 0.0\n","k = 1\n","    \n","# indicate hyperparameters here\n","model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size = X_train_ICA5.shape[1])\n","X_train, y_train, p_train = X_train_ICA5[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","X_val, y_val, p_val = X_train_ICA5[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, ica_num=ica_components)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","best_val_acc = TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('final validation accuracy is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[]}]}