{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "colab_version_clean_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA1x8mSiTyYL",
        "colab_type": "text"
      },
      "source": [
        "### loading modules and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQwpQEszAQ9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6iA6D4yYwiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # If using colab\n",
        " from google.colab import files\n",
        " files.upload()\n",
        "# # select the 3 .py files (models, utils, data_utils)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-S67grVAoSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################################################\n",
        "\n",
        "# If running with Google Colab\n",
        "# Create a folder \"C247\" and then store the project datasets within that folder\n",
        "# Check that your datasets are setup correctly\n",
        "\n",
        "!ls \"/content/gdrive/My Drive/C247\" # File path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jkt1ZNZWIhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models import *\n",
        "from utils import *\n",
        "from data_utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJfyBLNLA686",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_test = np.load(\"X_test.npy\")\n",
        "# y_test = np.load(\"y_test.npy\")\n",
        "# person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "# X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "# y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "# person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "# Change if your directory is different\n",
        "\n",
        "# dataset_path = './data/' # Yiming Path\n",
        "dataset_path = \"/content/gdrive/My Drive/C247/\" \n",
        "\n",
        "X_test = np.load(dataset_path + \"X_test.npy\")\n",
        "y_test = np.load(dataset_path + \"y_test.npy\")\n",
        "person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n",
        "X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n",
        "y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n",
        "person_test = np.load(dataset_path + \"person_test.npy\")\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))\n",
        "\n",
        "#train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90IvaY2LTyY1",
        "colab_type": "text"
      },
      "source": [
        "### K-Fold Training and Validation (use k=1 to get results faster)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3_bl5-h3DxE",
        "colab_type": "text"
      },
      "source": [
        "Data $\\rightarrow$ Window $\\rightarrow$ STFT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrIa4w_EqqOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 100\n",
        "window_stride = 40\n",
        "vote_num = 30 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 2.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 5\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yGSJZ62TyY7",
        "colab_type": "text"
      },
      "source": [
        "### Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kw9gvQr0S44",
        "colab_type": "text"
      },
      "source": [
        "#### Test 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT9IdrogTyY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFarYt6AtV9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 150\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 2.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOhVBENUvGWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oYBFsTI0X6O",
        "colab_type": "text"
      },
      "source": [
        "### Test 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEbqPF23weaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 150\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 1.0\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 25\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 2e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYf_Zl6NxE-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SeGVR_v0dpG",
        "colab_type": "text"
      },
      "source": [
        "### Test 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798JftVyyh-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 1.0\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFkQDOSZzR1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMH4qopo1t8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGEBGZiS2EK-",
        "colab_type": "text"
      },
      "source": [
        "### Test 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J8syp_l2GAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 1.0\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"window\"\n",
        "aug_2 = \"cwt\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYzzeNN_2Kh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THs058di9syd",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmwRgYkb8a5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 0.7\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCyum8Am977T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPzC1YWnAwsk",
        "colab_type": "text"
      },
      "source": [
        "### Testtttt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Pq_8g2Ae4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 0.4\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFnUcUAGCYn0",
        "colab_type": "text"
      },
      "source": [
        "## Bandpass Filter Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73g4VX76HqK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bandpass_filter(X,low,high):\n",
        "  N, C, T = X.shape\n",
        "  out = np.zeros_like(X)\n",
        "  nyq = 125 #nyquist frequency, highest able to be sensed for this data\n",
        "  if high > nyq :\n",
        "    high = nyq\n",
        "  order = 9\n",
        "\n",
        "  b, a = sig.butter(order, [low/nyq,high/nyq], btype='band')\n",
        "  out = sig.lfilter(b, a, X, axis=-1)\n",
        "\n",
        "  return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi3kzLexJrNe",
        "colab_type": "text"
      },
      "source": [
        "## Tests with bandpass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQp9Waa8O-eN",
        "colab_type": "text"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwdFsE2LCTC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 9\n",
        "cwt_scale = 1.0\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 30\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ7xtszgONPW",
        "colab_type": "text"
      },
      "source": [
        "### Test Again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHbuo9WYC8n4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 10\n",
        "cwt_scale = 2\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 40\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 5\n",
        "band_high = 35\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98CEEa5vTHbW",
        "colab_type": "text"
      },
      "source": [
        "### Using weird windowing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZuppYXaOhA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 10\n",
        "cwt_scale = 0.4\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'CNNGRUnet'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 2e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt2\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deSamYEt9Ltc",
        "colab_type": "text"
      },
      "source": [
        "### Repeating Josh's test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtJS_EoX6oGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 50\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 100\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.6\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 0\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"cwt2\"\n",
        "aug_2 = \"window\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJDD5RnrP8hu",
        "colab_type": "text"
      },
      "source": [
        "### Larger Window"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnHBn2FyP8BY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 125\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 0\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = \"window\"\n",
        "aug_2 = \"stft\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "for k in range(num_folds):\n",
        "    # indicate hyperparameters here\n",
        "    print ('fold {}'.format(k+1))\n",
        "    X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "    X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "    print('Initial fold shape: {}'.format(X_train.shape))\n",
        "    #apply second augmentation\n",
        "    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "    \n",
        "    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "    print('{} applied...'.format(aug_2))\n",
        "    print('Data shape: {}'.format(X_train.shape))\n",
        "    \n",
        "    model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "    print('Data prepared, model initialized, beginning training...')\n",
        "    best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "print('Augmenting test data...')\n",
        "X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "#X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_2,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('Testing...')\n",
        "TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7djE9W2QEbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0A7RQPbLzv1",
        "colab_type": "text"
      },
      "source": [
        "### STFT Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glQtMnWYLygG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_sizes = range(10,200,10)\n",
        "stft_strides = range(1,10)\n",
        "\n",
        "test_acc = np.empty((len(stft_sizes),len(stft_strides)))\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = None\n",
        "aug_2 = \"stft\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "#band_low = 7\n",
        "#band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "#X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1)#,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "for i in range(len(stft_sizes)):\n",
        "  for j in range(len(stft_strides)):\n",
        "    stft_size = stft_sizes[i]\n",
        "    stft_stride = stft_strides[j]\n",
        "    print('CURRENT STFT SIZE: %s CURRENT STFT STRIDE: %s'%(stft_size,stft_stride))\n",
        "    for k in range(num_folds):\n",
        "        # indicate hyperparameters here\n",
        "        print ('fold {}'.format(k+1))\n",
        "        X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "        X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "        print('Initial fold shape: {}'.format(X_train.shape))\n",
        "        #apply second augmentation\n",
        "        X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "        \n",
        "        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "        print('{} applied...'.format(aug_2))\n",
        "        print('Data shape: {}'.format(X_train.shape))\n",
        "        \n",
        "        model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "        EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "        EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "        EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "        EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "        print('Data prepared, model initialized, beginning training...')\n",
        "        best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "    print('Augmenting test data...')\n",
        "    X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    #X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_2,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    print('Testing...')\n",
        "    test_acc[i,j] = TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size,vote_num=vote_num,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUJWNHGQPvlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_sizes = range(40,200,10)\n",
        "stft_strides = range(1,10)\n",
        "\n",
        "test_acc = np.empty((len(stft_sizes),len(stft_strides)))\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = None\n",
        "aug_2 = \"stft\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "#band_low = 7\n",
        "#band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "#X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1)#,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "for i in range(len(stft_sizes)):\n",
        "  for j in range(len(stft_strides)):\n",
        "    stft_size = stft_sizes[i]\n",
        "    stft_stride = stft_strides[j]\n",
        "    print('CURRENT STFT SIZE: %s CURRENT STFT STRIDE: %s'%(stft_size,stft_stride))\n",
        "    for k in range(num_folds):\n",
        "        # indicate hyperparameters here\n",
        "        print ('fold {}'.format(k+1))\n",
        "        X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "        X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "        print('Initial fold shape: {}'.format(X_train.shape))\n",
        "        #apply second augmentation\n",
        "        X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "        \n",
        "        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "        print('{} applied...'.format(aug_2))\n",
        "        print('Data shape: {}'.format(X_train.shape))\n",
        "        \n",
        "        model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "        EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "        EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "        EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "        EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "        print('Data prepared, model initialized, beginning training...')\n",
        "        best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "    print('Augmenting test data...')\n",
        "    X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    #X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_2,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    print('Testing...')\n",
        "    test_acc[i,j] = TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size,vote_num=vote_num,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef_l2SiIyjGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_sizes = range(100,200,10)\n",
        "stft_strides = range(4,10,2)\n",
        "\n",
        "test_acc = np.empty((len(stft_sizes),len(stft_strides)))\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = None\n",
        "aug_2 = \"stft\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "#band_low = 7\n",
        "#band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "#X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1)#,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "for i in range(len(stft_sizes)):\n",
        "  for j in range(len(stft_strides)):\n",
        "    stft_size = stft_sizes[i]\n",
        "    stft_stride = stft_strides[j]\n",
        "    print('CURRENT STFT SIZE: %s CURRENT STFT STRIDE: %s'%(stft_size,stft_stride))\n",
        "    for k in range(num_folds):\n",
        "        # indicate hyperparameters here\n",
        "        print ('fold {}'.format(k+1))\n",
        "        X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "        X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "        print('Initial fold shape: {}'.format(X_train.shape))\n",
        "        #apply second augmentation\n",
        "        X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "        \n",
        "        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "        print('{} applied...'.format(aug_2))\n",
        "        print('Data shape: {}'.format(X_train.shape))\n",
        "        \n",
        "        model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "        EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "        EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "        EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "        EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "        print('Data prepared, model initialized, beginning training...')\n",
        "        best_model = TrainValRNN(model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "    print('Augmenting test data...')\n",
        "    X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    #X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_2,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    print('Testing...')\n",
        "    test_acc[i,j] = TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size,vote_num=vote_num,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szW0-b8r0_RP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_sizes = range(100,1000,50)\n",
        "stft_strides = range(5,20,5)\n",
        "\n",
        "test_acc = np.empty((len(stft_sizes),len(stft_strides)))\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = None\n",
        "aug_2 = \"stft\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1)#,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "for i in range(len(stft_sizes)):\n",
        "  for j in range(len(stft_strides)):\n",
        "    stft_size = stft_sizes[i]\n",
        "    stft_stride = stft_strides[j]\n",
        "    print('CURRENT STFT SIZE: %s CURRENT STFT STRIDE: %s'%(stft_size,stft_stride))\n",
        "    for k in range(num_folds):\n",
        "        # indicate hyperparameters here\n",
        "        print ('fold {}'.format(k+1))\n",
        "        X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "        X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "        print('Initial fold shape: {}'.format(X_train.shape))\n",
        "        #apply second augmentation\n",
        "        X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "        \n",
        "        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "        print('{} applied...'.format(aug_2))\n",
        "        print('Data shape: {}'.format(X_train.shape))\n",
        "        \n",
        "        model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "        EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "        EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "        EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "        EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "        print('Data prepared, model initialized, beginning training...')\n",
        "        best_model = TrainValRNN(verbose=False,model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "    print('Augmenting test data...')\n",
        "    X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    #X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_2,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    print('Testing...')\n",
        "    test_acc[i,j] = TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size,vote_num=vote_num,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRfU9cBR-VEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 250\n",
        "window_stride = 75\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_sizes = range(300,1000,100)\n",
        "stft_strides = range(5,20,5)\n",
        "\n",
        "test_acc = np.empty((len(stft_sizes),len(stft_strides)))\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = None\n",
        "aug_2 = \"stft\"\n",
        "\n",
        "#BANDPASS PARAMS\n",
        "band_low = 7\n",
        "band_high = 30\n",
        "\n",
        "#bandpass the data\n",
        "X_train_valid = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "print('Data bandpass filtered...')\n",
        "\n",
        "#make data N(0,1)\n",
        "mu = np.mean(X_train_valid, axis=(0,2), keepdims = True) \n",
        "std = np.std(X_train_valid, axis=(0,2), keepdims = True)\n",
        "X_train_valid = standardize(X_train_valid, mu, std)\n",
        "print('Data normalized...')\n",
        "print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "# apply first augmentation\n",
        "X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid,y_train_valid,person_train_valid,aug_type=aug_1)#,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "print('{} applied...'.format(aug_1))\n",
        "train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "for i in range(len(stft_sizes)):\n",
        "  for j in range(len(stft_strides)):\n",
        "    stft_size = stft_sizes[i]\n",
        "    stft_stride = stft_strides[j]\n",
        "    print('CURRENT STFT SIZE: %s CURRENT STFT STRIDE: %s'%(stft_size,stft_stride))\n",
        "    for k in range(num_folds):\n",
        "        # indicate hyperparameters here\n",
        "        print ('fold {}'.format(k+1))\n",
        "        X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "        X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "        print('Initial fold shape: {}'.format(X_train.shape))\n",
        "        #apply second augmentation\n",
        "        X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "        \n",
        "        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "        print('{} applied...'.format(aug_2))\n",
        "        print('Data shape: {}'.format(X_train.shape))\n",
        "        \n",
        "        model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "        EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "        EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "        EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "        EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "        print('Data prepared, model initialized, beginning training...')\n",
        "        best_model = TrainValRNN(verbose=False,model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "    print('Augmenting test data...')\n",
        "    X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    #X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_2,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    print('Testing...')\n",
        "    test_acc[i,j] = TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size,vote_num=vote_num,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx3w5xyI7W3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBLglhKeAvHh",
        "colab_type": "text"
      },
      "source": [
        "## Bandpass + Window grid search on bandpass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VThQFWu9Aw4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setting up the data augmentation here\n",
        "#aug_type = 'cwt'\n",
        "\n",
        "#WINDOW PARAMS\n",
        "window_size = 200\n",
        "window_stride = 20\n",
        "vote_num = 50 # how many samples should vote to classify?\n",
        "\n",
        "#STFT PARAMS\n",
        "stft_size = 125\n",
        "stft_stride = 5\n",
        "\n",
        "#CWT PARAMS\n",
        "cwt_level = 8\n",
        "cwt_scale = 0.5\n",
        "\n",
        "#RNN PARAMS\n",
        "rnn_type = 'GRU'\n",
        "dropout_param = 0.4\n",
        "num_epochs = 20\n",
        "hidden_size = 50\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-3\n",
        "num_folds = 1\n",
        "\n",
        "aug_1 = None\n",
        "aug_2 = \"window\"\n",
        "\n",
        "lows = range(2,16,2)\n",
        "highs = range(20,50,5)\n",
        "\n",
        "\n",
        "for low in lows:\n",
        "  for high in highs:\n",
        "    #BANDPASS PARAMS\n",
        "    band_low = low\n",
        "    band_high = high\n",
        "\n",
        "    #bandpass the data\n",
        "    X_train_valid_filt = bandpass_filter(X_train_valid, band_low, band_high)\n",
        "    print('Data bandpass filtered with low = %s and high = %s ...'%(low,high))\n",
        "\n",
        "    #make data N(0,1)\n",
        "    mu = np.mean(X_train_valid_filt, axis=(0,2), keepdims = True) \n",
        "    std = np.std(X_train_valid_filt, axis=(0,2), keepdims = True)\n",
        "    X_train_valid = standardize(X_train_valid_filt, mu, std)\n",
        "    print('Data normalized...')\n",
        "    print('Data shape: {}'.format(X_train_valid.shape))\n",
        "\n",
        "    # apply first augmentation\n",
        "    X_train_valid_aug,y_train_valid_aug,person_train_valid_aug = Aug_Data(X_train_valid_filt,y_train_valid,person_train_valid,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    print('{} applied...'.format(aug_1))\n",
        "    train_fold, val_fold = Train_Val_Data(X_train_valid_aug, y_train_valid_aug)\n",
        "\n",
        "\n",
        "    for k in range(num_folds):\n",
        "        # indicate hyperparameters here\n",
        "        print ('fold {}'.format(k+1))\n",
        "        X_train, y_train, p_train = X_train_valid_aug[train_fold[k]], y_train_valid_aug[train_fold[k]], person_train_valid_aug[train_fold[k]]\n",
        "        X_val, y_val, p_val = X_train_valid_aug[val_fold[k]], y_train_valid_aug[val_fold[k]], person_train_valid_aug[val_fold[k]]\n",
        "        print('Initial fold shape: {}'.format(X_train.shape))\n",
        "        #apply second augmentation\n",
        "        X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_2, cwt_level=cwt_level, cwt_scale=cwt_scale, stft_size=stft_size, stft_stride=stft_stride, window_size=window_size, window_stride=window_stride)\n",
        "        \n",
        "        #X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, window_size=window_size, aug_type=aug_2, cwt_level=cwt_level,cwt_scale=cwt_scale,stft_size=stft_size,stft_stride=stft_stride,window_stride=window_stride)\n",
        "        print('{} applied...'.format(aug_2))\n",
        "        print('Data shape: {}'.format(X_train.shape))\n",
        "        \n",
        "        model, criterion, optimizer = InitRNN(rnn_type=rnn_type, dropout=dropout_param, input_size=X_train.shape[1], hidden_size=hidden_size, lr=lr,weight_decay=weight_decay)\n",
        "        EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n",
        "        EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
        "        EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n",
        "        EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n",
        "        print('Data prepared, model initialized, beginning training...')\n",
        "        best_model = TrainValRNN(verbose=False,model=model, criterion=criterion, optimizer=optimizer, trainloader=EEG_trainloader, valloader=EEG_valloader, num_epochs=num_epochs, aug_type=aug_2, window_size=window_size, vote_num=vote_num)\n",
        "\n",
        "    print('Augmenting test data...')\n",
        "    X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_1,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    #X_test_aug, y_test_aug, person_test_aug = Aug_Data(X_test,y_test,person_test,aug_type=aug_2,window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale)\n",
        "    print('Testing...')\n",
        "    TestRNN(best_model, X_test_aug, y_test_aug, person_test_aug, aug_type=aug_2, window_size=window_size,window_stride=window_stride,stft_size=stft_size,stft_stride=stft_stride,cwt_level=cwt_level,cwt_scale=cwt_scale, vote_num=vote_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUhipihGCSVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}