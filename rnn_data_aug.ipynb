{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test = np.load(\"./data/X_test.npy\")\n",
    "y_test = np.load(\"./data/y_test.npy\")\n",
    "person_train_valid = np.load(\"./data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"./data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"./data/y_train_valid.npy\")\n",
    "person_test = np.load(\"./data/person_test.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training/Valid data shape: (2115, 22, 1000)\nTest data shape: (443, 22, 1000)\nTraining/Valid target shape: (2115,)\nTest target shape: (443,)\nPerson train/valid shape: (2115, 1)\nPerson test shape: (443, 1)\n"
    }
   ],
   "source": [
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"data_augmentation.py\n",
    "Automatically generated by Colaboratory.\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1mspvRcDFXus4jLFjUgUPtgrzm95cMxb7\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "We will put functions to augment data in here.\n",
    "Functions in this file:\n",
    "  window_data\n",
    "\"\"\"\n",
    "\n",
    "def window_data(X, y, window_size, stride):\n",
    "  '''\n",
    "  This function takes in X (a 3-d tensor) of size (#trials x #electrodes x #time \n",
    "  series) and y data of size (#trials) and outputs two options for using it. \n",
    "  X_new1: The first output stacks the windowed data in a new dimension, resulting \n",
    "    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\n",
    "  X_new2: The second option makes the windows into new trails, resulting in a new\n",
    "    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \n",
    "    for the larger number of trials, we also need to augment the y data.\n",
    "  y_new:  The augmented y vector of size (#trials*#windows) to match X_new2.\n",
    "  Some code to visualize what's happening:\n",
    "  #X_new_wind1, X_new_wind2, Y_new  = window_data(X_train_valid, y_train_valid, 200, 20)\n",
    "  #print(X_new_wind1.shape)\n",
    "  #print(X_new_wind2.shape)\n",
    "  #print(Y_new.shape)\n",
    "  '''\n",
    "  num_sub_trials = int((X.shape[2]-window_size)/stride)\n",
    "  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\n",
    "  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\n",
    "  y_new = np.empty([X.shape[0]*num_sub_trials])\n",
    "  for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "      for k in range(num_sub_trials):\n",
    "        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\n",
    "        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\n",
    "        y_new[i*num_sub_trials+k] = y[i]\n",
    "  return X_new1, X_new2, y_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_new, y_new = window_data(X_train_valid, y_train_valid, window_size=100, stride=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(19035,)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape\n",
    "y_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Dataloader for EEG data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_Dataset(Dataset):\n",
    "    def __init__ (self, X, y, p, mode='train'):\n",
    "        trial_num = X.shape[0]\n",
    "        trial_idx = np.arange(trial_num)\n",
    "        np.random.shuffle(trial_idx)\n",
    "        train_idx = trial_idx[: int(np.floor(0.8*trial_num))]\n",
    "        val_idx = trial_idx[int(np.ceil(0.8*trial_num)):]\n",
    "        self.X = X\n",
    "        self.y = y - 769\n",
    "        self.p = p\n",
    "        if mode == 'train':\n",
    "            self.sample_list = train_idx\n",
    "        else:\n",
    "            self.sample_list = val_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.sample_list))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample_idx = self.sample_list[idx]\n",
    "        eeg_seq = torch.from_numpy(self.X[sample_idx,:,:]).float()\n",
    "        label = torch.tensor(self.y[sample_idx]).long()\n",
    "        #person_id = torch.from_numpy(self.p[sample_idx,:]).long()\n",
    "        sample = {'eeg_seq': eeg_seq, 'label': label}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n1\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n2\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n3\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n4\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n5\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n6\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n7\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n8\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n9\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n10\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n11\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n12\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n13\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n14\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n15\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n16\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n17\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n18\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n19\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n20\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n21\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n22\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n23\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n24\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n25\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n26\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n27\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n28\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n29\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n30\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n31\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n32\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n33\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n34\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n35\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n36\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n37\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n38\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n39\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n40\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n41\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n42\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n43\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n44\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n45\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n46\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n47\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n48\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n49\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n50\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n51\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n52\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n53\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n54\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n55\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n56\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n57\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n58\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n59\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n60\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n61\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n62\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n63\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n64\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n65\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n66\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n67\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n68\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n69\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n70\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n71\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n72\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n73\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n74\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n75\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n76\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n77\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n78\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n79\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n80\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n81\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n82\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n83\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n84\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n85\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n86\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n87\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n88\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n89\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n90\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n91\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n92\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n93\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n94\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n95\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n96\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n97\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n98\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n99\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n100\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n101\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n102\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n103\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n104\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n105\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n106\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n107\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n108\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n109\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n110\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n111\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n112\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n113\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n114\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n115\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n116\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n117\ntorch.Size([100, 128, 22])\ntorch.Size([128])\n118\ntorch.Size([100, 124, 22])\ntorch.Size([124])\n"
    }
   ],
   "source": [
    "EEG_trainset = EEG_Dataset(X_new, y_new, person_train_valid, mode='train')\n",
    "EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
    "#EEG_testset = EEG_Dataset(mode='test')\n",
    "#EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=True)\n",
    "\n",
    "for idx, batch in enumerate(EEG_trainloader):\n",
    "    print (idx)\n",
    "    eeg_seq = batch['eeg_seq'].permute(2,0,1)\n",
    "    print (eeg_seq.size())\n",
    "    print (batch['label'].size())\n",
    "    #print (batch['person_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LSTM + FC to perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "epoch:1\nacc:0.26044129235618596\nloss:165.42790460586548\nepoch:2\nacc:0.28887575518781194\nloss:163.9574464559555\nepoch:3\nacc:0.30194378775939057\nloss:163.21649825572968\nepoch:4\nacc:0.3202653007617547\nloss:162.24136555194855\nepoch:5\nacc:0.3324796427633307\nloss:161.41858565807343\nepoch:6\nacc:0.34581034935644867\nloss:160.07163834571838\nepoch:7\nacc:0.3536905700026267\nloss:158.99358248710632\nepoch:8\nacc:0.3675466246388232\nloss:157.64956378936768\nepoch:9\nacc:0.3798923036511689\nloss:155.6817011833191\nepoch:10\nacc:0.396046755975834\nloss:154.0604157447815\nepoch:11\nacc:0.410428158655109\nloss:152.18084239959717\nepoch:12\nacc:0.42796164959285526\nloss:149.54713129997253\nepoch:13\nacc:0.4420147097452062\nloss:147.0814243555069\nepoch:14\nacc:0.4583004990806409\nloss:144.48752653598785\nepoch:15\nacc:0.4702521670606777\nloss:142.18133568763733\nepoch:16\nacc:0.484896243761492\nloss:139.26927208900452\nepoch:17\nacc:0.507551878119254\nloss:135.7285737991333\nepoch:18\nacc:0.5197662201208301\nloss:132.73919993638992\nepoch:19\nacc:0.5394667717362753\nloss:129.68473595380783\nepoch:20\nacc:0.554701864985553\nloss:126.47195601463318\n"
    }
   ],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, class_num):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hn, cn) = self.rnn(x)\n",
    "        out = self.fc(torch.squeeze(hn))\n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "model = model(input_size=22, hidden_size=100, class_num=4).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "\n",
    "EEG_trainset = EEG_Dataset(X_new, y_new, person_train_valid, mode='train')\n",
    "EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n",
    "EEG_testset = EEG_Dataset(X_new, y_new, person_train_valid, mode='test')\n",
    "EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n",
    "\n",
    "epoch = 20\n",
    "for i in range (epoch):\n",
    "    print ('epoch:{}'.format(i+1))\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for idx, batch in enumerate(EEG_trainloader):\n",
    "        eeg_seq = batch['eeg_seq'].permute(2,0,1).to(device)\n",
    "        label = batch['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output= model(eeg_seq)\n",
    "        loss = criterion(output, label)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()                \n",
    "        optimizer.step()\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        correct += torch.sum(pred == label).item()\n",
    "        total += label.shape[0]\n",
    "    print ('acc:{}'.format(correct/total))\n",
    "    print ('loss:{}'.format(running_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "acc:0.5098502758077226\n"
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "total = 0\n",
    "correct = 0\n",
    "for idx, batch in enumerate(EEG_testloader):\n",
    "    eeg_seq = batch['eeg_seq'].permute(2,0,1).to(device)\n",
    "    label = batch['label'].to(device)\n",
    "    output= model(eeg_seq)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    correct += torch.sum(pred == label).item()\n",
    "    total += label.shape[0]\n",
    "print ('acc:{}'.format(correct/total))\n",
    "#print ('loss:{}'.format(running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('ee247': conda)",
   "language": "python",
   "name": "python361064bitee247conda2f15fa1c8e864ba0bbee8e7adf578eb0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}