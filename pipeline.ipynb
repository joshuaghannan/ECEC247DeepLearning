{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "ee247",
   "display_name": "python3.6(ee247)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import scipy.signal as sig\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "GPU is available\n"
    }
   ],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training/Valid data shape: (2115, 22, 1000)\nTest data shape: (443, 22, 1000)\nTraining/Valid target shape: (2115,)\nTest target shape: (443,)\nPerson train/valid shape: (2115, 1)\nPerson test shape: (443, 1)\n"
    }
   ],
   "source": [
    "dataset_path = './data/'\n",
    "X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n",
    "y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n",
    "person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n",
    "X_test = np.load(dataset_path + \"X_test.npy\")\n",
    "y_test = np.load(dataset_path + \"y_test.npy\")\n",
    "person_test = np.load(dataset_path + \"person_test.npy\")\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some major changes here for the Train_Val_Data function\n",
    "def Train_Val_Data(X_train_valid, y_train_val):\n",
    "    '''\n",
    "    split the train_valid into k folds (we fix k = 5 here)\n",
    "    return: list of index of train data and val data of k folds\n",
    "    train_fold[i], val_fold[i] is the index for training and validation in the i-th fold \n",
    "\n",
    "    '''\n",
    "    fold_idx = []\n",
    "    train_fold = []\n",
    "    val_fold = []\n",
    "    train_val_num = X_train_valid.shape[0]\n",
    "    fold_num = int(train_val_num / 5)\n",
    "    perm = np.random.permutation(train_val_num)\n",
    "    for k in range(5):\n",
    "        fold_idx.append(np.arange(k*fold_num, (k+1)*fold_num, 1))\n",
    "    for k in range(5):\n",
    "        val_fold.append(fold_idx[k])\n",
    "        count = 0\n",
    "        for i in range(5):\n",
    "            if i != k:\n",
    "                if count == 0:\n",
    "                    train_idx = fold_idx[i]\n",
    "                else:\n",
    "                    train_idx = np.concatenate((train_idx, fold_idx[i]))\n",
    "                count += 1\n",
    "        train_fold.append(train_idx)\n",
    "\n",
    "    return train_fold, val_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Window Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(X, y, p, window_size, stride):\n",
    "  '''\n",
    "  X (a 3-d tensor) of size (#trials, #electrodes, #time series)\n",
    "  y (#trials,): label \n",
    "  p (#trials, 1): person id\n",
    "\n",
    "  X_new1: The first output stacks the windowed data in a new dimension, resulting \n",
    "    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\n",
    "  X_new2: The second option makes the windows into new trails, resulting in a new\n",
    "    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \n",
    "    for the larger number of trials, we also need to augment the y data.\n",
    "  y_new: The augmented y vector of size (#trials*#windows) to match X_new2.\n",
    "  p_new: The augmented p vector of size (#trials*#windows) to match X_new2\n",
    " \n",
    "  '''\n",
    "  num_sub_trials = int((X.shape[2]-window_size)/stride)\n",
    "  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\n",
    "  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\n",
    "  y_new = np.empty([X.shape[0]*num_sub_trials])\n",
    "  for i in range(X.shape[0]):\n",
    "    for j in range(X.shape[1]):\n",
    "      for k in range(num_sub_trials):\n",
    "        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\n",
    "        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\n",
    "        y_new[i*num_sub_trials+k] = y[i]\n",
    "        p_new[i*num_sub_trials+k] = p[i]\n",
    "  return X_new1, X_new2, y_new, p_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. STFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that computes the short-time fourier transform of the data and returns the spectrogram\n",
    "def stft_data(X, window, stride):\n",
    "    '''\n",
    "    Inputs:\n",
    "    X - input data, last dimension is one which transform will be taken across.\n",
    "    window - size of sliding window to take transform across\n",
    "    stride - stride of sliding window across time-series\n",
    "\n",
    "    Returns:\n",
    "    X_STFT - Output data, same shape as input with last dimension replaced with two new dimensions, F x T.\n",
    "            where F = window//2 + 1 is the frequency axis\n",
    "            and T = (input_length - window)//stride + 1, similar to the formula for aconvolutional filter.\n",
    "    t - the corresponding times for the time axis, T\n",
    "    f - the corresponding frequencies on the frequency axis, F.\n",
    "\n",
    "    reshape X_STFT (N, C, F, T) to (N, C*F, T) to fit the input of rnn\n",
    "\n",
    "    Note that a smaller window means only higher frequencies may be found, but give finer time resolution.\n",
    "    Conversely, a large window gives better frequency resolution, but poor time resolution.\n",
    "\n",
    "    '''\n",
    "    noverlap = window-stride\n",
    "    #print(noverlap)\n",
    "    if noverlap < 0 :\n",
    "        print('Stride results in skipped data!')\n",
    "        return\n",
    "    f, t, X_STFT = sig.spectrogram(X,nperseg=window,noverlap=noverlap,fs=250, return_onesided=True)\n",
    "    N, C, F, T = X_STFT.shape\n",
    "    X_STFT = X_STFT.reshape(N, C*F, T)\n",
    "    return X_STFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cwt_data(X, num_levels, top_scale=3):\n",
    "    '''\n",
    "    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\n",
    "    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\n",
    "    Appends to the data a new dimension, of size 'num_levels'\n",
    "    New dimension corresponds to wavelet content at num_levels different scalings (linear)\n",
    "    also returns the central frequencies that the scalings correspond to\n",
    "    input data is N x C X T\n",
    "    output data is N x C x T x F\n",
    "    note: CWT is fairly slow to compute\n",
    "\n",
    "    # EXAMPLE USAGE\n",
    "    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\n",
    "    '''\n",
    "    scales = np.logspace(start=0,stop=top_scale,num=num_levels)\n",
    "    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\n",
    "            out[i,j,:] = coef.T\n",
    "    freqs = pywt.scale2frequency('mexh',scales)*250\n",
    "    N, C, T, F = out.shape\n",
    "    X_CWT = np.transpose(out, (0,1,3,2)).reshape(N, C*F, T)\n",
    "    return X_CWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aug_Data(X, y, p, aug_type=None, window_size=None, window_stride=None, stft_size=None, stft_stride=None, cwt_level=None, cwt_scale=None):\n",
    "    if aug_type == None:\n",
    "        X_train, y_train, p_train = X, y, p\n",
    "    elif aug_type == \"window\":\n",
    "        _, X_train, y_train, p_train = window_data(X, y, p, window_size, window_stride)\n",
    "    elif aug_type == \"stft\":\n",
    "        X_train = stft_data(X, stft_size, stft_stride)\n",
    "        y_train, p_train = y, p\n",
    "    elif aug_type == 'cwt':\n",
    "        X_train = cwt_data(X, cwt_level, cwt_scale)\n",
    "        y_train, p_train = y, p\n",
    "    \n",
    "    return X_train, y_train, p_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1692, 22, 1000)"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_valid[train_fold[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_Dataset(Dataset):\n",
    "    '''\n",
    "    use use fold_idx to instantiate different train val datasets for k-fold cross validation\n",
    "\n",
    "    '''\n",
    "    def __init__ (self, train_fold, val_fold, fold_idx=0, mode='train'):\n",
    "        if mode == 'train':\n",
    "            self.X = X_train_valid[train_fold[fold_idx]]\n",
    "            self.y = y_train_valid[train_fold[fold_idx]] - 769\n",
    "            self.p = person_train_valid[train_fold[fold_idx]]\n",
    "            \n",
    "        elif mode == 'val':\n",
    "            self.X = X_train_valid[val_fold[fold_idx]]\n",
    "            self.y = y_train_valid[val_fold[fold_idx]] - 769\n",
    "            self.p = person_train_valid[val_fold[fold_idx]]         \n",
    "\n",
    "        elif mode == 'test':\n",
    "            self.X = X_test\n",
    "            self.y = y_test - 769        \n",
    "            self.p = person_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.X.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        X: (augmented) time sequence \n",
    "        y: class label\n",
    "        p: person id\n",
    "\n",
    "        '''\n",
    "        X = torch.from_numpy(self.X[idx,:,:]).float()\n",
    "        y = torch.tensor(self.y[idx]).long()\n",
    "        p = torch.from_numpy(self.p[idx,:]).long()     \n",
    "        sample = {'X': X, 'y': y, 'p':p}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMnet(nn.Module):\n",
    "    '''\n",
    "    Create Basic LSTM:\n",
    "    2 layers\n",
    "\n",
    "    TODO: make number of layers, dropout, activation function, regularization all params\n",
    "    see ex: https://blog.floydhub.com/gru-with-pytorch/\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_dim):\n",
    "        super(LSTMnet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_dim = output_dim\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, output_dim)\n",
    "    \n",
    "    def forward(self, x, h=None):\n",
    "        if type(h) == type(None):\n",
    "            out, hn = self.rnn(x)\n",
    "        else:\n",
    "            out, hn = self.rnn(x, h.detach())\n",
    "        out = self.fc(out[-1, :, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Basic GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}