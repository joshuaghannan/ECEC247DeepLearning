{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Eden_tests2.ipynb","provenance":[{"file_id":"1PgqWGedpQKO-QoN-Tp05zKK75xASQehm","timestamp":1583795432514}],"collapsed_sections":["oQ7mRTjzEI2m","y0kRQ1Zg-t8s","oBMmFyQsz1kF"],"toc_visible":true,"machine_shape":"hm"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/joshuaghannan/ECEC247_Project/blob/master/Updated_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"A6BvVAE2tvB0","colab_type":"text"},"source":["#Setup"]},{"cell_type":"code","metadata":{"id":"ZsCG9DHzEI2B","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import scipy.signal as sig\n","import pywt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o80JLlxyEI2H","colab_type":"text"},"source":["### Set up the Device"]},{"cell_type":"code","metadata":{"id":"-HjZycAvEI2J","colab_type":"code","outputId":"4c486dce-7dec-4bdc-8c37-f8929076e8cb","executionInfo":{"status":"ok","timestamp":1583868711476,"user_tz":420,"elapsed":2862,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n","is_cuda = torch.cuda.is_available()\n","\n","# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    # device = torch.device(\"cuda:1\") # For Yiming \n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["GPU not available, CPU used\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"26wpkKr9Em1E","colab_type":"text"},"source":["### If Using Colab"]},{"cell_type":"code","metadata":{"id":"KQwpQEszAQ9u","colab_type":"code","outputId":"652ca313-7fff-418c-900f-ae3c6d1e229b","executionInfo":{"status":"ok","timestamp":1583868729783,"user_tz":420,"elapsed":21151,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":123}},"source":["########################################################\n","\n","# If running with Google Colab\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E-S67grVAoSt","colab_type":"code","outputId":"ed1d20ea-f256-496c-e330-9049985e1985","executionInfo":{"status":"ok","timestamp":1583868730834,"user_tz":420,"elapsed":22182,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["########################################################\n","\n","# If running with Google Colab\n","# Create a folder \"C247\" and then store the project datasets within that folder\n","# Check that your datasets are setup correctly\n","\n","!ls \"/content/gdrive/My Drive/C247\" # File path"],"execution_count":0,"outputs":[{"output_type":"stream","text":["EEG_loading.ipynb  person_train_valid.npy  X_train_valid.npy\n","FinalProject\t   __pycache__\t\t   y_test.npy\n","icasso.py\t   Updated_pipeline.ipynb  y_train_valid.npy\n","person_test.npy    X_test.npy\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NiE2fkEzA3VO","colab_type":"text"},"source":["### Load the Datasets"]},{"cell_type":"code","metadata":{"id":"TJfyBLNLA686","colab_type":"code","outputId":"69b3e84a-6cd7-49a3-dee1-3c4427d00a8b","executionInfo":{"status":"ok","timestamp":1583868738509,"user_tz":420,"elapsed":29837,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["# X_test = np.load(\"X_test.npy\")\n","# y_test = np.load(\"y_test.npy\")\n","# person_train_valid = np.load(\"person_train_valid.npy\")\n","# X_train_valid = np.load(\"X_train_valid.npy\")\n","# y_train_valid = np.load(\"y_train_valid.npy\")\n","# person_test = np.load(\"person_test.npy\")\n","\n","# Change if your directory is different\n","\n","# dataset_path = './data/' # Yiming Path\n","dataset_path = \"/content/gdrive/My Drive/C247/\" \n","\n","X_test = np.load(dataset_path + \"X_test.npy\")\n","y_test = np.load(dataset_path + \"y_test.npy\")\n","person_train_valid = np.load(dataset_path + \"person_train_valid.npy\")\n","X_train_valid = np.load(dataset_path + \"X_train_valid.npy\")\n","y_train_valid = np.load(dataset_path + \"y_train_valid.npy\")\n","person_test = np.load(dataset_path + \"person_test.npy\")\n","print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n","print ('Test data shape: {}'.format(X_test.shape))\n","print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n","print ('Test target shape: {}'.format(y_test.shape))\n","print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n","print ('Person test shape: {}'.format(person_test.shape))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Training/Valid data shape: (2115, 22, 1000)\n","Test data shape: (443, 22, 1000)\n","Training/Valid target shape: (2115,)\n","Test target shape: (443,)\n","Person train/valid shape: (2115, 1)\n","Person test shape: (443, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gQEPDT85uAON","colab_type":"text"},"source":["# Data Manipulation"]},{"cell_type":"markdown","metadata":{"id":"JzSs4ByOEI2V","colab_type":"text"},"source":["### K-Fold"]},{"cell_type":"code","metadata":{"id":"LNKfnV6iEI2W","colab_type":"code","colab":{}},"source":["# some major changes here for the Train_Val_Data function\n","def Train_Val_Data(X_train_valid, y_train_val):\n","    '''\n","    split the train_valid into k folds (we fix k = 5 here)\n","    return: list of index of train data and val data of k folds\n","    train_fold[i], val_fold[i] is the index for training and validation in the i-th fold \n","\n","    '''\n","    fold_idx = []\n","    train_fold = []\n","    val_fold = []\n","    train_val_num = X_train_valid.shape[0]\n","    fold_num = int(train_val_num / 5)\n","    perm = np.random.permutation(train_val_num)\n","    for k in range(5):\n","        fold_idx.append(np.arange(k*fold_num, (k+1)*fold_num, 1))\n","    for k in range(5):\n","        val_fold.append(fold_idx[k])\n","        count = 0\n","        for i in range(5):\n","            if i != k:\n","                if count == 0:\n","                    train_idx = fold_idx[i]\n","                else:\n","                    train_idx = np.concatenate((train_idx, fold_idx[i]))\n","                count += 1\n","        train_fold.append(train_idx)\n","\n","    return train_fold, val_fold"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UuWOwEaeEI23","colab_type":"text"},"source":["### Customized Dataset"]},{"cell_type":"code","metadata":{"id":"b-Kbua1ZEI28","colab_type":"code","colab":{}},"source":["class EEG_Dataset(Dataset):\n","    '''\n","    use use fold_idx to instantiate different train val datasets for k-fold cross validation\n","\n","    '''\n","    def __init__ (self, X_train=None, y_train=None, p_train=None, X_val=None, y_val=None, p_val=None, X_test=None, y_test=None, p_test=None, mode='train'):\n","        if mode == 'train':\n","            self.X = X_train\n","            self.y = y_train- 769\n","            self.p = p_train\n","            \n","        elif mode == 'val':\n","            self.X = X_val\n","            self.y = y_val- 769\n","            self.p = p_val\n","\n","        elif mode == 'test':\n","            self.X = X_test\n","            self.y = y_test - 769        \n","            self.p = p_test\n","\n","    def __len__(self):\n","        return (self.X.shape[0])\n","    \n","    def __getitem__(self, idx):\n","        '''\n","        X: (augmented) time sequence \n","        y: class label\n","        p: person id\n","\n","        '''\n","        X = torch.from_numpy(self.X[idx,:,:]).float()\n","        y = torch.tensor(self.y[idx]).long()\n","        p = torch.tensor(self.p[idx]).long()\n","        #p = torch.from_numpy(self.p[idx,:]).long()     \n","        sample = {'X': X, 'y': y, 'p':p}\n","\n","        return sample"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hbiGv8ouEI2b","colab_type":"text"},"source":["## Data Augmentation Functions"]},{"cell_type":"markdown","metadata":{"id":"Mm-B-8Jc8HdG","colab_type":"text"},"source":["###Center and Whiten Data\n","Scales and shifts data to have zero mean and variance 1"]},{"cell_type":"code","metadata":{"id":"UzXmEVoM8IeA","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","def scale_data(X):\n","  #Takes 3-dim X and outputs scaled and shifted X_new with zero mean and var 1\n","  X_scaled = np.empty_like(X)\n","  for i in range(X.shape[1]):\n","    X_scaled[:,i,:] = preprocessing.scale(X[:,i,:])\n","  return X_scaled"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P_y4pb5vEI2d","colab_type":"text"},"source":["### 1. Window Data"]},{"cell_type":"code","metadata":{"id":"T5dPzOfbEI2e","colab_type":"code","colab":{}},"source":["def window_data(X, y, p, window_size, stride):\n","  '''\n","  X (a 3-d tensor) of size (#trials, #electrodes, #time series)\n","  y (#trials,): label \n","  p (#trials, 1): person id\n","\n","  X_new1: The first output stacks the windowed data in a new dimension, resulting \n","    in a 4-d tensor of size (#trials x #electrodes x #windows x #window_size).\n","  X_new2: The second option makes the windows into new trails, resulting in a new\n","    X tensor of size (#trials*#windows x #electrodes x #window_size). To account \n","    for the larger number of trials, we also need to augment the y data.\n","  y_new: The augmented y vector of size (#trials*#windows) to match X_new2.\n","  p_new: The augmented p vector of size (#trials*#windows) to match X_new2\n"," \n","  '''\n","  num_sub_trials = int((X.shape[2]-window_size)/stride)\n","  X_new1 = np.empty([X.shape[0],X.shape[1],num_sub_trials,window_size])\n","  X_new2 = np.empty([X.shape[0]*num_sub_trials,X.shape[1],window_size])\n","  y_new = np.empty([X.shape[0]*num_sub_trials])\n","  p_new = np.empty([X.shape[0]*num_sub_trials])\n","  for i in range(X.shape[0]):\n","    for j in range(X.shape[1]):\n","      for k in range(num_sub_trials):\n","        X_new1[i,j,k:k+window_size]    = X[i,j,k*stride:k*stride+window_size]\n","        X_new2[i*num_sub_trials+k,j,:] = X[i,j,k*stride:k*stride+window_size]\n","        y_new[i*num_sub_trials+k] = y[i]\n","        p_new[i*num_sub_trials+k] = p[i]\n","  return X_new1, X_new2, y_new, p_new"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQ7mRTjzEI2m","colab_type":"text"},"source":["### 2. STFT"]},{"cell_type":"code","metadata":{"id":"RU7uZckAEI2n","colab_type":"code","colab":{}},"source":["# Function that computes the short-time fourier transform of the data and returns the spectrogram\n","def stft_data(X, window, stride):\n","    '''\n","    Inputs:\n","    X - input data, last dimension is one which transform will be taken across.\n","    window - size of sliding window to take transform across\n","    stride - stride of sliding window across time-series\n","\n","    Returns:\n","    X_STFT - Output data, same shape as input with last dimension replaced with two new dimensions, F x T.\n","            where F = window//2 + 1 is the frequency axis\n","            and T = (input_length - window)//stride + 1, similar to the formula for aconvolutional filter.\n","    t - the corresponding times for the time axis, T\n","    f - the corresponding frequencies on the frequency axis, F.\n","\n","    reshape X_STFT (N, C, F, T) to (N, C*F, T) to fit the input of rnn\n","\n","    Note that a smaller window means only higher frequencies may be found, but give finer time resolution.\n","    Conversely, a large window gives better frequency resolution, but poor time resolution.\n","\n","    '''\n","    noverlap = window-stride\n","    #print(noverlap)\n","    if noverlap < 0 :\n","        print('Stride results in skipped data!')\n","        return\n","    f, t, X_STFT = sig.spectrogram(X,nperseg=window,noverlap=noverlap,fs=250, return_onesided=True)\n","    N, C, F, T = X_STFT.shape\n","    X_STFT = X_STFT.reshape(N, C*F, T)\n","    return X_STFT"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oKn0SF9dEI2s","colab_type":"text"},"source":["### 3. CWT"]},{"cell_type":"code","metadata":{"id":"HCxP0HCQEI2t","colab_type":"code","colab":{}},"source":["def cwt_data(X, num_levels, top_scale=3):\n","    '''\n","    Takes in data, computes CWT using the mexican hat or ricker wavelet using scipy\n","    Also takes in the top scale parameter.  I use logspace, so scale goes from 1 -> 2^top_scale with num_levels steps.\n","    Appends to the data a new dimension, of size 'num_levels'\n","    New dimension corresponds to wavelet content at num_levels different scalings (linear)\n","    also returns the central frequencies that the scalings correspond to\n","    input data is N x C X T\n","    output data is N x C x T x F\n","    note: CWT is fairly slow to compute\n","\n","    # EXAMPLE USAGE\n","    test, freqs = cwt_data(X_train_valid[0:5,:,:],num_levels=75,top_scale=4)\n","    '''\n","    scales = np.logspace(start=0,stop=top_scale,num=num_levels)\n","    out = np.empty((X.shape[0],X.shape[1],X.shape[2],num_levels))\n","    for i in range(X.shape[0]):\n","        for j in range(X.shape[1]):\n","            coef = sig.cwt(X[i,j,:],sig.ricker,scales)\n","            out[i,j,:] = coef.T\n","    freqs = pywt.scale2frequency('mexh',scales)*250\n","    N, C, T, F = out.shape\n","    X_CWT = np.transpose(out, (0,1,3,2)).reshape(N, C*F, T)\n","    return X_CWT"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cLD4Nd_4DLFe","colab_type":"text"},"source":["### 4. Independent Component Analysis (ICA)"]},{"cell_type":"code","metadata":{"id":"8NBd6c-3DOy2","colab_type":"code","colab":{}},"source":["def ica_data(X, n_components):\n","  # FUNCTION TO COMPUTE THE ICA OF DATA\n","  out = np.empty((X.shape[0], n_components, X.shape[-1]))\n","  for i in range(X.shape[0]):\n","    ica = FastICA(n_components=n_components, whiten=True, max_iter=300, tol=0.01)\n","    out[i,:,:] = ica.fit_transform(X[i,:,:].T).T  # Reconstruct signals\n","  return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LU9E1jC7_hdJ","colab_type":"text"},"source":["## Define data augmentation wrapper"]},{"cell_type":"code","metadata":{"id":"zSFCOa05EI2y","colab_type":"code","colab":{}},"source":["def Aug_Data(X, y, p, aug_type=None, window_size=200, window_stride=20, stft_size=None, stft_stride=None, cwt_level=None, cwt_scale=None):\n","    if aug_type == None:\n","        X_aug, y_aug, p_aug = X, y, p\n","    elif aug_type == \"window\":\n","        _, X_aug, y_aug, p_aug = window_data(X, y, p, window_size, window_stride)\n","    elif aug_type == \"stft\":\n","        X_aug = stft_data(X, stft_size, stft_stride)\n","        y_aug, p_aug = y, p\n","    elif aug_type == 'cwt':\n","        X_aug = cwt_data(X, cwt_level, cwt_scale)\n","        y_aug, p_aug = y, p\n","    \n","    return X_aug, y_aug, p_aug"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jOKsX1Xm-O42","colab_type":"text"},"source":["# Architectures"]},{"cell_type":"markdown","metadata":{"id":"pTAZw5n7EI3B","colab_type":"text"},"source":["### Define Basic LSTM"]},{"cell_type":"code","metadata":{"id":"2-drfGKkEI3D","colab_type":"code","colab":{}},"source":["class LSTMnet(nn.Module):\n","    '''\n","    Create Basic LSTM:\n","    2 layers\n","\n","    TODO: make number of layers, dropout, activation function, regularization all params\n","    see ex: https://blog.floydhub.com/gru-with-pytorch/\n","    '''\n","\n","    def __init__(self, input_size, hidden_size, output_dim, dropout):\n","        super(LSTMnet, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_dim = output_dim\n","        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, output_dim)\n","    \n","    def forward(self, x, h=None):\n","        if type(h) == type(None):\n","            out, hn = self.rnn(x)\n","        else:\n","            out, hn = self.rnn(x, h.detach())\n","        out = self.fc(out[-1, :, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BNUej_RTEI3H","colab_type":"text"},"source":["### Define Basic GRU"]},{"cell_type":"code","metadata":{"id":"G48clZrtEI3J","colab_type":"code","colab":{}},"source":["class GRUnet(nn.Module):\n","    '''\n","    Create Basic GRU:\n","    2 layers\n","\n","    TODO: make number of layers, dropout, activation function, regularization all params\n","    see ex: https://blog.floydhub.com/gru-with-pytorch/\n","    '''\n","\n","    def __init__(self, input_size, hidden_size, output_dim, dropout):\n","        super(GRUnet, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_dim = output_dim\n","        self.rnn = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=2, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size, output_dim)\n","    \n","    def forward(self, x, h=None):\n","        if type(h) == type(None):\n","            out, hn = self.rnn(x)\n","        else:\n","            out, hn = self.rnn(x, h.detach())\n","        out = self.fc(out[-1, :, :])\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-u6gCZLEI3P","colab_type":"text"},"source":["# RNN Initialization"]},{"cell_type":"code","metadata":{"id":"e-90NzPjEI3R","colab_type":"code","colab":{}},"source":["def InitRNN(rnn_type=\"LSTM\", input_size=22, hidden_size=50, output_dim=4, dropout=0.5, lr=1e-3):\n","    '''\n","    Function to initialize RNN\n","    \n","    input: RNN type(LSTM, GRU), and other params if neccessary (regularization, acitvation, dropout, num layers, etc.)\n","\n","    output: model, criterion, optimizer\n","\n","    TODO: Eventually should also take in params such as dropout, number of layers, and activation function(s), etc.\n","    '''\n","\n","    if rnn_type==\"LSTM\":\n","        model = LSTMnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n","\n","    elif rnn_type==\"GRU\":\n","        model = GRUnet(input_size=input_size, hidden_size=hidden_size, output_dim=output_dim, dropout=dropout).to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    return model, criterion, optimizer\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJwC6_vOEI3Y","colab_type":"text"},"source":["### K-Fold Training and Cross Validation"]},{"cell_type":"code","metadata":{"id":"36PDvdn1EI3g","colab_type":"code","colab":{}},"source":["def TrainRNN(trainloader, valloader, num_epochs=6, verbose=True, aug_type=None):\n","    val_acc_list = []\n","    for ep in range(num_epochs):\n","        tstart = time.time()\n","        running_loss = 0.0\n","        correct, total = 0, 0\n","        for idx, batch in enumerate(EEG_trainloader):\n","            optimizer.zero_grad()\n","            X = batch['X'].permute(2, 0, 1).to(device)\n","            y = batch['y'].to(device)\n","            output = model(X)\n","            loss = criterion(output, y)\n","            running_loss += loss.item()\n","            loss.backward()\n","            optimizer.step()\n","            pred = torch.argmax(output, dim=1)\n","            correct += torch.sum(pred == y).item()\n","            total += y.shape[0]\n","        train_acc = correct / total\n","        train_loss = running_loss\n","        '''\n","        The validation need to be customized according to the data augmenation type\n","        for stft and cwt: they didn't increase the number of trials, we can directly pass the augmented data to the model\n","        for window: it increase the number of trials, we need to do a voting for different subsequences in one trial\n","        \n","        '''\n","        if aug_type == 'window':\n","            correct, total = 0, 0\n","            for idx, batch in enumerate(EEG_valloader):\n","                X = batch['X'].permute(2, 0, 1).to(device)\n","                y = batch['y'].to(device)\n","                vote_idx = np.random.choice(1000-window_size, vote_num)\n","                vote_pred = np.zeros(y.shape[0])\n","                for i in range(len(vote_idx)):\n","                    X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","                    output = model(X_sub)\n","                    pred = torch.argmax(output, dim=1)\n","                    if i == 0:\n","                        vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","                    else:\n","                        vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","                    for row in range(y.shape[0]):\n","                        vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","                vote_pred = torch.from_numpy(vote_pred).long()\n","                correct += torch.sum(vote_pred == y.cpu()).item()\n","                total += y.shape[0]\n","            val_acc = correct / total        \n","        else:\n","            correct, total = 0, 0\n","            for idx, batch in enumerate(EEG_valloader):\n","                X = batch['X'].permute(2, 0, 1).to(device)\n","                y = batch['y'].to(device)\n","                output = model(X)                    \n","                pred = torch.argmax(output, dim=1)\n","                correct += torch.sum(pred == y.cpu()).item()\n","                total += y.shape[0]\n","            val_acc = correct / total\n","        tend = time.time()\n","        if verbose:\n","            print('epoch: {:<3d}    time: {:<3.2f}    loss: {:<3.3f}    train acc: {:<1.3f}    val acc: {:<1.3f}'.format(ep+1, tend - tstart, train_loss, train_acc, val_acc))\n","        val_acc_list.append(val_acc)\n","    best_val_acc = max(val_acc_list)\n","    return best_val_acc"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YyEi2-f-EI3u","colab_type":"text"},"source":["# Pipeline"]},{"cell_type":"markdown","metadata":{"id":"mdrFodRqEI3v","colab_type":"text"},"source":["## 1. Split the data to train and validation"]},{"cell_type":"code","metadata":{"id":"FBPsXoMTEI3x","colab_type":"code","outputId":"1e106c50-d990-4f6e-c0e9-2b4caaf19529","executionInfo":{"status":"ok","timestamp":1583868747346,"user_tz":420,"elapsed":502,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","X_train_valid[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1692, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"Y_dtSFRAEI36","colab_type":"text"},"source":["## 2. Initialize the model"]},{"cell_type":"code","metadata":{"id":"CLP8d7J3EI37","colab_type":"code","colab":{}},"source":["# indicate hyperparameters here\n","model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bMOLEuXpQsMV","colab_type":"text"},"source":["#Experiments"]},{"cell_type":"markdown","metadata":{"id":"RI2MU7fuQk3W","colab_type":"text"},"source":["## Windowed Augmentation"]},{"cell_type":"markdown","metadata":{"id":"p7n2-WvtQ0zV","colab_type":"text"},"source":["### finding ideal stride for windowed augmentation"]},{"cell_type":"code","metadata":{"id":"6wa-4hkqQ5Fu","colab_type":"code","outputId":"2a2e4c45-4ab6-45c1-8d79-dfefe18347da","executionInfo":{"status":"ok","timestamp":1583883288425,"user_tz":420,"elapsed":3698490,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":519}},"source":["aug_type = \"window\"\n","window_size = 150\n","strides = [10, 25, 50, 100]\n","#win_stride = 50\n","vote_num = 50\n","best_val_acc = 0.0\n","k = 0\n","for win_stride in strides:\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n","    # indicate hyperparameters here\n","    print ('stride: {}'.format(win_stride))\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=win_stride)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('best validation is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["stride: 10\n","epoch: 1      time: 331.18    loss: 1553.087    train acc: 0.276    val acc: 0.262\n","epoch: 2      time: 327.14    loss: 1552.710    train acc: 0.280    val acc: 0.350\n","epoch: 3      time: 326.42    loss: 1544.233    train acc: 0.297    val acc: 0.326\n","epoch: 4      time: 327.20    loss: 1538.230    train acc: 0.306    val acc: 0.338\n","epoch: 5      time: 326.28    loss: 1534.997    train acc: 0.313    val acc: 0.355\n","epoch: 6      time: 324.37    loss: 1494.675    train acc: 0.358    val acc: 0.366\n","stride: 25\n","epoch: 1      time: 144.98    loss: 622.750    train acc: 0.267    val acc: 0.336\n","epoch: 2      time: 143.28    loss: 620.345    train acc: 0.285    val acc: 0.340\n","epoch: 3      time: 143.05    loss: 619.238    train acc: 0.291    val acc: 0.288\n","epoch: 4      time: 143.65    loss: 620.260    train acc: 0.288    val acc: 0.284\n","epoch: 5      time: 142.09    loss: 619.223    train acc: 0.291    val acc: 0.352\n","epoch: 6      time: 145.43    loss: 614.616    train acc: 0.311    val acc: 0.369\n","stride: 50\n","epoch: 1      time: 88.01    loss: 311.943    train acc: 0.259    val acc: 0.251\n","epoch: 2      time: 87.39    loss: 310.985    train acc: 0.272    val acc: 0.291\n","epoch: 3      time: 85.53    loss: 309.683    train acc: 0.287    val acc: 0.314\n","epoch: 4      time: 84.81    loss: 308.962    train acc: 0.297    val acc: 0.338\n","epoch: 5      time: 85.77    loss: 307.851    train acc: 0.301    val acc: 0.284\n","epoch: 6      time: 85.41    loss: 309.563    train acc: 0.290    val acc: 0.314\n","stride: 100\n","epoch: 1      time: 53.92    loss: 147.073    train acc: 0.253    val acc: 0.291\n","epoch: 2      time: 54.41    loss: 146.618    train acc: 0.271    val acc: 0.262\n","epoch: 3      time: 54.29    loss: 146.302    train acc: 0.279    val acc: 0.260\n","epoch: 4      time: 54.68    loss: 145.728    train acc: 0.293    val acc: 0.286\n","epoch: 5      time: 54.54    loss: 145.256    train acc: 0.300    val acc: 0.281\n","epoch: 6      time: 53.69    loss: 144.452    train acc: 0.313    val acc: 0.307\n","best validation is :1.3806146572104019\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XeStPdgKEI4A","colab_type":"text"},"source":["### finding ideal window size for windowed augmentation"]},{"cell_type":"code","metadata":{"id":"Pw2GmqpDaWK6","colab_type":"code","outputId":"be5ecde2-0fa3-4761-a0c2-0063a3ba0891","executionInfo":{"status":"ok","timestamp":1583892209016,"user_tz":420,"elapsed":8835449,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":502}},"source":["aug_type = \"window\"\n","#window_size = 50\n","windows = [50, 150, 200, 250]\n","stride = 10\n","vote_num = 50\n","best_val_acc = 0.0\n","k = 0\n","for window_size in windows:\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n","    # indicate hyperparameters here\n","    print ('window_size {}'.format(window_size))\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc = TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","#print ('best validation is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["window_size 50\n","epoch: 1      time: 140.25    loss: 1733.324    train acc: 0.277    val acc: 0.357\n","epoch: 2      time: 137.34    loss: 1717.255    train acc: 0.306    val acc: 0.333\n","epoch: 3      time: 138.59    loss: 1699.115    train acc: 0.326    val acc: 0.291\n","epoch: 4      time: 137.23    loss: 1683.486    train acc: 0.340    val acc: 0.381\n","epoch: 5      time: 139.93    loss: 1667.062    train acc: 0.355    val acc: 0.388\n","epoch: 6      time: 138.08    loss: 1650.986    train acc: 0.368    val acc: 0.355\n","window_size 150\n","epoch: 1      time: 328.67    loss: 1554.043    train acc: 0.272    val acc: 0.253\n","epoch: 2      time: 326.29    loss: 1545.088    train acc: 0.291    val acc: 0.355\n","epoch: 3      time: 320.84    loss: 1499.160    train acc: 0.349    val acc: 0.345\n","epoch: 4      time: 325.38    loss: 1430.609    train acc: 0.401    val acc: 0.371\n","epoch: 5      time: 325.86    loss: 1359.511    train acc: 0.442    val acc: 0.392\n","epoch: 6      time: 322.28    loss: 1286.476    train acc: 0.486    val acc: 0.357\n","window_size 200\n","epoch: 1      time: 633.32    loss: 1460.006    train acc: 0.282    val acc: 0.331\n","epoch: 2      time: 396.26    loss: 1455.803    train acc: 0.291    val acc: 0.343\n","epoch: 3      time: 394.74    loss: 1413.106    train acc: 0.349    val acc: 0.369\n","epoch: 4      time: 399.38    loss: 1311.549    train acc: 0.431    val acc: 0.371\n","epoch: 5      time: 400.15    loss: 1188.958    train acc: 0.511    val acc: 0.359\n","epoch: 6      time: 394.00    loss: 1070.796    train acc: 0.577    val acc: 0.381\n","window_size 250\n","epoch: 1      time: 1023.39    loss: 1370.563    train acc: 0.277    val acc: 0.260\n","epoch: 2      time: 468.19    loss: 1365.472    train acc: 0.292    val acc: 0.350\n","epoch: 3      time: 466.29    loss: 1368.170    train acc: 0.285    val acc: 0.352\n","epoch: 4      time: 466.96    loss: 1349.913    train acc: 0.311    val acc: 0.376\n","epoch: 5      time: 469.49    loss: 1290.174    train acc: 0.383    val acc: 0.348\n","epoch: 6      time: 470.85    loss: 1193.584    train acc: 0.452    val acc: 0.416\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mpaoajnlEI4B","colab_type":"code","outputId":"dbd5d3c3-4a12-4097-bac2-e9a996dbc9ee","executionInfo":{"status":"ok","timestamp":1583876688787,"user_tz":420,"elapsed":4068275,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":398}},"source":["aug_type = \"window\"\n","#window_size = 50\n","windows = [100, 200, 500]\n","stride = 10\n","best_val_acc = 0.0\n","k = 0\n","for window_size in windows:\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n","    # indicate hyperparameters here\n","    print ('window_size {}'.format(window_size))\n","    X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('best validation is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["window_size 100\n","epoch: 1      time: 67.43    loss: 329.843    train acc: 0.259    val acc: 0.251\n","epoch: 2      time: 67.25    loss: 328.945    train acc: 0.275    val acc: 0.331\n","epoch: 3      time: 68.59    loss: 328.265    train acc: 0.288    val acc: 0.265\n","epoch: 4      time: 68.10    loss: 328.877    train acc: 0.276    val acc: 0.284\n","epoch: 5      time: 67.83    loss: 326.786    train acc: 0.298    val acc: 0.296\n","epoch: 6      time: 68.33    loss: 326.647    train acc: 0.300    val acc: 0.310\n","window_size 200\n","epoch: 1      time: 320.78    loss: 293.701    train acc: 0.263    val acc: 0.312\n","epoch: 2      time: 148.88    loss: 292.625    train acc: 0.284    val acc: 0.329\n","epoch: 3      time: 100.00    loss: 291.648    train acc: 0.291    val acc: 0.305\n","epoch: 4      time: 101.20    loss: 291.135    train acc: 0.298    val acc: 0.333\n","epoch: 5      time: 99.46    loss: 290.517    train acc: 0.305    val acc: 0.364\n","epoch: 6      time: 100.77    loss: 289.986    train acc: 0.307    val acc: 0.307\n","window_size 500\n","epoch: 1      time: 438.53    loss: 184.447    train acc: 0.260    val acc: 0.251\n","epoch: 2      time: 436.81    loss: 184.138    train acc: 0.270    val acc: 0.265\n","epoch: 3      time: 458.72    loss: 183.930    train acc: 0.276    val acc: 0.272\n","epoch: 4      time: 478.40    loss: 183.370    train acc: 0.290    val acc: 0.291\n","epoch: 5      time: 536.42    loss: 182.902    train acc: 0.293    val acc: 0.265\n","epoch: 6      time: 431.97    loss: 182.249    train acc: 0.307    val acc: 0.286\n","average best validation accuracy of 5 folds is :0.1971631205673759\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y0kRQ1Zg-t8s"},"source":["## run next CWT augmentation followed by windowing"]},{"cell_type":"markdown","metadata":{"id":"fBYwYVzTOjIP","colab_type":"text"},"source":["####Preprocess data"]},{"cell_type":"code","metadata":{"id":"xfHA00evOgMr","colab_type":"code","colab":{}},"source":["num_levels = 20\n","top_scale = 1\n","X_cwt = cwt_data(X, num_levels, top_scale=top_scale)\n","train_fold, val_fold = Train_Val_Data(X_train_valid, y_train_valid)\n","X_train_valid[train_fold[0]].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JZVM9z8_OoOa","colab_type":"text"},"source":["###Run the thing"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"5e009e06-9261-4692-b44d-34715bed7bce","id":"C_R_S0Di-t8u","executionInfo":{"status":"ok","timestamp":1583811554314,"user_tz":420,"elapsed":2121981,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":398}},"source":["aug_type = 'window'\n","best_val_acc = 0.0\n","window_size = 250\n","stride = 10\n","vote_num = 50\n","k = 0\n","    \n","for k in range(1):\n","    # indicate hyperparameters here\n","    model, criterion, optimizer = InitRNN(rnn_type='LSTM', input_size = 22*num_levels)\n","    print ('fold {}'.format(k+1))\n","    X_train, y_train, p_train = X_cwt[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","    X_val, y_val, p_val = X_cwt[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","    X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type, window_size=window_size, window_stride=stride)\n","    if aug_type != 'window':\n","        X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","    EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","    EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","    EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","    EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","    best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type)\n","print ('best validation is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fold 1\n","epoch: 1      time: 91.46    loss: 19.451    train acc: 0.259    val acc: 0.274\n","epoch: 2      time: 89.24    loss: 19.270    train acc: 0.311    val acc: 0.253\n","epoch: 3      time: 88.86    loss: 19.191    train acc: 0.326    val acc: 0.234\n","epoch: 4      time: 87.98    loss: 19.000    train acc: 0.337    val acc: 0.232\n","epoch: 5      time: 88.60    loss: 18.908    train acc: 0.368    val acc: 0.236\n","epoch: 6      time: 89.76    loss: 18.737    train acc: 0.373    val acc: 0.253\n","epoch: 7      time: 93.21    loss: 18.607    train acc: 0.362    val acc: 0.243\n","epoch: 8      time: 96.55    loss: 18.474    train acc: 0.377    val acc: 0.217\n","epoch: 9      time: 102.01    loss: 18.446    train acc: 0.382    val acc: 0.227\n","epoch: 10     time: 98.99    loss: 18.321    train acc: 0.375    val acc: 0.217\n","epoch: 11     time: 98.85    loss: 18.141    train acc: 0.397    val acc: 0.251\n","epoch: 12     time: 99.75    loss: 17.827    train acc: 0.427    val acc: 0.248\n","epoch: 13     time: 113.61    loss: 17.612    train acc: 0.425    val acc: 0.239\n","epoch: 14     time: 115.82    loss: 17.510    train acc: 0.447    val acc: 0.267\n","epoch: 15     time: 118.04    loss: 17.285    train acc: 0.443    val acc: 0.262\n","epoch: 16     time: 117.94    loss: 17.204    train acc: 0.438    val acc: 0.243\n","epoch: 17     time: 109.04    loss: 17.243    train acc: 0.444    val acc: 0.265\n","epoch: 18     time: 115.06    loss: 17.053    train acc: 0.436    val acc: 0.239\n","epoch: 19     time: 115.87    loss: 16.982    train acc: 0.449    val acc: 0.265\n","epoch: 20     time: 113.69    loss: 16.669    train acc: 0.472    val acc: 0.246\n","average best validation accuracy of 5 folds is :0.05484633569739953\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5OyShp4PN-OZ","colab_type":"code","outputId":"86d318c3-9e99-424e-a27b-d8f085e6bc3f","executionInfo":{"status":"ok","timestamp":1583811570097,"user_tz":420,"elapsed":2124894,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test, aug_type=aug_type, cwt_level=num_levels, cwt_scale=top_scale)\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(443, 330, 1000)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"12a03160-ca02-4b77-b5bc-bf2428e408d6","id":"jTafPsT0-t8x","executionInfo":{"status":"ok","timestamp":1583811574402,"user_tz":420,"elapsed":2126786,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","correct, total = 0, 0\n","for idx, batch in enumerate(EEG_testloader):\n","    X = batch['X'].permute(2, 0, 1).to(device)\n","    y = batch['y'].to(device)\n","    output = model(X)                    \n","    pred = torch.argmax(output, dim=1)\n","    correct += torch.sum(pred == y.cpu()).item()\n","    total += y.shape[0]\n","test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy: 0.2415\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oBMmFyQsz1kF"},"source":["## 3. Do K-Fold training and validation with windowed augmentation\n","\n","Did not re-initialize RNN for every fold"]},{"cell_type":"markdown","metadata":{"id":"xwNDC2j979dq","colab_type":"text"},"source":["###Whiten and center data"]},{"cell_type":"code","metadata":{"id":"U2FNKIcB8AhR","colab_type":"code","outputId":"3419e9df-a45f-4884-db02-63a8e33e63aa","executionInfo":{"status":"ok","timestamp":1583816432759,"user_tz":420,"elapsed":1989,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_scaled = scale_data(X_train_valid)\n","train_fold, val_fold = Train_Val_Data(X_scaled, y_train_valid)\n","X_train_valid[train_fold[0]].shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1692, 22, 1000)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"qbKrZ4i78Byi","colab_type":"text"},"source":["###Run the thing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"p6RWrgr2z1kL","outputId":"60089771-4b01-4b50-a8b9-e938b16bc8f9","executionInfo":{"status":"ok","timestamp":1583818345133,"user_tz":420,"elapsed":1910680,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"colab":{"base_uri":"https://localhost:8080/","height":190}},"source":["aug_type = \"window\"\n","window_size = 200\n","vote_num = 20\n","best_val_acc = 0.0\n","model, criterion, optimizer = InitRNN(rnn_type='LSTM')\n","k=0\n","# indicate hyperparameters here\n","print ('fold {}'.format(k+1))\n","X_train, y_train, p_train = X_train_valid[train_fold[k]], y_train_valid[train_fold[k]], person_train_valid[train_fold[k]]\n","X_val, y_val, p_val = X_train_valid[val_fold[k]], y_train_valid[val_fold[k]], person_train_valid[val_fold[k]]\n","X_train, y_train, p_train = Aug_Data(X_train, y_train, p_train, aug_type=aug_type)\n","if aug_type != 'window':\n","    X_val, y_val, p_val = Aug_Data(X_val, y_val, p_val, aug_type=aug_type)\n","EEG_trainset = EEG_Dataset(X_train=X_train, y_train=y_train, p_train=p_train, mode='train')\n","EEG_trainloader = DataLoader(EEG_trainset, batch_size=128, shuffle=True)\n","EEG_valset = EEG_Dataset(X_val=X_val, y_val=y_val, p_val=p_val, mode='val')\n","EEG_valloader = DataLoader(EEG_valset, batch_size=128, shuffle=False)\n","best_val_acc += TrainRNN(EEG_trainloader, EEG_valloader, aug_type=aug_type) / 5\n","print ('average best validation accuracy of 5 folds is :{}'.format(best_val_acc))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["fold 1\n","epoch: 1      time: 539.78    loss: 731.980    train acc: 0.270    val acc: 0.291\n","epoch: 2      time: 204.58    loss: 729.750    train acc: 0.283    val acc: 0.293\n","epoch: 3      time: 201.08    loss: 727.745    train acc: 0.293    val acc: 0.312\n","epoch: 4      time: 188.42    loss: 724.522    train acc: 0.302    val acc: 0.329\n","epoch: 5      time: 193.51    loss: 728.958    train acc: 0.287    val acc: 0.324\n","epoch: 6      time: 191.84    loss: 726.361    train acc: 0.295    val acc: 0.355\n","epoch: 7      time: 191.39    loss: 724.376    train acc: 0.303    val acc: 0.274\n","epoch: 8      time: 191.68    loss: 725.553    train acc: 0.297    val acc: 0.319\n","average best validation accuracy of 5 folds is :0.07092198581560284\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"b7a2332f-f4ee-4484-ddaf-c1be96f20a27","executionInfo":{"status":"error","timestamp":1583816227890,"user_tz":420,"elapsed":664,"user":{"displayName":"Eden Haney","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib9imPrgjxzjV1g9-PpXI0ncoF52ZbGyE6wYF09A=s64","userId":"14340126640988707257"}},"id":"9IKRQvvjz1kM","colab":{"base_uri":"https://localhost:8080/","height":380}},"source":["X_test, y_test, p_test = X_test, y_test, person_test\n","if aug_type == 'window':\n","    EEG_testset = EEG_Dataset(X_train, y_train, p_train, X_val, y_val, p_val, X_test, y_test, p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)\n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        vote_idx = np.random.choice(1000-window_size, vote_num)\n","        vote_pred = np.zeros(y.shape[0])\n","        for i in range(len(vote_idx)):\n","            X_sub = X[vote_idx[i]:vote_idx[i]+200,:,:]\n","            output = model(X_sub)\n","            pred = torch.argmax(output, dim=1)\n","            if i == 0:\n","                vote_matrix = np.asarray(pred.cpu().view(-1, 1))\n","            else:\n","                vote_matrix = np.hstack((vote_matrix, np.asarray(pred.cpu().view(-1,1))))\n","            for row in range(y.shape[0]):\n","                vote_pred[row] = np.bincount(vote_matrix[row, :]).argmax()\n","        vote_pred = torch.from_numpy(vote_pred).long()\n","        correct += torch.sum(vote_pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total \n","else:\n","    X_test, y_test, p_test = Aug_Data(X_test, y_test, p_test)\n","    EEG_testset = EEG_Dataset(X_test=X_test, y_test=y_test, p_test=p_test, mode='test')\n","    EEG_testloader = DataLoader(EEG_testset, batch_size=128, shuffle=False)    \n","    correct, total = 0, 0\n","    for idx, batch in enumerate(EEG_testloader):\n","        X = batch['X'].permute(2, 0, 1).to(device)\n","        y = batch['y'].to(device)\n","        output = model(X)                    \n","        pred = torch.argmax(output, dim=1)\n","        correct += torch.sum(pred == y.cpu()).item()\n","        total += y.shape[0]\n","    test_acc = correct / total\n","print ('Testing Accuracy: {:.4f}'.format(test_acc))\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-30dbd1255fe0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mX_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvote_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-540e1971b022>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    157\u001b[0m             raise RuntimeError(\n\u001b[1;32m    158\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m--> 159\u001b[0;31m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 22, got 330"]}]}]}